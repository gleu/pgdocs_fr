<?xml version="1.0" encoding="ISO-8859-1"?>
<!-- SAS 20060623 : Relecture initiale -->
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.3//EN"
"http://www.oasis-open.org/docbook/xml/4.3/docbookx.dtd" >

<article id="postgresqlconf" lang="fr">
 <articleinfo>
  <title>Fichier postgresql.conf et guide de configuration utilisateur générale (<foreignphrase>Global User Configuration (GUC)</foreignphrase>) annotés</title>
  <subtitle>PostgreSQL 8.0.x</subtitle>
 </articleinfo>

<sect1>
<title>Emplacement des fichiers</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>data_directory</entry>
  <entry>Répertoire</entry>
  <entry>ConfigDir</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Répertoire de stockage des données
  </entry>
  <entry>
  Ces nouveaux paramètres de configuration des emplacements de fichiers facilitent l'administration
  d'une installation de PostgreSQL lorsque les fichiers de configuration et de surveillance
  sont séparés de la base, généralement dans un but d'ajustement à une spécification particulière
  du fichier d'administration ou pour automatiser la conduite de tests avec plusieurs configurations.
  Lorsque ce paramètre est utilisé, seul l'emplacement du fichier postgresql.conf doit être
  précisé au démarrage du postmaster (à l'aide de -D ou PGDATA). Cette approche est supérieure
  à l'utilisation de lien symbolique, unique option jusque là disponible.
  </entry>
 </row>
 <row>
  <entry>hba_file</entry>
  <entry>nom de fichier</entry>
  <entry>ConfigDir/pg_hba.conf</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Fichier de configuration pour l'authentification basée sur l'hôte (habituellement appelé pg_hba.conf)
  </entry>
  <entry></entry>
 </row>
 <row>
  <entry>ident_file</entry>
  <entry>Nom de fichier</entry>
  <entry>ConfigDir/pg_ident.conf</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Fichier de configuration pour l'authentification par ident (habituellement appelé pg_ident.conf)
  </entry>
  <entry></entry>
 </row>
 <row>
  <entry>external_pid_file</entry>
  <entry>Nom de fichier</entry>
  <entry>Aucun</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Nom du fichier additionnel d'identifiant de processus (PID) que le postmaster crée pour les programmes d'administration serveur
  </entry>
  <entry>
  Ce paramètre est utile pour les programmes d'administration et les interfaces utilisateur 
  graphiques qui s'attendent à trouver le PID de PostgreSQL à un emplacement particulier, en général
  /var. Ce n'est qu'une copie du PID, en aucun cas le fichier utilisé par pg_ctl au démarrage. 
  Ce dernier est situé dans le répertoire des données.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect1>

<sect1>
<title>Connexions et authentification</title>

<sect2>
<title>Paramètres de connexion</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>listen_addresses</entry>
  <entry></entry>
  <entry>localhost</entry>
  <entry>Démarrage</entry>
  <entry>-h x -i</entry>
  <entry>
  Adresse(s) TCP/IP sur la(es)quelle(s) le serveur écoute les connexions en provenance
  des clients. La valeur à la forme d'une liste de noms d'hôte ou d'adresses IP séparés par des
  virgules. La valeur spéciale '*' correspond à toutes les interfaces IP disponibles. 
  Si la liste est vide, le serveur n'écoute aucune interface IP. Dans ce cas, seules les
  sockets de domaine UNIX peuvent être utilisées pour se connecter. La valeur par défaut est
  'localhost', ce qui n'autorise que les connexions &laquo&nbsp;loopback&nbsp;&raquo;.
  </entry>
  <entry>
  <para>
  Ce paramètre remplace les deux paramètres &laquo&nbsp;tcp_ip&nbsp;&raquo; et 
  &laquo&nbsp;virtual_host&nbsp;&raquo; de la version 7.4. La plupart des utilisateurs peuvent
  utiliser '*' pour écouter toutes les adresses, ou laisser 'localhost' pour une machine sécurisée.
  À la différence des versions précédentes, la valeur par défaut autorise désormais les connexions
  TCP/IP sur 127.0.0.1. Le serveur web local peut ainsi se connecter sans paramétrage particulier.
  </para>
  <para>
  Pour une accès sécurisé, ce paramètre doit être modifié <emphasis>après</emphasis>
  la configuration du fichier pg_hba.conf.
  </para>
  </entry>
 </row>
 <row>
  <entry>port</entry>
  <entry>129 à 32768</entry>
  <entry>5432</entry>
  <entry>Démarrage</entry>
  <entry>-p #</entry>
  <entry>
  Le port TCP sur lequel le serveur écoute. 5432 par défaut. Ce port est utilisé pour toutes les 
  adresses IP que le serveur écoute.
  </entry>
  <entry>
  <para>
  Un port alternatif est essentiellement utilisé lorsqu'il est nécessaire de faire tourner
  plusieurs serveurs PostgreSQL sur la même machine, pendant une mise à niveau par exemple.
  </para>
  <para>
  Une alternative à cette configuration est l'utilisation de l'option de compilation
  &laquo;&nbsp;with-port&nbsp;&raquo;.
  Cette option fixe le port alternatif dans toutes les bibliothèques évitant ainsi de
  préciser l'option -p pour tous les clients.
  </para>
  </entry>
 </row>
 <row>
  <entry>max_connections</entry>
  <entry>2 à 262143</entry>
  <entry>100</entry>
  <entry>Démarrage</entry>
  <entry>-N #</entry>
  <entry>
  Nombre maximum de connexions concurrentes à un serveur de bases de données.
  Typiquement 100 par défaut, il peut être réduit si la configuration du noyau
  l'impose (initdb tente de le déterminer).
  </entry>
  <entry>
  Ce paramètre doit être maintenu près du minimum requis par l'application.
  En effet, chaque connexion nécessite des ressources
  système significatives. Les applications web qui servent des centaines
  d'utilisateurs peuvent utiliser une réserve de connexions
  (<foreignphrase>connection pool</foreignphrase>) pour réduire le nombre 
  de connexions demandées. L'augmentation du paramètre demande un ajustement des
  limites mémoire du système.
  </entry>
 </row>
 <row>
  <entry>superuser_reserved_connections</entry>
  <entry>0 à max_connections - 1</entry>
  <entry>2</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Nombre de connexions réservées aux superutilisateurs PostgreSQL. Au plus
  max_connections connexions peuvent être actives simultanément. Lorsque
  le nombre de connexions concurrentes atteint max_connections moins
  superuser_reserved_connections, seules les connexions de superutilisateurs
  sont encore autorisées.
  </entry>
  <entry>
  Cela protège l'accès des superutilisateurs en cas d'engorgement de la base.
  Ce paramètre ne doit être positionné à 0 que lorsqu'il est certain que
  toutes les connexions ne sont jamais utilisées. (NDR&nbsp;: Je positionne
  souvent ce paramètre à 1, puisque je ne me connecte en superutilisateur
  à la base qu'en cas de problème.) Le paramétrage à 2 par défaut prévoit le 
  cas d'utilitaire administratif connecté en permanence, autovacuum par exemple.
  </entry>
 </row>
 <row>
  <entry>unix_socket_directory</entry>
  <entry></entry>
  <entry>''</entry>
  <entry>Démarrage</entry>
  <entry>-k $</entry>
  <entry>
  Répertoire du socket de domaine Unix sur lequel le serveur écoute
  les connections de clients. Par défaut, c'est /tmp, mais le paramètre
  peut être modifié à la compilation.
  </entry>
  <entry>
  Aucune recommandation particulière.
  </entry>
 </row>
 <row>
  <entry>unix_socket_group</entry>
  <entry></entry>
  <entry>''</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Groupe propriétaire du socket de domaine Unix. (L'utilisateur propriétaire
  de ce socket est toujours celui qui démarre le serveur.) Combiné avec l'option
  UNIX_SOCKET_PERMISSIONS, ce paramètre peut être utilisé comme mécanisme
  supplémentaire de contrôle des accès pour ce type de socket. Par défaut, 
  c'est une chaîne vide, soit le groupe par défaut de l'utilisateur.
  </entry>
  <entry>
  Aucune recommandation particulière.</entry>
 </row>
 <row>
  <entry>unix_socket_permissions</entry>
  <entry></entry>
  <entry>0777</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  <para>
  Permissions d'accès au socket de domaine Unix. Les sockets de domaine Unix
  utilise le système habituel de gestion des permissions des systèmes de 
  fichier Unix. La valeur de l'option doit être précisée sous la forme numérique
  acceptée par les outils système chmod et umask. L'utilisation du format 
  octal impose un 0 (zéro) en début de nombre.
  </para>
  <para>
  Les permissions par défaut sont 0777, tout le monde peut se connecter.
  Des alternatives acceptables sont 0770 (autorisations pour l'utilisateur
  et le groupe, voir aussi unix_socket_group), et 0700 (utilisateur seul).
  En général, dans le cas d'une socket de domaine Unix, seule la permission
  d'écriture importe. Il n'y a donc aucun intérêt à positionner ou supprimer
  les droits d'écriture ou de lecture.
  </para>
  </entry>
  <entry>
  Aucune recommandation particulère.</entry>
 </row>
 <row>
  <entry>rendezvous_name</entry>
  <entry></entry>
  <entry>''</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Nom du diffuseur Rendezvous. La valeur par défaut, indiquée par une chaîne
  vide '', est le nom de l'ordinateur. Cette option n'a d'intérêt que pour les
  plateformes qui supportent Rendezvous.
  </entry>
  <entry>
  Aucune recommandation particulière.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Securité et authentification</title>

<table>
<title>Securité et authentication (Fichier postgresql.conf et guide de configuration utilisateur générale (<foreignphrase>Global User Configuration (GUC)</foreignphrase>) annotés)</title>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>authentication_timeout</entry>
  <entry>1-600 sec</entry>
  <entry>600</entry>
  <entry>Rechargement</entry>
  <entry></entry>
  <entry>
  Temps maximum laissé à un client pour réussir l'authentification, en secondes.
  Si un client potentiel n'a pas terminé la séquence d'authentification
  pendant ce temps, le serveur met fin à la connexion. Cela permet 
  d'éviter qu'un client bloqué n'occupe indéfiniment une connexion.
  </entry>
  <entry>
  Le temps d'attente peut être réduit s'il s'agit d'exécuter un site web
  à grand traffic. Afin d'éviter une indisponibilité non souhaitée,
  ou une attente trop longue lorsque le serveur est chargé, il peut
  être utile de faire correspondre ce temps d'attente avec celui de l'intergiciel.
  </entry>
 </row>
 <row>
  <entry>ssl</entry>
  <entry>true, false</entry>
  <entry>false</entry>
  <entry>Démarrage</entry>
  <entry>-l</entry>
  <entry>Active les connexions SSL</entry>
  <entry>
  SSL est une alternative chiffrée à l'accès direct au port TCP/IP, nécessaire
  pour les clients accédant à des données sécurisées, en particulier à travers
  un réseau sans fil. PostgreSQL envoie les requêtes et les données en texte,
  même lors de l'utilisation d'un mot de passe chiffré. SSL peut être difficile
  à configurer, et tout les clients ne supportent pas l'accès SSL.
  </entry>
 </row>
 <row>
  <entry>password_encryption</entry>
  <entry>true, false</entry>
  <entry>true</entry>
  <entry>Exécution</entry>
  <entry></entry>
  <entry>
  Détermine le chiffrement du mot de passe lorsque ni ENCRYPTED ni UNENCRYPTED
  ne sont précisés lors de l'indication d'un mot de passe avec les commandes
  CREATE USER et ALTER USER.
  </entry>
  <entry>
  Il est préférable de laisser la valeur à <foreignphrase>true</foreignphrase> (vrai),
  à la fois dans le fichier de configuration et à la connexion. Il n'y a quasiment
  jamais de raison de ne pas chiffrer les mots de passe des utilisateurs de la base de
  données.
  </entry>
 </row>
 <row>
  <entry>krb_server_keyfile</entry>
  <entry></entry>
  <entry>''</entry>
  <entry>Démarrage</entry>
  <entry></entry>
  <entry>
  Positionne l'implantation du fichier de clés du serveur Kerberos.
  </entry>
  <entry>
  Utilisé uniquement pour l'authentification Kerberos des utilisateurs.
  </entry>
 </row>
 <row>
  <entry>db_user_namespace</entry>
  <entry>true, false</entry>
  <entry>false</entry>
  <entry>Rechargement</entry>
  <entry></entry>
  <entry>
  Lorsque cette option est activée, les utilisateurs doivent être créés comme
  username@dbname. Lorsque le nom d'utilisateur est fourni par un client, 
  @ et le nom de la base sont ajoutés au nom de l'utilisateur.
  C'est ce nom d'utilisateur, dépendant d'une base de données, qui est
  ensuite recherché par le serveur. Lors de la création dans l'environnement
  SQL d'utilisateurs dont le nom contient @, il est nécessaire de placer le
  nom de l'utilisateur entre des guillemets simples.
  name.
  </entry>
  <entry>
  Cette option prend en charge les installations (telles que les FAI)
  qui nécessitent des utilisateurs définis par base de données. C'est
  assez contraignant, et cela devrait être supprimé lorsqu'une meilleure
  solution sera créée. Il est ainsi préférable de ne pas utiliser cette option
  lorsqu'elle n'est pas vitale.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Utilisation des ressources</title>

<sect2>
<title>Mémoire</title>

<note>
 <para>
  Augmenter la valeur de la plupart des paramètres suivants
  oblige à modifier les options du noyau du système d'exploitation 
  pour augmenter la mémoire alloué à un processus ou à un utilisateur.
  La documentation en ligne fournit des informations sur les commandes
  à utiliser pour de nombreux systèmes d'exploitation. Sauf indication
  contraire, la plupart de ces options s'additionnent pour déterminer 
  la quantité totale de mémoire utilisée par PostgreSQL.
 </para>
</note>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documetation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>shared_buffers</entry>
  <entry>16 à 262143</entry>
  <entry>1000</entry>
  <entry>
  Démarrage
  </entry>
  <entry>-B x</entry>
  <entry>
  Positionne le nombre de tampons de mémoire partagée utilisé par le 
  serveur de bases de données. Le minimum est 2 X max_connections.
  La valeur par défaut est généralement 1000, mais elle peut être
  inférieure si la configuration du noyau l'impose (ce qu'initdb détermine). 
  Chaque tampon représente 8192 octets, à moins qu'une valeur
  différente de BLCKSZ n'ait été choisie à la compilation. La valeur
  minimale est de 16 et de deux fois la valeur de max_connections.
  Néanmoins, un paramétrage significativement supérieur au minimum
  est souvent nécessaire pour assurer des performances satisfaisantes.
  En production, il est recommandé d'utiliser une valeur de quelques
  milliers.
  </entry>
  <entry>
  <para>
  Le paramétrage de shared_buffers nécessite une discussion bien plus complète
  que ne l'autorise la place ici disponible. On peut se référer à d'autres
  articles sur le sujet.
  </para>
  <para>
  Quelques règles empiriques&nbsp;:
  Sur un serveur PostgreSQL dédié, une valeur convenable se situe en général entre 
  1&nbsp;000 et 50&nbsp;000 (8Mo et 400Mo). Les facteurs qui incitent à augmenter
  la valeur sont des connexions plus nombreuses, des parties actives de la base
  plus grandes, des requêtes longues et complexes, et des grandes tables. La
  RAM disponible limite le ombre maximum de shared_buffers&nbsp;; 1/3 de la RAM
  disponible est la limite maximale à utiliser.
  </para>
  </entry>
 </row>
 <row>
  <entry>
  work_mem
  </entry>
  <entry>64 à Int Max</entry>
  <entry>1024</entry>
  <entry>
  Exécution
  </entry>
  <entry>-S #</entry>
  <entry>
  <para>
  Précise la quantité de mémoire utisable par les opérations de tri interne et
  les tables de hachage avant d'utiliser des fichiers temporaires. La valeur
  est indiquée en kilooctets, la valeur par défaut est 1024 kilooctets (1Mo).
  En cas de requête complexe, de nombreuses opérations de tri ou de hachage
  peuvent s'exécuter en parallèle&nbsp;; chacune peut utiliser la quantité
  de mémoire indiquée par la valeur de ce paramètre avant de commencer à
  utiliser des fichiers temporaires. De plus, de nombreuses sessions
  peuvent effectuer ces opérations concurrentiellement. La mémoire totale
  utilisée peut être plusieurs fois la valeur de work_mem&nbsp;; il faut
  en tenir compte lors du choix de la valeur. Les opérations de tri sont 
  utilisées par ORDER BY, DISTINCT et les jointures. Les tables de hachage
  sont utilisées dans les jointures de hachage, les aggrégations par hachage
  et la résolution par hachage des sous-requêtes IN.
  </para>
  </entry>
  <entry>
  <para>
  À l'origine appelé sort_mem, le paramètre a été renommé pour refléter
  l'extension de son rôle au-delà des simples tris.
  </para>
  <para>
  work_mem est un compromis. Une plus grande valeur est utilisée pour&nbsp;: les
  bases de données volumineuses, les requêtes complexes, une grande quantité de 
  RAM disponible. Une plus petite valeur est recherchée pour&nbsp;: une faible
  quantité de RAM ou de nombreux accès concurrents. Trouver le bon compromis
  peut s'avérer délicat.
  </para>
  <para>
  Une autre façon d'ajuster cette valeur consiste à surveiller les fichiers
  temporaires de PostgreSQL (dans PGDATA/base/DB_OID/pgsql_tmp) et d'accroître
  la valeur de sort_mem si de nombreuses requêtes permutent avec ces fichiers.
  </para>
  <para>
  Il ne faut pas oublier que ce paramètre peut être positionné par connexion.
  Ainsi, dans le cas où seules quelques requêtes très complexes sont à
  exécuter, la valeur peut être augmentée avant leur exécution, mais conservée
  basse pour les autres connexions.
  </para>
  </entry>
 </row>
 <row>
  <entry>
  maintenance_work_mem
  </entry>
  <entry>1024 à Int Max</entry>
  <entry>8192</entry>
  <entry>
  Exécution
  </entry>
  <entry></entry>
  <entry>
  Indique la quantité maximale de mémoire à utiliser dans les opérations
  de maintenance, telles que VACUUM, CREATE INDEX et ALTER TABLE ADD FOREIGN KEY.
  La valeur est précisée en kilooctets. La valeur par défaut est 16384 kilooctets
  (16 Mo). Puisque seule une de ces opérations peut être effectuée à la fois
  au cours d'une session, et qu'en général peu se produisent simultanément
  sur une même installation, il n'y a aucun risque à positionner ce paramètre
  à une valeur nettement supérieure à celle de work_mem. Une valeur élevée
  peut améliorer les performances du nettoyage (vacuum) et de la restauration
  des sauvegardes.
  </entry>
  <entry>
  <para>
  À l'origine appelé vacuum_mem, le paramètre a été renommé pour refléter l'extension
  de son rôle à l'allocation de mémoire lors du chargement des index.
  </para>
  <para>
  La valeur par défaut est généralement trop basse. Il en résulte un blocage
  des E/S du système par les opérations de VACUUM et de créations d'index et/ou
  des blocages d'objets pendant la permutation. Une valeur convenable est généralement
  comprise entre 32&nbsp;Mo et 256&nbsp;Mo&nbsp;; cela dépend autant de la RAM
  disponible que du plus grand volume (attendu) des objets de la base. 
  </para>
  <para>
  Tout comme work_mem, ce paramètre peut être fixé à l'exécution, ce qui permet 
  de l'accroître temporairement lors du chargement d'index ou de la création 
  de clés sur des tables volumineuses.
  </para>
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Mappe de l'espace libre <foreignphrase>Free Space Map</foreignphrase></title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Paramètre</entry>
  <entry>Échelle</entry>
  
  <entry>Valeur par défaut</entry>
  <entry>Positionné au</entry>
  <entry>-o</entry>
  <entry>Ce que dit la documentation</entry>
  <entry>Commentaires</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>max_fsm_pages</entry>
  <entry>1000 à Int Max</entry>
  <entry>20000</entry>
  <entry>
  Démarrage
  </entry>
  <entry></entry>
  <entry>
  Positionne le nombre maximum de pages disque pour lesquels l'espace
  libre est recherché dans la mappe de l'espace libre partagé.
  Six octets de mémoire partagée sont consommés pour chaque connecteur
  de page. La valeur doit être supérieure à 16 X max_fsm_relations.
  </entry>
  <entry>
  <para>
  Un paramétrage correct de la FSM peut éliminer, ou au moins, retarder
  l'obligation d'exécuter VACUUM FULL et REINDEX. La meilleure façon de le régler 
  est la suivante&nbsp;: 1) calculer la fréquence du VACUUM (normal) de la
  base en fonction des écritures&nbsp;; 2) utiliser la base en fonctionnement
  normal et exécuter VACUUM VERBOSE ANALYZE à la place de VACUUM, en sauvegardant
  la sortie dans un fichier&nbsp;; 3) calculer le nombre de pages maximum réclamé
  par VACUUM et utiliser ce chiffre.
  </para>
  <para>
  Alternativement, en cas d'utilisation d'autovacuum, la valeur peut être
  issue d'un pourcentage du nombre total de pages dans la base, pour coïncider
  avec le pourcentage d'autovacuum. Quoiqu'il en soit, une page demande peu
  de mémoire (environ 6 octets). il est donc préférable d'être généreux plutôt 
  que radin.
  </para>
  <para>
  Pour les base de données qui connaissent des &laquo&nbsp;pics&nbsp;&raquo;
  d'activité (rafales d'un million de mises à jour mais pas d'autre
  activité des minutes ou des heures durant), ce nombre peut être 
  impossible à optimiser. Les lignes insérées n'ont pas d'impact
  sur la FSM. Enfin, si le serveur est peu fourni en RAM, augmenter
  cette valeur peut s'avérer contre-productif.
  </para>
  </entry>
 </row>
 <row>
  <entry>max_fsm_relations</entry>
  <entry>10 à Int Max</entry>
  <entry>1000</entry>
  <entry>
  Démarrage
  </entry>
  <entry></entry>
  <entry>
  Positionne le nombre maximum de relations (tables et index) pour
  lesquels l'espace libre est recherché dans la mappe de l'espce libre
  partagé. Chaque connecteur utilise approximativement 50 octets de mémoire.
  </entry>
  <entry>
  Peu d'utilisateurs peuvent avoir besoin d'ajuster ce paramètre, mais il est
  intéressant de le considérer. FSM_relations doit être au moins équivalent
  au nombre de tables dans l'ensemble des bases, bases squelettes et schéma
  système compris. PostgreSQL peut avoir des performances aléatoires 
  si le nombre de FSM_relations est trop faible.
  </entry>
 </row>
 <row>
  <entry>max_stack_depth</entry>
  <entry></entry>
  <entry></entry>
  <entry></entry>
  <entry></entry>
  <entry>
  Indique la profondeur maximale que peut atteindre la pile d'exécution du serveur
  en toute sécurité. Le réglage idéal du parmètre correspond à la limite réelle
  de la pile imposée par le noyau (positionné par ulimit -s ou équivalent), diminué
  d'une marge de sécurité d'un Mo environ. Cette marge de sécurité est nécessaire
  parce que la profondeur de la pile n'est pas vérifiée pour chaque routine du
  serveur, mais uniquement pour les routines potentiellement récursives, telles
  que les évaluations d'expressions. Une valeur plus grande
  que la limite réelle du noyau peut conduire une fonction récursive à
  occasionner un plantage d'un processus serveur. La valeur par défaut de 2048 ko
  (2 Mo) est résolument basse et ne risque pas d'occasionner un plantage. Néanmoins, 
  elle peut s'avérer trop petite pour autoriser l'exécution de fonctions complexes.
  </entry>
  <entry>
  <para>
  La paramètre s'est appelé max_expr_depth, et son unité ne correspondait pas 
  à celle utilisée par la plupart des noyaux systèmes.
  </para>
  <para>
  En cas de dépassement de ce paramètre, un message d'erreur spécifique est
  produit. A ce moment-là, il peut être augmenter
  <emphasis>avec précaution</emphasis>&nbsp;; de nombreux systèmes d'exploitation
  ont des limites aussi basses que 8&nbsp;Mo.
  </para>
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<!-- ICI -->
<sect2>
<title>Kernel Resource Usage</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>max_files_per_process</entry>
  <entry>25 to Int Max</entry>
  <entry>1000</entry>
  <entry>
  Startup
  </entry>
  <entry></entry>
  <entry>
  Sets the maximum number of simultaneously open files
  allowed to each server subprocess. The default is 1000. If the kernel is
  enforcing a safe per-process limit, you don't need to worry about this
  setting. But on some platforms (notably, most BSD systems), the kernel will
  allow individual processes to open many more files than the system can really
  support when a large number of processes all try to open that many files. If
  you find yourself seeing "Too many open files" failures, try reducing this
  setting. This option can only be set at server start.
  </entry>
  <entry>
  Per the docs, mainly used for BSD. Don't bother with it unless you get
  a &#8220;too many files&#8221; message.
  </entry>
 </row>
 <row>
  <entry>preload_libraries</entry>
  <entry>File path</entry>
  <entry>Empty</entry>
  <entry>
  Startup
  </entry>
  <entry></entry>
  <entry>
  <para>
  This variable specifies one or more shared libraries
  that are to be preloaded at server start. A parameterless initialization
  function can optionally be called for each library. To specify that, add a
  colon and the name of the initialization function after the library name. For
  example '$libdir/mylib:mylib_init' would cause mylib to be preloaded and
  mylib_init to be executed. If more than one library is to be loaded, separate
  their names with commas.
  </para>
  <para>
  If a specified library or initialization function is
  not found, the server will fail to start. PostgreSQL procedural language
  libraries may be preloaded in this way, typically by using the syntax
  '$libdir/plXXX:plXXX_init' where XXX is pgsql, perl, tcl, or python.
  </para>
  <para>
  By preloading a shared library (and initializing it if
  applicable), the library startup time is avoided when the library is first
  used. However, the time to start each new server process may increase
  slightly, even if that process never uses the library. So this option is
  recommended only for libraries that will be used in most sessions.
  </para>
  </entry>
  <entry>
  This is only useful for specific specialized database
  purposes. For example, a mapping database might gain some small performance
  by preloading the GIS libraries. For most systems, this is better left alone.
  
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Vacuum Delay</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>vacuum_cost_delay</entry>
  <entry></entry>
  <entry>0</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  The length of time, in milliseconds, that the process will sleep when the cost
  limit has been exceeded. The default value is 0, which disables the cost-based
  vacuum delay feature. Positive values enable cost-based vacuuming. Note that
  on many systems, the effective resolution of sleep delays is 10 milliseconds;
  setting vacuum_cost_delay to a value that is not a multiple of 10 may have the
  same results as setting it to the next higher multiple of 10.
  </entry>
  <entry>
  This setting is extremely valuable when vacuuming large tables which otherwise
  might tie up I/O for long periods or hold locks blocking numerous queries.
  Turning on vacuum delay, essentially, breaks up vacuuming any large table into
  segments defined as specific quantities of work, between which vacuum goes
  to sleep for the time defined in this setting. This has the overall effect of
  increasing the time required to vacuum, possibly by several multiples, but
  reducing the overall system impact of that vacuum, by as much as 85%.
  Reasonable delay settings are between 50ms and 200ms.
  </entry>
 </row>
 <row>
  <entry>vacuum_cost_page_hit</entry>
  <entry></entry>
  <entry>1</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  The estimated cost for vacuuming a buffer found in the shared buffer cache. It
  represents the cost to lock the buffer pool, lookup the shared hash table and
  scan the content of the page.
  </entry>
  <entry>
  This setting should probably be left alone in favor of manipulating
  vacuum_cost_limit.
  </entry>
 </row>
 <row>
  <entry>vacuum_cost_page_miss</entry>
  <entry></entry>
  <entry>10</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  The estimated cost for vacuuming a buffer that has to be read from disk. This
  represents the effort to lock the buffer pool, lookup the shared hash table,
  read the desired block in from the disk and scan its content.
  </entry>
  <entry>
  This setting should probably be left alone in favor of manipulating
  vacuum_cost_limit.
  </entry>
 </row>
 <row>
  <entry>vacuum_cost_page_dirty</entry>
  <entry></entry>
  <entry>20</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  The estimated cost charged when vacuum modifies a block that was previously
  clean. It represents the extra I/O required to flush the dirty block out to
  disk again.
  </entry>
  <entry>
  This setting should probably be left alone in favor of manipulating
  vacuum_cost_limit.
  </entry>
 </row>
 <row>
  <entry>vacuum_cost_limit</entry>
  <entry></entry>
  <entry>200</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  The accumulated cost that will cause the vacuuming process to sleep.
  </entry>
  <entry>
  Lower this in order to break up vacuuming into more "segmentsé. A really
  aggressive combination might be vacuum_cost_delay of 200ms and
  vacuum_cost_limit of 50; this could result in vacuum taking 10 times as long
  with almost no database performance impact. Most DBAs will want to be more
  moderate.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Background Writer</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>bgwriter_delay</entry>
  <entry></entry>
  <entry>200</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Specifies the delay between activity rounds for the background writer. In
  each round the writer issues writes for some number of dirty buffers
  (controllable by the following parameters). The selected buffers will always
  be the least recently used ones among the currently dirty buffers. It then
  sleeps for bgwriter_delay milliseconds, and repeats.
  </entry>
  <entry>
  <para>
  The Background Writer is a new feature, designed to alleviate checkpoint
  spikes.
  </para>
  <para>
  We are still doing testing on bgwriter settings at OSDL; there are no
  recommendations at this time.
  </para>
  </entry>
 </row>
 <row>
  <entry>bgwriter_percent</entry>
  <entry></entry>
  <entry>1</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  In each round, no more than this percentage of the currently dirty buffers
  will be written (rounding up any fraction to the next whole number of
  buffers).
  </entry>
  <entry>
  We are still doing testing on bgwriter settings at OSDL; there are no
  recommendations at this time.
  </entry>
 </row>
 <row>
  <entry>bgwriter_maxpages</entry>
  <entry></entry>
  <entry>100</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  In each round, no more than this many dirty buffers will be written.
  </entry>
  <entry>
  We are still doing testing on bgwriter settings at OSDL; there are no
  recommendations at this time.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>WAL Options</title>

<sect2>
<title>Settings</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>fsync</entry>
  <entry>true, false</entry>
  <entry>true</entry>
  <entry>Startup</entry>
  <entry>-F (off)</entry>
  <entry>
  <para>
  If this option is on, the PostgreSQL backend will use the fsync() system
  call in several places to make sure that updates are physically written to
  disk. This insures that a database installation will recover to a consistent
  state after an operating system or hardware crash.
  </para>
  <para>
  However, using fsync() results in a performance penalty: when a transaction
  is committed, PostgreSQL must wait for the operating system to flush the
  write-ahead log to disk. When fsync is disabled, the operating system is
  allowed to do its best in buffering, ordering, and delaying writes. This can
  result in significantly improved performance. However, if the system crashes,
  the results of the last few committed transactions may be lost in part or
  whole. In the worst case, unrecoverable data corruption may occur. (Crashes
  of the database server itself are not a risk factor here. Only an
  operating-system-level crash creates a risk of corruption.)
  </para>
  </entry>
  <entry>
  <para>
  Turn WAL off (fsync=false) only for a read-only database or one where the
  database can be regenerated from external software. While RAID plus UPSes can
  do a lot to protect your data, turning off fsync means that you
  <emphasis>will</emphasis> be restoring from backup in the event of hardware
  or power failure.
  </para>
  <para>
  On the other hand, WAL imposes significant penalties on database writes,
  especially in single-disk systems. Essentially you are doubling the amount of
  read/write activity required for each update, plus requiring you to disable
  performance-enhancing disk-caching features of your OS and hardware.  So, if
  your data is disposable, turing Fsync off is worth consideration.
  </para>
  <para>
  If WAL is off, the rest of the options in this section are irrelevant.
  </para>
  </entry>
 </row>
 <row>
  <entry>wal_sync_method</entry>
  <entry>fsync, fdatasync, open_sync, open_datasync</entry>
  <entry>Varies by platform</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Method used for forcing WAL updates out to disk. Possible values are
  FSYNC (call fsync() at each commit), FDATASYNC (call fdatasync() at
  each commit), OPEN_SYNC (write WAL files with open() option O_SYNC),
  or OPEN_DATASYNC (write WAL files with open() option O_DSYNC). Not
  all of these choices are available on all platforms.
  </entry>
  <entry>
  The system call used to sync the WAL to disk. Defaults have been
  set for each OS based on OS documentation, but no in-depth
  comparative tests have been posted. It's possible that changing the
  method could improve write speed on your platform, but don't monkey
  with it unless you have the time and resources to run comparative
  and failure tests.
  </entry>
 </row>
 <row>
  <entry>wal_buffers</entry>
  <entry>4 to Int Max</entry>
  <entry>8</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Number of disk-page buffers allocated in shared memory for WAL data. The
  default is 8. The setting need only be large enough to hold the amount of
  WAL data generated by one typical transaction.
  </entry>
  <entry>
  Increasing this parameter has been shown to have minimal effect, even on
  very busy OLTP systems. If you know that you will have very large
  transactions, you may want to increase this just to be safe (to 16 and 64)
  but focus your tuning more on checkpoint_segments.
  </entry>
 </row>
 <row>
  <entry>commit_delay</entry>
  <entry>0 - 100000</entry>
  <entry>0</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Time delay between writing a commit record to the WAL buffer and flushing the
  buffer out to disk, in microseconds. A nonzero delay can allow multiple
  transactions to be committed with only one fsync() system call, if system
  load is high enough that additional transactions become ready to commit within
  the given interval. But the delay is just wasted if no other transactions
  become ready to commit. Therefore, the delay is only performed if at least
  commit_siblings other transactions are active at the instant that a server
  process has written its commit record.
  </entry>
  <entry>
  These two settings are configured together for an environment with a high
  volume of small transactions. When set, they allow a group of otherwise
  unrelated transactions to be flushed to disk at the same time, with possible
  significant performance gain. However, this is a tradeoff against waiting a
  few milliseconds extra on each transaction. If you want to test if this
  improves performance for you, a good starting point is commit_delay of 500
  (½ millisecond).
  </entry>
 </row>
 <row>
  <entry>commit_siblings</entry>
  <entry>1 - 1000</entry>
  <entry>5</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Minimum number of concurrent open transactions to require before performing
  the COMMIT_DELAY delay. A larger value makes it more probable that at least
  one other transaction will become ready to commit during the delay interval.
  </entry>
  <entry>
  If using commit_delay, you'll want to vary this setting depending on the
  average length of a transaction in your system. If transactions are very
  short (simple 1-row update/insert statements) then you'll want a low setting
  as simultaneous commit is probable; if some transactions are longer, you'll
  want to raise it to avoid unnecessary use of the commit_delay.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Checkpoints</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>checkpoint_segments</entry>
  <entry>1 to Int Max</entry>
  <entry>3</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Maximum distance between automatic WAL checkpoints, in log file segments
  (each segment is normally 16 megabytes).
  </entry>
  <entry>
  This is the most effective setting for dealing with large updates, data
  loading, and heavy OLTP activity. For any system with heavy write activity,
  you'll want to raise this to at least 8; on systems with very large write
  loads (such as loads of several GB of data), as much as 128 (and we've used
  256 for DBT2 testing). However, this does require a significant amount of
  disk space for the xlog ( ( 2  x segments  + 1 )  x 16mb, to be precise),
  and is a limited improvement if your xlog is not on a separate disk resource
  from the data.
  </entry>
 </row>
 <row>
  <entry>checkpoint_timeout</entry>
  <entry>30 to 3600</entry>
  <entry>300</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Maximum time between automatic WAL checkpoints, in seconds.
  </entry>
  <entry>
  Increase this setting dramatically (up to 30 minutes) for large data loads.
  For other purposes, settings between 3min and 10min is the useful range; use
  higher settings for write activity which comes in bursts. Increasing
  checkpoint timeouts is currently limited by the increased impact that disk
  sync has with longer times.
  </entry>
 </row>
 <row>
  <entry>checkpoint_warning</entry>
  <entry>0 to Int Max</entry>
  <entry>0</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Send a message to the server logs if checkpoints caused by the filling of
  checkpoint segment files happens more frequently than this number of
  seconds. Zero turns off the warning.
  </entry>
  <entry>
  Useful for detecting if checkpoint_segments needs to be increased. Turn it on
  during development periods and scan the log for warnings; several of them
  generally means an increase is warranted.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Archiving</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>archive_command</entry>
  <entry>shell command</entry>
  <entry>''</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  <para>
  The shell command to execute to archive a completed segment of the WAL file
  series. If this is an empty string (the default), WAL archiving is disabled.
  Any %p in the string is replaced by the absolute path of the file to archive,
  and any %f is replaced by the file name only. Use %% to embed an actual %
  character in the command. For more information see Section 22.3.1.
  </para>
  <para>
  It is important for the command to return a zero exit status if and only if
  it succeeds.
  </para>
  </entry>
  <entry>
  This setting turns on the new Point In Time Recovery feature by providing a
  shell command to archive (copy) completed WAL segments to another location.
  See discussion on backup and recovery for further information on how to use
  this.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Query Tuning</title>

<sect2>
<title>Planner Methods</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para>enable_hashagg</para>
  <para>enable_hashjoin</para>
  <para>enable_indexscan</para>
  <para>enable_mergejoin</para>
  <para>enable_nestloop</para>
  <para>enable_seqscan</para>
  <para>enable_sort</para>
  <para>enable_tidscan</para>
  </entry>
  <entry>true, false</entry>
  <entry>true</entry>
  <entry>Runtime</entry>
  <entry>
  <para></para>
  <para>-fi</para>
  <para>-fm</para>
  <para>-fn</para>
  <para>-fs</para>
  <para></para>
  <para>-ft*</para>
  <para></para>
  </entry>
  <entry>
  Enables or disables the query planner's use of the respective plan types.
  The default is on. This is used for debugging the query planner.
  </entry>
  <entry>
  <para>
  These options are pretty much only for use in query testing; frequently one
  sets &#8220;enable_seqscan = false&#8221; in order to determine if the
  planner is unnecessarily discarding an index, for example. However,
  it would require very unusual circumstances to change any of them to false in
  the .conf file. In fact, if you find yourself doing so, then there are probably
  other query tuning settings you've overlooked and should be modifying instead.
  </para>
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Planner Cost Constants</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>effective_cache_size</entry>
  <entry>0 to Double</entry>
  <entry>1000</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Sets the optimizer's assumption about the effective size of the disk cache
  (that is, the portion of the kernel's disk cache that will be used for
  PostgreSQL data files). This is measured in disk pages, which are normally
  8 kB each.
  </entry>
  <entry>
  Primarily set the planner's estimates of the relative likelihood of a
  particular table or index being in memory, and will thus have a significant
  effect on whether the planner chooses indexes over seqscans, as well as a few
  other query structures.  As such, should be set to about 2/3 of your available
  RAM to ensure that the planner is adequately informed.  Many times, DBAs
  wanting to turn enable_seqscan off need to change this setting instead.
  </entry>
 </row>
 <row>
  <entry>
  <para>random_page_cost</para>
  </entry>
  <entry>0 to Double</entry>
  <entry>4</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Sets the planner's estimate of the cost of a nonsequentially fetched disk
  page. This is measured as a multiple of the cost of a sequential page fetch.
  A higher value makes it more likely a sequential scan will be used, a lower
  value makes it more likely an index scan will be used.
  </entry>
  <entry>
  <para>
  Useful values of this setting range between 2.0 and 4.0, the lower for a fast
  CPU, fast I/O, and a database that fits completely in RAM, and higher if your
  CPU or disk bandwidth are taxed, or if your main tables and their indexes are
  several times larger than available RAM. Do not ever set this lower than 1.5;
  if query problems seem to indicate doing so, then there are probably other
  settings (like effective_cache_size) that need adjustment.
  </para>
  <para>
  When testing the effect of different settings, remember to test a variety of
  queries from your workload, and not just one problem query.
  </para>
  </entry>
 </row>
 <row>
  <entry>
  <para>cpu_tuple_cost</para>
  <para>cpu_index_tuple_cost</para>
  <para>cpu_operator_cost</para>
  </entry>
  <entry>0 to Double</entry>
  <entry>
  <para>0.01</para>
  <para>0.001</para>
  <para>0.0025</para>
  </entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Sets the query optimizer's estimate of the CPU cost of processing each tuple,
  index lookup, and where clause item (respectively) during a query. This is
  measured as a fraction of the cost of a sequential page fetch.
  </entry>
  <entry>
  These default costs are fairly arbitrary, which is why they are available as
  adjustable settings.  However, no-one in the community has been able to
  convincingly demonstrate better cost defaults, and more often changes have an
  adverse effect on some queries.  So unless you have a great deal of time for
  query testing, it's better to leave these three settings alone.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Genetic Estimate Query Optimizer</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>geqo</entry>
  <entry>true, false</entry>
  <entry>true</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Enables or disables genetic query optimization, which is an algorithm that
  attempts to do query planning without exhaustive searching. This is on by
  default. See also the various other GEQO_ settings.
  </entry>
  <entry>
  <para>
  GEQO was introduced in PostgreSQL 6.5 as a way of dealing with join
  optimization queries with too many tables for an exhaustive analysis by the
  planner. It's important to realize that GEQO queries will, as a rule, be
  slower to execute than regular queries. It's designed to kick in when
  otherwise query planning would swamp your CPU.
  </para>
  <para>
  If you find that your application is making use of GEQO a lot, it's probably
  advisable to start writing queries with an explicit join order, as you can
  exercise more discrimination than the algorithm.
  </para>
  </entry>
 </row>
 <row>
  <entry>geqo_threshold</entry>
  <entry>2 to Int Max</entry>
  <entry>11</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Use genetic query optimization to plan queries with at least this many FROM
  items involved. (Note that a JOIN construct counts as only one FROM item.)
  The default is 11. For simpler queries it is usually best to use the
  deterministic, exhaustive planner. This parameter also controls how hard
  the optimizer will try to merge subquery FROM clauses into the upper query.
  </entry>
  <entry>
  It's possible that, on machines with very fast CPUs (dual Opteron, for
  example) raising this threshold slightly (such as to 14) is warranted.
  However, previous advice to raise it to 20 turned out to be based on an
  unusual test case and has since been disproven.
  </entry>
 </row>
 <row>
  <entry>
  <para>geqo_selection_bias</para>
  <para>geqo_pool_size</para>
  <para>geqo_effort</para>
  <para>geqo_generations</para>
  <para>geqo_random_seed</para>
  </entry>
  <entry>1.5-2.0</entry>
  <entry>
  <para>2.0</para>
  <para>0</para>
  <para>1</para>
  <para>0</para>
  <para>-1</para>
  </entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Various tuning parameters for the genetic query optimization algorithm: The
  pool size is the number of individuals in one population. Valid values are
  between 128 and 1024. If it is set to 0 (the default) a pool size of
  2^(QS+1), where QS is the number of FROM items in the query, is taken. The
  effort is used to calculate a default for generations. Valid values are
  between 1 and 80, 40 being the default. Generations specifies the number of
  iterations in the algorithm. The number must be a positive integer. If 0 is
  specified then Effort * Log2(PoolSize) is used. The run time of the algorithm
  is roughly proportional to the sum of pool size and generations. The
  selection bias is the selective pressure within the population. Values can be
  from 1.50 to 2.00; the latter is the default. The random seed can be set to
  get reproducible results from the algorithm. If it is set to -1 then the
  algorithm behaves non-deterministically.
  </entry>
  <entry></entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Other Query Modifiers</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>default_statistics_target</entry>
  <entry>1-1000</entry>
  <entry>10</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Sets the default statistics target for table columns that have not had a
  column-specific target set via ALTER TABLE SET STATISTICS. Larger values
  increase the time needed to do ANALYZE, but may improve the quality of the
  planner's estimates.
  </entry>
  <entry>
  Has no effect until your next ANALYZE.  Generally not recommended as a way of
  improving statistics overall except for unusual databases; for one thing,
  collecting increased statistics on wide columns (large text, for example) can
  be burdensome enough to be counter-productive.  For a database which is
  almost entirely numerical, modest increases (to 100, for example) may have
  overall benefit; otherwise, try increasing statistics on specific columns.
  </entry>
 </row>
 <row>
  <entry>from_collapse_limit</entry>
  <entry>0 to Int Max</entry>
  <entry>8</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  The planner will merge sub-queries into upper queries if the resulting FROM
  list would have no more than this many items. Smaller values reduce planning
  time but may yield inferior query plans. The default is 8. It is usually
  wise to keep this less than GEQO_THRESHOLD.
  </entry>
  <entry>
  As with many other settings in this section, you want only to change this for
  specific unfixable queries at runtime.  Decreasing it should force
  materialization of some subqueries if that is desired.  Most DBAs won't want
  to change it at all.
  </entry>
 </row>
 <row>
  <entry>join_collapse_limit</entry>
  <entry>1 to Int Max</entry>
  <entry>8</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  The planner will flatten explicit inner JOIN constructs into lists of FROM
  items whenever a list of no more than this many items would result. Usually
  this is set the same as FROM_COLLAPSE_LIMIT. Setting it to 1 prevents any
  flattening of inner JOINs, allowing explicit JOIN syntax to be used to
  control the join order. Intermediate values might be useful to trade off
  planning time against quality of plan.
  </entry>
  <entry>
  This option is designed for those of us who like writing our queries using
  explicit JOIN syntax (e.g. &#8220;a join b using (1) join c using (2)&#8221;),
  but would still like the planner to select the join order for best execution.
  Particularly, people switching from MS SQL Server will want to enable this
  option with a moderately high value, as that database does JOIN collapsing
  automatically. As above, keep this setting below geqo_threshold.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Logging and Debugging Options</title>

<sect2>
<title>Where To Log</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>log_destination</entry>
  <entry>stderr, syslog, eventlog</entry>
  <entry>stderr</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  PostgreSQL supports several methods for logging server messages, including
  stderr and syslog. On Windows, eventlog is also supported. Set this option
  to a list of desired log destinations separated by commas.
  </entry>
  <entry>
  This is analogous to the old â&#8364;&#339;syslogâ&#8364;&#157; setting, but
  with the cryptic codes removed. Also supports the Win32 â&#8364;&#339;eventlogâ&#8364;&#157;.
  When setting up your server, it's important to decide how you want to log
  PostgreSQL messages: either to syslog, which is easier for overall system
  administration, or to a private PostgreSQL log, which is better for debugging
  database problems. Of course, you can log to both, but that's probably an
  excess of output.
  </entry>
 </row>
 <row>
  <entry>redirect_stderr</entry>
  <entry></entry>
  <entry></entry>
  <entry></entry>
  <entry></entry>
  <entry>
  This option allows messages sent to stderr to be captured and redirected into
  log files. This option, in combination with logging to stderr, is often more
  useful than logging to syslog, since some types of messages may not appear in
  syslog output (a common example is dynamic-linker failure messages).
  </entry>
  <entry>
  This is the new â&#8364;&#339;log rotationâ&#8364;&#157; feature. It also
  replaces the -l command line switch for pg_ctl, and/or command-line redirect.
  It is only applicable if you chose â&#8364;&#339;stderrâ&#8364;&#157; above,
  and the following 5 options only take effect if you choose this one. You can
  use redirect_stderr and turn rotation off in order to have create the same
  effect as the old -l option.
  </entry>
 </row>
 <row>
  <entry>log_directory</entry>
  <entry>directory</entry>
  <entry>pg_log</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  When redirect_stderr is enabled, this option determines the directory in
  which log files will be created. It may be specified as an absolute path,
  or relative to the cluster data directory.
  </entry>
  <entry>
  Defaults to a â&#8364;&#339;pg_logâ&#8364;&#157; directory in your PGDATA,
  which is probably not a wise choice if you have other disks/arrays available.
  /var/pg_log is popular.
  </entry>
 </row>
 <row>
  <entry>log_filename</entry>
  <entry>special</entry>
  <entry>postgresql-%Y-%m-%d_%H%M%S.log</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  When redirect_stderr is enabled, this option sets the file names of the
  created log files. The value is treated as a strftime pattern, so
  %-escapes can be used to specify time-varying file names. If no
  %-escapes are present, PostgreSQL will append the epoch of the new log file's
  open time. For example, if log_filename were server_log, then the chosen file
  name would be server_log.1093827753 for a log starting at Sun Aug 29 19:02:33
  2004 MST.</entry>
  <entry>
  File name for each rotational log segment, with escapes. The default should
  suit most DBAs.  If your logs never go over size, it can be simpler to
  include only the date.  Another possible variation is to have the log record
  only the hour, or only the day of the week, in order to prevent getting more
  than a certain number of logs.  See log_truncate below.
  </entry>
 </row>
 <row>
  <entry>log_rotation_age</entry>
  <entry>0 to Int Max</entry>
  <entry>1440</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  When redirect_stderr is enabled, this option determines the maximum lifetime
  of an individual log file. After this many minutes have elapsed, a new log
  file will be created. Set to zero to disable time-based creation of new log
  files.
  </entry>
  <entry>
  The default (24 hours) is suitable for most installations.
  </entry>
 </row>
 <row>
  <entry>log_rotation_size</entry>
  <entry>0 to Int Max</entry>
  <entry>10240</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  When redirect_stderr is enabled, this option determines the maximum size of
  an individual log file. After this many kilobytes have been emitted into a
  log file, a new log file will be created. Set to zero to disable size-based
  creation of new log files.
  </entry>
  <entry>
  The default (10MB) is suitable for most installations.
  </entry>
 </row>
 <row>
  <entry>log_truncate_on_rotation</entry>
  <entry>True, False</entry>
  <entry>False</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  When redirect_stderr is enabled, this option will cause PostgreSQL to truncate
  (overwrite), rather than append to, any existing log file of the same name.
  However, truncation will occur only when a new file is being opened due to
  time-based rotation, not during server startup or size-based rotation. When
  false, pre-existing files will be appended to in all cases. For example,
  using this option in combination with a log_filename like postgresql-%H.log
  would result in generating twenty-four hourly log files and then cyclically
  overwriting them.
  </entry>
  <entry>
  This setting can be combined with log_filename, above, to create a 7-day or
  24-hour (or 60-minute, for that matter) continuous replacement of logs.
  </entry>
 </row>
 <row>
  <entry>syslog_facility</entry>
  <entry>LOCAL#</entry>
  <entry>LOCAL0</entry>
  <entry></entry>
  <entry>Startup</entry>
  <entry>
  When logging to syslog is enabled, this option determines the syslog "facility"
  to be used. You may choose from LOCAL0, LOCAL1, LOCAL2, LOCAL3, LOCAL4, LOCAL5,
  LOCAL6, LOCAL7; the default is LOCAL0. See also the documentation of your
  system's syslog daemon.
  </entry>
  <entry>
  No recommendations.
  </entry>
 </row>
 <row>
  <entry>syslog_ident</entry>
  <entry></entry>
  <entry>postgres</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  When logging to syslog is enabled, this option determines the program name
  used to identify PostgreSQL messages in syslog logs. The default is postgres.
  </entry>
  <entry>
  Those running multiple versions of PostgreSQL on the same machine will want
  to remember to change this string to indicate which server.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>When to Log</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para>client_min_messages</para>
  <para>log_min_messages</para>
  <para>log_min_error_statement</para>
  </entry>
  <entry>
  debug5, debug4, debug3, debug2, debug1,
  info, notice, warning, error, log, fatal, panic
  </entry>
  <entry>
  <para>notice</para>
  <para>notice</para>
  <para>panic</para>
  </entry>
  <entry>
  <para>Runtime</para>
  <para>Superuser</para>
  <para>Superuser</para>
  </entry>
  <entry>-d x</entry>
  <entry>
  <para>
  This controls how much message detail is written to the server logs and the
  client. Valid values are DEBUG5, DEBUG4, DEBUG3, DEBUG2, DEBUG1, INFO,
  NOTICE, WARNING, ERROR, LOG, FATAL, and PANIC. Later values send less detail
  to the logs. The default is NOTICE. Note that LOG has a different precedence
  here than in CLIENT_MIN_MESSAGES.
  </para>
  <para>
  client_min_messages outputs to the client session; log_min_messages to the
  log, and log_min_error_statement controls recording of SQL errors to the log.
  </para>
  </entry>
  <entry>
  <para>
  Raising debug levels is always good for testing applications; DEBUG1 is a good
  setting for general troubleshooting.  NOTICE is suitable for general
  production, and thourougly tested systems can probably be reduced to ERROR or
  even FATAL.
  </para>
  <para>
  The cost is greater use of disk space, some minor performance cost for output
  (usually &lt; 5%). However, the performance cost increases significantly if
  your logs are on the same disk/array as WAL or your database, as heavy debug
  output will take I/O away from database activity. The impact of debug5 on a
  high-transaction single-disk system can be quite high.  This caution applys
  to all of the loggin options below.
  </para>
  </entry>
 </row>
 <row>
  <entry>log_error_verbosity</entry>
  <entry>terse, default, verbose</entry>
  <entry>default</entry>
  <entry>Superuser</entry>
  <entry></entry>
  <entry>
  Controls the amount of detail written in the server log for each message
  that is logged. Valid values are TERSE, DEFAULT, and VERBOSE, each adding
  more fields to displayed messages.
  </entry>
  <entry>
  What setting you use here depends on your production status, and what
  log-monitoring tools you are using.
  </entry>
 </row>
 <row>
  <entry>log_min_duration_statement</entry>
  <entry>-1 to Int Max</entry>
  <entry>-1</entry>
  <entry>Superuser</entry>
  <entry></entry>
  <entry>
  Sets a minimum statement execution time (in milliseconds) that causes a
  statement to be logged. All SQL statements that run for the time specified
  or longer will be logged with their duration. Setting this to zero will
  print all queries and their durations. Minus-one (the default) disables the
  feature. For example, if you set it to 250 then all SQL statements that run
  250ms or longer will be logged. Enabling this option can be useful in tracking
  down unoptimized queries in your applications.
  </entry>
  <entry>
  This setting is extremely useful for second-stage database tuning. Once
  you've taken care the bulk of the indexing and performance issues,
  log_min_duration_statement will allow you to log only the slowest (and
  possibly still broken) queries.
  </entry>
 </row>
 <row>
  <entry>silent_mode</entry>
  <entry>True, False</entry>
  <entry>False</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Runs the server silently. If this option is set, the server will automatically
  run in background and any controlling terminals are disassociated (same effect
  as postmaster's -S option). The server's standard output and standard error
  are redirected to /dev/null, so any messages sent to them will be lost. Unless
  syslog logging is selected or redirect_stderr is enabled, using this option is
  discouraged because it makes it impossible to see error messages.
  </entry>
  <entry>
  The documentation pretty much covers it.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>What to Log</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para>debug_print_parse</para>
  <para>debug_print_rewritten</para>
  <para>debug_print_plan</para>
  <para>debug_pretty_print</para>
  </entry>
  <entry>true, false</entry>
  <entry>false</entry>
  <entry></entry>
  <entry></entry>
  <entry>
  These flags enable various debugging output to be sent to the server log. For
  each executed query, print either the query text, the resulting parse tree,
  the query rewriter output, or the execution plan. DEBUG_PRETTY_PRINT indents
  these displays to produce a more readable but much longer output format.
  </entry>
  <entry>
  Can be useful for detecting common slow queries if you are able to wade
  through the voluminous log output. Particularly useful in interactive log
  watching when procedures hang; you can sometimes see exactly what step
  hangs (sometimes you can't, though, because the log waits on the database).
  </entry>
 </row>
 <row>
  <entry>
  <para>log_connections</para>
  <para>log_disconnections</para>
  </entry>
  <entry>true, false</entry>
  <entry>false</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  log_connections outputs a line to the server log detailing each successful
  connection. log_disconnections outputs a line in the server log similar to
  log_connections but at session termination, and includes the duration of the
  session.
  </entry>
  <entry>
  Essential logging items for any secure application.
  </entry>
 </row>
 <row>
  <entry>log_hostname</entry>
  <entry>true, false</entry>
  <entry>false</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  By default, connection logs only show the IP address of the connecting host.
  If you want it to show the host name you can turn this on, but depending on
  your host name resolution setup it might impose a non-negligible performance
  penalty.
  </entry>
  <entry>
  This can be useful for debugging/security management, but if DNS is not local
  can delay new connections significantly.
  </entry>
 </row>
 <row>
  <entry>log_statement</entry>
  <entry>None, DDL, Mod, All</entry>
  <entry>False</entry>
  <entry>Superuser</entry>
  <entry></entry>
  <entry>
  Controls which SQL statements are logged. Valid values are none, ddl, mod,
  and all. ddl logs all data definition commands like CREATE, ALTER, and DROP
  commands. mod logs all ddl statements, plus INSERT, UPDATE, DELETE, TRUNCATE,
  and COPY FROM. PREPARE and EXPLAIN ANALYZE statements are also logged if
  their contained command is of an appropriate type.
  </entry>
  <entry>
  This setting has been improved and expanded by the ability to log only
  database changes, or only updates/inserts/deletes. Please see also the
  limitations on this feature, mentioned in the docs.
  </entry>
 </row>
 <row>
  <entry>log_duration</entry>
  <entry>True, False</entry>
  <entry>False</entry>
  <entry>Superuser</entry>
  <entry></entry>
  <entry>
  Causes the duration of every completed statement which satisfies
  log_statement to be logged. When using this option, if you are not using
  syslog, it is recommended that you log the PID or session ID using
  log_line_prefix so that you can link the statement to the duration using
  the process ID or session ID.
  </entry>
  <entry>
  Essential to first-state database tuning. The PQA log digest utility, for
  example, requires log_statement and log_duration options to supply you with
  a list of the slowest and the most frequent queries. Only takes effect if
  log_statement is at least â&#8364;&#339;DDLâ&#8364;&#157;.
  </entry>
 </row>
 <row>
  <entry>log_line_prefix</entry>
  <entry>Special</entry>
  <entry>''</entry>
  <entry>Superuser</entry>
  <entry></entry>
  <entry>
  This is a printf-style string that is output at the beginning of each log
  line. The default is an empty string. Each recognized escape is replaced as
  outlined in the docs - anything else that looks like an escape is ignored.
  Other characters are copied straight to the log line. Some escapes are only
  recognized by session processes, and do not apply to background processes
  such as the postmaster. Syslog produces its own time stamp and process ID
  information, so you probably do not want to use those escapes if you are
  using syslog.
  </entry>
  <entry>
  <para>
  Replaces log_pid, log_source_port, log_timestamp, and a host of home-grown
  logging techniques to supply exactly the detail wanted with each log line.
  </para>
  <para>
  For example, if you were trying to diagnose a deadlocking problem, you might
  use  â&#8364;&#339;%t %p %u %d %xâ&#8364;&#157; to give you the information
  you need. No doubt in the future log tools will develop which expect specific
  formats for these, but none exist yet.
  </para>
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Statistics</title>

<sect2>
<title>Statistics Logging</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para>log_parser_stats</para>
  <para>log_planner_stats</para>
  <para>log_executor_stats</para>
  <para>log_statement_stats</para>
  </entry>
  <entry>true, false</entry>
  <entry>false</entry>
  <entry>Superuser</entry>
  <entry>
  <para>-tpa</para>
  <para>-tpl</para>
  <para>-te</para>
  <para>-s</para>
  </entry>
  <entry>
  For each query, write performance statistics of the respective module to the
  server log. This is a crude profiling instrument. log_statement_stats reports
  total statement statistics, while the others report per-state statistics.
  log_statement_stats can not be enabled with the other options. All of these
  options are disabled by default. Only superusers can turn off any of these
  options if they have been enabled by the administrator.
  </entry>
  <entry>
  Unless you have a serious log-crunching tool designed to crunch this
  information it's of limited usefulness due to sheer volume.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Query and Index Statistics</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>stats_start_collector</entry>
  <entry>true, false</entry>
  <entry>true</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Controls whether the server should start the statistics-collection subprocess.
  </entry>
  <entry>
  Unless the 5% or so overhead created by the statistics collector is critical
  for your system, you should turn on at least start_collector and
  stats_command_string.
  </entry>
 </row>
 <row>
  <entry>stats_reset_on_server_start</entry>
  <entry></entry>
  <entry>True</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  If on, collected statistics are zeroed out whenever the server is restarted.
  If off, statistics are accumulated across server restarts.
  </entry>
  <entry>
  If routine database restarts are part of your maintenance plan, then you
  probably want to turn this off or you'll have difficulty accumulating enough
  statistics to be useful.  Otherwise, leave it on.
  </entry>
 </row>
 <row>
  <entry>stats_command_string</entry>
  <entry></entry>
  <entry>False</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Enables the collection of statistics on the currently executing command of
  each session, along with the time at which that command began execution.
  This option is off by default. Note that even when enabled, this information
  is not visible to all users, only to superusers and the user owning the
  session being reported on; so it should not represent a security risk. This
  data can be accessed via the pg_stat_activity system view.
  </entry>
  <entry>
  This allows you to use pg_stat_activity view to track current queries, which
  can be invaluable for troubleshooting.  Most DBAs will want this on.
  </entry>
 </row>
 <row>
  <entry>stats_row_level</entry>
  <entry></entry>
  <entry>False</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Enables the collection of row-level statistics on database activity. This
  option is disabled by default. If this option is enabled, the data that
  is produced can be accessed via the pg_stat and pg_statio family of system
  views.
  </entry>
  <entry>
  This option enables the collection of some statistics on index and table use.
  Vitally important during initial database tuning, it becomes less useful in
  production and should probably be turned off then.
  </entry>
 </row>
 <row>
  <entry>stats_block_level</entry>
  <entry></entry>
  <entry>False</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Enables the collection of block-level statistics on database activity. This
  option is disabled by default.
  </entry>
  <entry>
  Gives block-level stats, which are useful in monitoring I/O and cache hit
  performance for turning system variables and hardware. Again, turn it on
  during system testing, and back off in production.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Client Connection Defaults</title>

<sect2>
<title>Statement Behavior</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>search_path</entry>
  <entry>path</entry>
  <entry>'$user,public'</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  <para>
  This variable specifies the order in which schemas are searched when an
  object (table, data type, function, etc.) is referenced by a simple name
  with no schema component. When there are objects of identical names in
  different schemas, the one found first in the search path is used. An object
  that is not in any of the schemas in the search path can only be referenced
  by specifying its containing schema with a qualified (dotted) name.
  </para>
  <para>
  The value for search_path has to be a comma-separated list of schema names.
  If one of the list items is the special value $user, then the schema having
  the name returned by SESSION_USER is substituted, if there is such a schema.
  (If not, $user is ignored.) The system catalog schema, pg_catalog, is always
  searched, whether it is mentioned in the path or not.
  </para>
  </entry>
  <entry>
  <para>
  This is a variable to manipulate after you have the schema design for your
  database, but not necessarily in this file.  For example, you may with to
  set search_path by user, which is done through ALTER USER and not through
  this GUC.
  </para>
  <para>
  On the other hand, if you are using multiple schema which should be visible
  to all users, remember to add the additional schema to the search_path in
  postgresql.conf.
  </para>
  </entry>
 </row>
 <row>
  <entry>default_tablespace</entry>
  <entry></entry>
  <entry>''</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  This variable specifies the default tablespace in which to create objects
  (tables and indexes) when a CREATE command does not explicitly specify a
  tablespace.  The value is either the name of a tablespace, or an empty string
  to specify using the default tablespace of the current database. If the value
  does not match the name of any existing tablespace, PostgreSQL will
  automatically use the default tablespace of the current database.
  </entry>
  <entry>
  It is unlikely that you will want to set this in the .conf file; see ALTER
  DATABASE instead.
  </entry>
 </row>
 <row>
  <entry>check_function_bodies</entry>
  <entry>True, False</entry>
  <entry>True</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  This parameter is normally true. When set to false, it disables validation of
  the function body string during CREATE FUNCTION. Disabling validation is
  occasionally useful to avoid problems such as forward references when
  restoring function definitions from a dump.
  </entry>
  <entry>
  As with the others, not to be set in the .conf file for general purposes.
  </entry>
 </row>
 <row>
  <entry>default_transaction_isolation</entry>
  <entry>read committed, serializable</entry>
  <entry>'read committed'</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Each SQL transaction has an isolation level, which can be either "read
  uncommitted", "read committed", "repeatable read", or "serializable". This
  parameter controls the default isolation level of each new transaction. The
  default is "read committed".
  </entry>
  <entry>
  The default, here, is the value that supports standard MVCC behavior.
  â&#8364;&#339;Serializableâ&#8364;&#157; is mainly useful for when you need
  to launch long-running procedures which must be successive, or when your
  updates pose a significant and regular risk of deadlock. Under a heavy
  multi-user load, setting â&#8364;&#339;serializableâ&#8364;&#157; can impose
  a significant penalty as numerous transactions are forced to wait for the
  serialized transaction to complete. In a single-user database, there should
  be little effect.  In any case, not to be set in the .conf file but rather at
  runtime.
  </entry>
 </row>
 <row>
  <entry>default_transaction_read_only</entry>
  <entry>true, false</entry>
  <entry>false</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  A read-only SQL transaction cannot alter non-temporary tables. This parameter
  controls the default read-only status of each new transaction. The default is
  false (read/write).
  </entry>
  <entry>
  Potentially useful for individual connections, but not as useful to set in
  .conf file, unless you want to force a lot of users into read-only mode (and
  assume that they don't know how to use SET commands).
  </entry>
 </row>
 <row>
  <entry>statement_timeout</entry>
  <entry>0 to Int Max</entry>
  <entry>0</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Aborts any statement that takes over the specified number of milliseconds.
  A value of zero turns off the timer.
  </entry>
  <entry>
  Designed to help the application where it is possible to users to execute
  queries that swamp the CPU for minutes, such as apps that allow dynamic
  queries. Setting this value to a finite amount can prevent those users from
  monopolizing resources, but you'll need to be prepared to deal with the
  exception, which is the same error as â&#8364;&#339;query cancelled by
  userâ&#8364;&#157;.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Locale and Formatting</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>
  <para>datestyle</para>
  <para>timezone</para>
  <para>australian_timezones</para>
  </entry>
  <entry></entry>
  <entry>
  <para>'iso, us'</para>
  <para>unknown</para>
  <para>false</para>
  </entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  <para>
  Sets the display format for dates, as well as the rules for interpreting
  ambiguous input dates.
  </para>
  <para>
  Sets the time zone for displaying and interpreting timestamps. The default
  is to use whatever the system environment specifies as the time zone.
  </para>
  <para>
  If set to true, CST, EST, and SAT are interpreted as Australian time zones
  rather than as North American Central/Eastern time zones and Saturday.
  </para>
  </entry>
  <entry>
  For changing the default display of dates and interpretation of timezones to
  suit your locality and/or organization standards.
  </entry>
 </row>
 <row>
  <entry>extra_float_digits</entry>
  <entry>-14 to 2</entry>
  <entry>0</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  This parameter adjusts the number of digits displayed for floating-point
  values, including float4, float8, and geometric data types. The parameter
  value is added to the standard number of digits (FLT_DIG or DBL_DIG as
  appropriate). The value can be set as high as 2, to include
  partially-significant digits; this is especially useful for dumping float
  data that needs to be restored exactly. Or it can be set negative to suppress
  unwanted digits.
  </entry>
  <entry></entry>
 </row>
 <row>
  <entry>
  <para>lc_messages</para>
  <para>lc_monetary</para>
  <para>lc_time</para>
  <para>lc_numeric</para>
  </entry>
  <entry>System-dependent</entry>
  <entry>Special</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  Sets the locale to use for formatting error messages, monetary amounts, time
  and numeric values. Acceptable values are system-dependent; see Section 7.1
  for more information. If this variable is set to the empty string (which is
  the default) then the value is inherited from the execution environment of
  the server in a system-dependent way.
  </entry>
  <entry>
  These settings are set by the initdb script when it creates your PGDATA
  directory. Should be set to your language, currency, etc, or 'C'
  locale for some installations.
  </entry>
 </row>
 <row>
  <entry>client_encoding</entry>
  <entry>OS-dependent</entry>
  <entry>sql_ascii</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  Sets the client-side encoding for multi-byte character sets. The default is
  to use the database encoding.
  </entry>
  <entry>
  Usually ignored in favor of database encoding. Would be set per client only
  for multi-lingual applications, which would then require considerable care to
  manage the different encodings.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Other Defaults</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>explain_pretty_print</entry>
  <entry>True,False</entry>
  <entry>False</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Determines whether EXPLAIN VERBOSE uses the indented or non-indented format
  for displaying detailed query-tree dumps.
  </entry>
  <entry>
  If you need to use EXPLAIN VERBOSE, pretty_print is essential for readability;
  set it to True. It's a rare occasion where VERBOSE is needed, though.
  </entry>
 </row>
 <row>
  <entry>dynamic_library_path</entry>
  <entry>path</entry>
  <entry>'$libdir'</entry>
  <entry>Superuser</entry>
  <entry></entry>
  <entry>
  If a dynamically loadable module needs to be opened and the specified name
  does not have a directory component (i.e. the name does not contain a slash),
  the system will search this path for the specified file. (The name that is
  used is the name specified in the CREATE FUNCTION or LOAD command.)
  </entry>
  <entry>
  Can be SET by superuser.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Lock Management</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>deadlock_timeout</entry>
  <entry>1 to Int Max</entry>
  <entry>1000</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  This is the amount of time, in milliseconds, to wait on a lock before
  checking to see if there is a deadlock condition. The check for deadlock is
  relatively slow, so the server doesn't run it every time it waits for a lock.
  We (optimistically?) assume that deadlocks are not common in production
  applications and just wait on the lock for a while before starting check for
  a deadlock. Increasing this value reduces the amount of time wasted in
  needless deadlock checks, but slows down reporting of real deadlock errors.
  The default is 1000 (i.e., one second), which is probably about the smallest
  value you would want in practice. On a heavily loaded server you might want
  to raise it. Ideally the setting should exceed your typical transaction time,
  so as to improve the odds that the lock will be released before the waiter
  decides to check for deadlock.
  </entry>
  <entry>
  No recommendations aside from those in the documentation.
  </entry>
 </row>
 <row>
  <entry>max_locks_per_transaction</entry>
  <entry>10 to Int Max</entry>
  <entry>64</entry>
  <entry>No</entry>
  <entry></entry>
  <entry>
  The shared lock table is sized on the assumption that at most
  max_locks_per_transaction * max_connections distinct objects will need to be
  locked at any one time. The default, 64, which has historically proven
  sufficient, but you might need to raise this value if you have clients that
  touch many different tables in a single transaction. This option can only be
  set at server start.
  </entry>
  <entry>
  Occasionally it can be necessary to raise this parameter in star-schema
  database with hundreds of lookup tables. It's better to act in response to
  the error, though, than to anticipate.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

<sect1>
<title>Version and Platform Compatibility</title>

<sect2>
<title>Previous PostgreSQL Versions</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>add_missing_from</entry>
  <entry>true, false</entry>
  <entry>true</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  Enables planner to â&#8364;&#339;Add Missing From Clauseâ&#8364;&#157; when
  you omit a table from your query. Will be False by default in future versions.
  When true, tables that are referenced by a query will be automatically added
  to the FROM clause if not already present. The default is true for
  compatibility with previous releases of PostgreSQL. However, this behavior is
  not SQL-standard, and many people dislike it because it can mask mistakes
  (such as referencing a table where you should have referenced its alias).
  Set to false for the SQL-standard behavior of rejecting references to tables
  that are not listed in FROM.
  </entry>
  <entry>
  Always set this to false.  If it's set to true, a simple mis-reference of a
  table alias can result in an unconstrained join, and a runaway query that
  will soak up your system resources.  This will hopefully be false by default
  in the future.
  </entry>
 </row>
 <row>
  <entry>regex_flavor</entry>
  <entry>advanced, extended, basic</entry>
  <entry>advanced</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  The regular expression "flavor" can be set to advanced, extended, or basic.
  The usual default is advanced. The extended setting may be useful for exact
  backwards compatibility with pre-7.4 releases of PostgreSQL.
  </entry>
  <entry>
  What you set here is pretty much dependent on what kind of regex behavior
  you're used to.  Programmers in Perl, Java, and other languages will be
  familiar with Advanced; other users may wish the less complex syntax of
  Basic.  Do not change this after your database testing is complete, as it
  could change the results of queries.
  </entry>
 </row>
 <row>
  <entry>sql_inheritance</entry>
  <entry>true, false</entry>
  <entry>true</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  This controls the inheritance semantics, in particular whether subtables are
  included by various commands by default. They were not included in versions
  prior to 7.1. If you need the old behavior you can set this variable to off,
  but in the long run you are encouraged to change your applications to use the
  ONLY keyword to exclude subtables.
  </entry>
  <entry>
  Only needed for people upgrading 7.0 applications.
  </entry>
 </row>
 <row>
  <entry>default_with_oids</entry>
  <entry>True, false</entry>
  <entry>True</entry>
  <entry>Runtime</entry>
  <entry></entry>
  <entry>
  This controls whether CREATE TABLE and CREATE TABLE AS include an OID column
  in newly-created tables, if neither WITH OIDS nor WITHOUT OIDS is specified.
  It also determines whether OIDs will be included in tables created by SELECT
  INTO. In PostgreSQL 8.0.0 default_with_oids defaults to true. This is also
  the behavior of previous versions of PostgreSQL. However, assuming that
  tables will contain OIDs by default is not encouraged. This option will
  probably default to false in a future release of PostgreSQL.
  </entry>
  <entry>
  In a database with very large tables, it can be useful to set this to false.
  This will save you around 8 bytes per row, which across millions of rows can
  make a difference.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

<sect2>
<title>Platform and Client Compatibility</title>

<table>
<tgroup cols="7" align="left" colsep="1" rowsep="1">

<thead>
 <row>
  <entry>Setting</entry>
  <entry>Range</entry>
  <entry>Default</entry>
  <entry>SET at</entry>
  <entry>-o</entry>
  <entry>Documentation says</entry>
  <entry>Comments</entry>
 </row>
</thead>

<tbody>
 <row>
  <entry>transform_null_equals</entry>
  <entry>true, false</entry>
  <entry>false</entry>
  <entry>Yes</entry>
  <entry></entry>
  <entry>
  When turned on, expressions of the form expr = NULL (or NULL = expr) are
  treated as expr IS NULL, that is, they return true if expr evaluates to the
  null value, and false otherwise. The correct behavior of expr = NULL is to
  always return null (unknown).
  </entry>
  <entry></entry>
 </row>
 <row>
  <entry>custom_variable_classes</entry>
  <entry></entry>
  <entry>''</entry>
  <entry>Startup</entry>
  <entry></entry>
  <entry>
  This variable specifies one or several class names to be used for custom
  variables, in the form of a comma-separated list. A custom variable is a
  variable not normally known to PostgreSQL proper but used by some add-on
  module. Such variables must have names consisting of a class name, a dot,
  and a variable name. custom_variable_classes specifies all the class names
  in use in a particular installation.
  </entry>
  <entry>
  The add-in modules which require this (e.g. PL/Java) should have instructions
  on how to set it.
  </entry>
 </row>
</tbody>
</tgroup>
</table>

</sect2>

</sect1>

</article>
