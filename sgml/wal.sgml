<!-- $Header: /var/lib/cvs/pgsql-fr/sgml/wal.sgml,v 1.9 2005/07/15 06:14:30 guillaume Exp $ -->

<chapter id="reliability">
 <title>Reliability</title>

  <para>
   Reliability is a major feature of any serious database system, and
   <productname>PostgreSQL</> does everything possible to guarantee
   reliable operation. One aspect of reliable operation is that all data
   recorded by a committed transaction should be stored in a non-volatile area
   that is safe from power loss, operating system failure, and hardware
   failure (except failure of the non-volatile area itself, of course).
   Successfully writing the data to the computer's permanent storage
   (disk drive or equivalent) ordinarily meets this requirement.
   In fact, even if a computer is fatally damaged, if
   the disk drives survive they can be moved to another computer with
   similar hardware and all committed transactions will remain intact.
  </para>

  <para>
   While forcing data periodically to the disk platters might seem like
   a simple operation, it is not. Because disk drives are dramatically
   slower than main memory and CPUs, several layers of caching exist
   between the computer's main memory and the disk platters.
   First, there is the operating system's buffer cache, which caches
   frequently requested disk blocks and combines disk writes. Fortunately,
   all operating systems give applications a way to force writes from
   the buffer cache to disk, and <productname>PostgreSQL</> uses those
   features.  (See the <xref linkend="guc-wal-sync-method"> parameter
   to adjust how this is done.)
  </para>

  <para>
   Next, there may be a cache in the disk drive controller; this is
   particularly common on <acronym>RAID</> controller cards. Some of
   these caches are <firstterm>write-through</>, meaning writes are passed
   along to the drive as soon as they arrive. Others are
   <firstterm>write-back</>, meaning data is passed on to the drive at
   some later time. Such caches can be a reliability hazard because the
   memory in the disk controller cache is volatile, and will lose its
   contents in a power failure.  Better controller cards have
   <firstterm>battery-backed</> caches, meaning the card has a battery that
   maintains power to the cache in case of system power loss.  After power
   is restored the data will be written to the disk drives.
  </para>

  <para>
   And finally, most disk drives have caches. Some are write-through
   while some are write-back, and the
   same concerns about data loss exist for write-back drive caches as
   exist for disk controller caches.  Consumer-grade IDE drives are
   particularly likely to contain write-back caches that will not
   survive a power failure.
  </para>

  <para>
   When the operating system sends a write request to the disk hardware,
   there is little it can do to make sure the data has arrived at a truly
   non-volatile storage area. Rather, it is the
   administrator's responsibility to be sure that all storage components
   ensure data integrity.  Avoid disk controllers that have non-battery-backed
   write caches.  At the drive level, disable write-back caching if the
   drive cannot guarantee the data will be written before shutdown.
  </para>
  
  <para>
   Another risk of data loss is posed by the disk platter write
   operations themselves. Disk platters are divided into sectors,
   commonly 512 bytes each.  Every physical read or write operation
   processes a whole sector.
   When a write request arrives at the drive, it might be for 512 bytes,
   1024 bytes, or 8192 bytes, and the process of writing could fail due
   to power loss at any time, meaning some of the 512-byte sectors were
   written, and others were not.  To guard against such failures,
   <productname>PostgreSQL</> periodically writes full page images to
   permanent storage <emphasis>before</> modifying the actual page on
   disk. By doing this, during crash recovery <productname>PostgreSQL</> can
   restore partially-written pages.  If you have a battery-backed disk
   controller or filesystem software (e.g., Reiser4) that prevents partial
   page writes,  you can turn off this page imaging by using the 
   <xref linkend="guc-full-page-writes"> parameter.
  </para>
 
  <para>
   The following sections explain how the Write-Ahead Log is used to 
   obtain efficient, reliable operation.
  </para>

  <sect1 id="wal">
   <title>Write-Ahead Logging (<acronym>WAL</acronym>)</title>

 <indexterm zone="wal">
  <primary>WAL</primary>
 </indexterm>

 <indexterm>
  <primary>log transaction</primary>
  <see>WAL</see>
 </indexterm>

  <para>
   <firstterm>Write-Ahead Logging</firstterm> (<acronym>WAL</acronym>)
   est une approche conventionnelle pour l'écriture d'un journal de
   transactions.  Sa description détaillée peut être trouvée dans la
   plupart (si ce n'est tous) des livres sur le traitement
   transactionnel. Brièvement, le concept central des
   <acronym>WAL</acronym> est d'effectuer les changements des fichiers de
   données (où résident les tables et les index) 
   uniquement après que ces changements ont été écrits dans un journal,
   c'est-à-dire quand l'enregistrement du journal décrivant les changements a
   été écrit vers le
   stockage permanent.  Si nous suivons cette procédure, nous n'avons
   pas besoin d'écrire les pages de données vers le disque à chaque
   validation de transaction car nous savons que, dans l'éventualité
   d'une défaillance, nous serons capables de récupérer la base de
   données en utilisant le journal&nbsp;: chaque changement qui n'a pas été
   appliqué aux pages de données peut être ré-exécuté depuis les
   enregistrements du journal. (Ceci est une récupération roll-forward,
   aussi connue sous le nom de REDO.)
  </para>

   <para>
    Un avantage majeur en utilisant les <acronym>WAL</acronym>
    est la réduction significative du nombre d'écritures sur le disque
    puisque seul le journal des transactions a besoin d'être écrit sur le
    disque au moment où la transaction est validée plutôt que d'écrire dans chaque fichier de
    données modifié par la transaction. Dans un environnement
    multi-utilisateurs, la validation de nombreuses transactions peut être
    accomplie avec un seul <function>fsync()</function> du journal.  De plus, ce
    dernier est écrit séquentiellement et donc, le coût de
    synchronisation du journal est largement moindre que le coût d'écriture des
    pages de données. Ceci est spécialement vrai pour les serveurs gérant
    beaucoup de petites transactions touchant différentes parties du stockage de
    données.
   </para>

   <para>
    Les <acronym>WAL</acronym> rendent possible le support de sauvegarde
    en ligne et de récupération à un moment, comme décrit dans <xref
    linkend="backup-online">. En archivant les données WAL, nous pouvons
    supporter le retour à tout instant couvert par les données disponibles
    dans les WAL&nbsp;: nous installons simplement une ancienne sauvegarde
    physique de la base de données et nous rejouons les journaux WAL jusqu'au
    moment désiré. Qui plus est, la sauvegarde physique n'a pas besoin d'être
    une image instantanée de l'état de la base de données &mdash; si elle a été
    faire pendant une période de temps, alors rejouer les journaux WAL pour
    cette période corrigera toute inconsistance interne.
   </para>
  </sect1>

 <sect1 id="wal-configuration">
  <title>Configuration de <acronym>WAL</acronym></title>

  <para>
   Il y a plusieurs paramètres de configuration associés à
   <acronym>WAL</acronym> qui affectent les performances de la base de
   de données.  Cette section explique leur utilisation.  Consultez la
   <xref linkend="runtime-config"> pour des détails sur la
   mise en place de ces paramètres de configuration.
  </para>

  <para>
   Dans la séquence des transactions, les
   <firstterm>points de contrôles</firstterm><indexterm><primary>points de
   contrôle</></> (checkpoints) sont des
   points qui garantissent que les fichiers de données ont été mis à
   jour avec toutes les informations enregistrées dans le journal avant le
   point de contrôle.  Au moment du point de contrôle, toutes les
   les pages de données non propres sont écrites sur le disque et une
   entrée spéciale, pour le point de contrôle, est écrite dans le
   journal. En cas de défaillance, la procédure de
   récupération looks at the latest
   checkpoint record to determine the point in the log (known as the redo
   record) from which it should start the REDO operation.  Any changes made to
   data files before that point are known to be already on disk.  Hence, after
   a checkpoint has been made, any log segments preceding the one containing
   the redo record are no longer needed and can be recycled or removed. (When
   <acronym>WAL</acronym> archiving is being done, the log segments must be
   archived before being recycled or removed.)
  </para>

  <para>
   Le processus d'écriture en tâche de fond lancera automatiquement un point de
   contrôle de temps en temps. Un point de contrôle est créé tous les <xref
   linkend="guc-checkpoint-segments"> segments de journaux ou dès que <xref
   linkend="guc-checkpoint-timeout"> secondes se sont
   écoulées.  Les paramètres par défaut sont respectivement 3 segments
   et 300 secondes.  Il est également possible de forcer la création
   d'un point de contrôle en utilisant la commande SQL
   <command>CHECKPOINT</command>.
  </para>

  <para>
   Réduire <varname>checkpoint_segments</varname> et/ou
   <varname>checkpoint_timeout</varname> a pour conséquence de faire
   des points de contrôle plus fréquent.  Ceci permet une récupération
   plus rapide après une défaillance (puisque moins de travail a
   besoin d'être récupéré).  Cependant, il faut équilibrer cela avec
   l'augmentation du coût d'écriture des pages de données non propres.
   If 
   <xref linkend="guc-full-page-writes"> is set (as is the default), there is 
   another factor to consider. To ensure data page consistency, 
   the first modification of a data page after each checkpoint results in 
   logging the entire page content. In that case,
   a smaller checkpoint interval increases the volume of output to the WAL log,
   partially negating the goal of using a smaller interval, 
   and in any case causing more disk I/O.
  </para>

  <para>
   Les points de contrôle sont assez coûteux, tout d'abord parce qu'ils
   écrivent tous les tampons utilisés, et ensuite parce que cela suscite un
   trafic WAL supplémentaire comme indiqué ci-dessus. Du coup, il est conseillé
   de configurer les paramètres en relation assez haut pour que ces points de
   contrôle n'arrivent pas trop fréquemment. En tant que simple vérification de
   santé de vos paramètres, vous pouvez configurer le paramètre <xref
   linkend="guc-checkpoint-warning">. Si les points de contrôle arrivent plus
   rapidement que <varname>checkpoint_warning</> secondes, un message sera
   affiché dans les journaux du serveur, recommandant d'accroître
   <varname>checkpoint_segments</varname>. Une apparition occasionnelle d'un
   message ne doit pas vous alarmer mais, s'il apparaît souvent, alors les
   paramètres de contrôle devraient être augmentés. Bulk operations such
   as large <command>COPY</> transfers may cause a number of such warnings
   to appear if you have not set <varname>checkpoint_segments</> high
   enough.
  </para>

  <para>
   Il y aura au moins un fichier segment WAL et normalement
   pas plus de 2 * <varname>checkpoint_segments</varname> + 1
   fichiers.  Chaque fichier de segment fait normalement 16&nbsp;Mo (bien
   que cette taille puisse être modifiée lors de la compilation du serveur). Vous pouvez
   utiliser cela pour estimer l'espace disque
   nécessaire pour <acronym>WAL</acronym>. D'habitude, quand les vieux fichiers 
   segment de journaux ne sont plus nécessaires, ils sont recyclés
   (renommés pour devenir les prochains segments dans une séquence
   numérotée).  Si, à cause d'un pic temporaire du taux d'écriture des journaux,
   il y a plus de 2 * <varname>checkpoint_segments</varname> + 1
   fichiers segments, ceux inutilisés seront effacés au lieu d'être
   recyclés jusqu'à ce que le système soit en-dessous de cette limite.
  </para>

  <para>
   Il y a deux fonctions <acronym>WAL</acronym> internes couramment
   utilisées&nbsp;:
   <function>LogInsert</function> et <function>LogFlush</function>.
   <function>LogInsert</function> est utilisée pour placer une
   nouvelle entrée à l'intérieur des tampons <acronym>WAL</acronym> en mémoire
   partagée.  Si il n'y a plus
   d'espace pour une nouvelle entrée, <function>LogInsert</function>
   devra écrire (bouger dans le cache du noyau) quelques tampons
   <acronym>WAL</acronym> remplis.  Ceci n'est pas désirable parce que
   <function>LogInsert</function> est utilisée lors de chaque
   modification bas niveau de la base (par exemple, insertion d'une
   ligne) quand un verrou exclusif est posé sur des pages de données
   affectées, donc l'opération nécessite d'être aussi rapide que
   possible.  Pire encore, écrire des tampons <acronym>WAL</acronym>
   peut aussi forcer la création d'un nouveau segment de journal ce qui
   peut prendre beaucoup plus de temps.  Normalement, les tampons
   <acronym>WAL</acronym> devrait être écrits et vidés par une requête
   de <function>LogFlush</function> qui est faite, la plupart du
   temps, au moment de la validation d'une transaction pour assurer
   que les entrées de la transaction sont écrites vers un stockage
   permanent.  Sur les systèmes avec une importante écriture de journaux,
   les requêtes de <function>LogFlush</function> peuvent ne pas
   arriver assez souvent pour empêcher <function>LogInsert</function> d'avoir
   à écrire.  Sur de tel système, on devrait augmenter le nombre de tampons
   <acronym>WAL</acronym> en modifiant le paramètre de configuration <xref
   linkend="guc-wal-buffers">. Par défaut, le nombre de tampons est de 8. 
   Augmenter cette valeur augmentera considérablement l'utilisation de la
   mémoire partagée. When 
   <xref linkend="guc-full-page-writes"> is set and the system is very busy, 
   setting this value higher will help smooth response times during the 
   period immediately following each checkpoint.
  </para>

  <para>
   Le paramètre <xref linkend="guc-commit-delay"> définit combien de
   micro-secondes le processus serveur dormira après l'écriture d'une
   entrée de validation dans le journal avec
   <function>LogInsert</function> avant d'exécuter un 
   <function>LogFlush</function>.  Ce délai permet aux autres
   processus du serveur d'ajouter leurs entrées de validation dans le
   fichier de journal afin de tout écrire vers le disque avec une seule
   synchronisation du journal.  Aucune mise en sommeil n'aura lieu si
   <xref linkend="guc-fsync"> n'est pas disponible ou si moins de
   <xref linkend="guc-commit-siblings"> autres sessions sont, à ce
   moment, dans des transactions actives&nbsp;; cela évite de dormir quand
   il est improbable qu'une autre session fasse bientôt une
   validation.  Notez que dans la plupart des plate-formes, la
   résolution d'une requête de sommeil est de 10 millisecondes, donc
   un <varname>commit_delay</varname> différent de zéro et configuré
   entre 1 et 10000 micro-secondes aura le même effet.  Les bonnes
   valeurs pour ce paramètre ne sont pas encore claires&nbsp;; les essais
   sont encouragés.
  </para>

  <para>
   Le paramètre <xref linkend="guc-wal-sync-method"> détermine comment 
   <productname>PostgreSQL</productname> demandera au noyau de forcer les mises
   à jour <acronym>WAL</acronym> sur le disque. Toutes les options devraient
   être les mêmes dans la mesure où la fiabilité ne disparaît pas,
   mais c'est avec des options spécifiques à la plate-forme que ça
   sera le plus rapide.  Notez que ce paramètre est ignoré si
   <varname>fsync</varname> a été désactivé.
  </para>

  <para>
   Configurer le paramètre <xref linkend="guc-wal-debug"> avec une
   valeur différente de zéro aura pour résultat d'enregistrer dans les
   journaux du serveur l'appel WAL à chaque <function>LogInsert</function>
   et <function>LogFlush</function>.  En ce moment, il n'est fait
   aucune différence entre les valeurs supérieures à zéro.  Cette
   option pourra être remplacée par un mécanisme plus général dans le
   futur.
  </para>
   <para>
   Activer le paramètre de configuration <xref linkend="guc-wal-debug"> (à
   supposer que <productname>PostgreSQL</productname> ait été compilé avec le
   support de ce paramètre) résultera dans l'enregistrement de chaque appel
   <acronym>WAL</acronym> à <function>LogInsert</function> et
   <function>LogFlush</function> dans les journaux du serveur. Cette option
   pourrait être remplacée par un mécanisme plus général dans le futur.
  </para>
</sect1>

 <sect1 id="wal-internals">
  <title>Vue interne des WAL</title>

  <para>
   <acronym>WAL</acronym> est automatiquement disponible&nbsp;; aucune
   action n'est requise de la part de l'administrateur excepté
   de s'assurer que l'espace disque requis par les journaux
   WAL soit présent et que tous les réglages soient faits (regardez
   la <xref linkend="wal-configuration">).
  </para>

  <para>
   Les journaux <acronym>WAL</acronym> sont stockés dans le répertoire
   <filename>pg_xlog</filename> sous le répertoire de données, comme un ensemble
   de fichiers segments, chacun d'une taille de 16&nbsp;Mo généralement. Chaque
   segment est divisé en pages de généralement 8&nbsp;Ko. Les en-têtes de
   l'entrée du journal sont décrites dans
   <filename>access/xlog.h</filename>&nbsp;; le contenu de l'entrée dépend
   du type de l'événement qui est enregistré.  Les fichiers segments
   sont nommés avec un chiffre qui est toujours incrémenté et qui
   commence à <filename>000000010000000000000000</filename>.  Les nombres ne
   bouclent pas actuellement, mais cela devrait prendre beaucoup de temps
   pour épuiser le stock de nombres disponibles.
  </para>

  <para>
   Il est avantageux que le journal soit situé sur un autre disque que
   celui des fichiers principaux de la base de données.  Cela peut
   être réalisé en déplaçant le répertoire
   <filename>pg_xlog</filename> vers un autre emplacement (alors que
   le serveur est arrêté, naturellement) et en créant un lien
   symbolique de l'endroit d'origine dans le répertoire principal de
   données au nouvel emplacement.
  </para>

  <para>
   Le but de <acronym>WAL</acronym>, s'assurer que le journal est écrit
   avant l'altération des entrées dans la base, peut être mis en échec par
   les lecteurs des disques<indexterm><primary>disques durs</></> qui
   faussement rapportent une écriture
   réussie au noyau quand, en fait, ils ont seulement mis en cache
   les données et ne les ont pas encore stockées sur le disque.  Une
   coupure de courant dans ce genre de situation peut toujours mener à
   la corruption irrécupérable des données.  Les administrateurs
   devraient s'assurer que les disques contenant les journaux
   <acronym>WAL</acronym> de <productname>PostgreSQL</productname> ne
   produisent pas ce genre de faux rapports.
  </para>

  <para>
   Après qu'un point de contrôle ait été fait et que le journal ait été
   écrit, la position du point de contrôle est sauvegardée dans le
   fichier <filename>pg_control</filename>.  Donc, quand la
   restauration doit être faite, le serveur lit en premier
   <filename>pg_control</filename> et ensuite l'entrée du point de
   contrôle&nbsp;; ensuite, il exécute l'opération REDO en parcourant vers
   l'avant à partir de la position du journal indiquée dans l'entrée du
   point de contrôle. Parce que l'ensemble du contenu des pages de
   données est sauvegardé dans le journal à la première modification de
   page après un point de contrôle, toutes les pages changées depuis
   le point de contrôle seront restaurées dans un état cohérent.
  </para>

  <para>
   Pour gérer le cas où <filename>pg_control</filename> est corrompu, nous
   devons supporter la possibilité de parcourir des segments de journaux
   existants en ordre inverse &mdash; de plus récent au plus ancien &mdash; pour
   trouver le dernier point de vérification. Ceci n'a pas encore été implémenté.
   <filename>pg_control</filename> est assez petit (moins d'une page disque)
   pour ne pas être sujet aux problèmes d'écriture partielle et, au moment où
   ceci est écrit, il n'y a eu aucun rapport d'échecs de la base de données
   uniquement à cause de son incapacité à lire <filename>pg_control</filename>.
   Donc, bien que cela soit théoriquement un point faible,
   <filename>pg_control</filename> ne semble pas être un problème en pratique.
  </para>
 </sect1>
</chapter>

<!-- Keep this comment at the end of the file
Local variables:
mode:sgml
sgml-omittag:nil
sgml-shorttag:t
sgml-minimize-attributes:nil
sgml-always-quote-attributes:t
sgml-indent-step:1
sgml-indent-data:t
sgml-parent-document:nil
sgml-default-dtd-file:"./reference.ced"
sgml-exposed-tags:nil
sgml-local-catalogs:("/usr/lib/sgml/catalog")
sgml-local-ecat-files:nil
End:
-->

