<?xml version="1.0" encoding="UTF-8"?>
<!-- doc/src/sgml/parallel.sgml -->

 <chapter id="parallel-query">
  <title>Requêtes parallélisées</title>

  <indexterm zone="parallel-query">
   <primary>requête parallélisée</primary>
  </indexterm>

  <para>
   <productname>PostgreSQL</productname> peut préparer des plans de requêtes
   utilisant plusieurs CPU pour répondre plus rapidement à certaines requêtes.
   Cette fonctionnalité est connue sous le nom de requêtes parallélisées. Un
   grand nombre de requêtes ne peuvent pas bénéficier de cette fonctionnalité,
   soit à cause de la limitation de l'implémentation actuelle soit parce qu'il
   n'existe pas de plan imaginable qui soit plus rapide qu'un plan
   sériel. Néanmoins, pour les requêtes pouvant en bénéficier, l'accélération
   due à une requête parallélisée est souvent très significative. Beaucoup de
   ces requêtes peuvent s'exécuter au moins deux fois plus rapidement grâce à
   la parallélisation, et certaines requêtes quatre fois
   voire plus. Les requêtes touchant à une grande quantité de données, mais
   ne retournant que quelques lignes à l'utilisateur sont généralement celles
   qui bénéficient le plus de cette fonctionnalité. Ce chapitre explique
   quelques détails sur le fonctionnement des requêtes parallélisées et dans
   quelles situations elles peuvent être utilisées pour que les
   utilisateurs intéressés sachent quoi en attendre.
  </para>

 <sect1 id="how-parallel-query-works">
  <title>Comment fonctionne la parallélisation des requêtes</title>

   <para>
    Quand l'optimiseur détermine que la parallélisation est la stratégie la
    plus rapide pour une requête particulière, il crée un plan d'exécution incluant
    un <firstterm>n&oelig;ud Gather</firstterm>. En voici un exemple simple&nbsp;:

<screen>
EXPLAIN SELECT * FROM pgbench_accounts WHERE filler LIKE '%x%';
                                     QUERY PLAN                                      
-------------------------------------------------------------------------------------
 Gather  (cost=1000.00..217018.43 rows=1 width=97)
   Workers Planned: 2
   -&gt;  Parallel Seq Scan on pgbench_accounts  (cost=0.00..216018.33 rows=1 width=97)
         Filter: (filler ~~ '%x%'::text)
(4 rows)
</screen>
   </para>

   <para>
    Dans tous les cas, le n&oelig;ud <literal>Gather</literal> aura
    extactement un no&oelig;ud enfant, qui est la portion du plan exécutée en
    parallèle. Si le n&oelig;ud <literal>Gather</literal> est à la racine du
    plan, alors la requête entière est parallélisée. S'il est placé ailleurs
    dans le plan, alors seulement cette portion du plan s'exécutera en
    parallèle. Dans l'exemple ci-dessus, la requête accède à une seule
    table, donc il n'existe qu'un seul autre n&oelig;ud de plan que le
    n&oelig;ud <literal>Gather</literal> lui-même&nbsp;; comme ce n&oelig;ud
    est un enfant du n&oelig;ud <literal>Gather</literal>, il
    s'exécutera en parallèle.
   </para>

   <para>
    En <link linkend="using-explain">utilisant EXPLAIN</link>, vous pouvez
    voir le nombre de processus d'aide (appelés
    <foreignphrase>workers</foreignphrase>) choisis par le planificateur.
    Quand le n&oelig;ud <literal>Gather</literal> est atteint lors de
    l'exécution de la requête, le processus en charge de la session
    demandera un nombre de processus d'arrière plan (<link
    linkend="bgworker">background workers</link>) égal au nombre de workers
    choisi par le planificateur. Le nombre total de <foreignphrase>background
    workers</foreignphrase> pouvant exister à un même moment est limité par le
    paramètre <xref linkend="guc-max-worker-processes"/>&nbsp;; il est donc possible
    qu'une requête parallélisée s'exécute avec moins de
    <foreignphrase>workers</foreignphrase> que prévu, voire même sans
    <foreignphrase>worker</foreignphrase> du tout. Le plan optimal peut
    dépendre du nombre de <foreignphrase>workers</foreignphrase> disponibles,
    ce qui peut résulter en de médiocres performances des
    requêtes. Si cela survient fréquemment, étudiez l'augmentation de
    <varname>max_worker_processes</varname> pour qu'un plus grand nombre de
    <foreignphrase>workers</foreignphrase> puissent travailler simultanément
    ou la diminution de <xref linkend="guc-max-parallel-workers-per-gather"/> pour que
    le planificateur réclame moins de <foreignphrase>workers</foreignphrase>.
   </para>

   <para>
    Chaque processus <foreignphrase>background worker</foreignphrase> démarré
    avec succès dans une requête parallélisée donnée exécutera la
    portion du plan descendant du n&oelig;ud
    <literal>Gather</literal>. Le processus principal, appelé
    <foreignphrase>leader</foreignphrase>, exécutera aussi cette portion du
    plan bien qu'il ait des responsabilités supplémentaires&nbsp;: il doit
    aussi lire toutes les lignes générées par les
    <foreignphrase>workers</foreignphrase>. Quand la portion parallélisée du
    plan ne génère qu'un petit nombre de lignes, le
    <foreignphrase>leader</foreignphrase> se comportera souvent comme un
    <foreignphrase>worker</foreignphrase> supplémentaire, accélérant
    l'exécution de la requête. Par contre, quand la portion parallèle du plan
    génère un grand nombre de lignes, le <foreignphrase>leader</foreignphrase>
    peut être accaparé par la lecture des lignes générées par
    les <foreignphrase>workers</foreignphrase> et par le traitement
    des autres étapes au-dessus du n&oelig;ud <literal>Gather</literal>. Dans de
    tels cas, le <foreignphrase>leader</foreignphrase> travaillera très peu sur la
    portion parallélisée du plan.
   </para>
 </sect1>

 <sect1 id="when-can-parallel-query-be-used">
  <title>Quand la parallélisation des requêtes peut-elle être utilisée&nbsp;?</title>

  <para>
    Il existe plusieurs paramètres pouvant empêcher le planificateur
    de la requête de générer un plan parallélisé quelles que soient les
    circonstances. Pour faire en sorte que des plans parallélisés puissent
    être générés, les paramètres suivants doivent être configurés ainsi&nbsp;:
  </para>

  <itemizedlist>
    <listitem>
      <para>
        <xref linkend="guc-max-parallel-workers-per-gather"/> doit être
        configuré à une valeur strictement positive. Ceci est un cas spécial
        du principe plus général qu'il n'y aura pas plus de
        <foreignphrase>workers</foreignphrase> que le nombre configuré via
        <varname>max_parallel_workers_per_gather</varname>.
      </para>
    </listitem>

    <listitem>
      <para>
        <xref linkend="guc-dynamic-shared-memory-type"/> doit être configuré à
        une valeur autre que <literal>none</literal>. Les requêtes
        parallélisées nécessitent de la mémoire partagée dynamique pour
        fournir des données entre les processus participant à la
        parallélisation.
      </para>
    </listitem>
  </itemizedlist>

  <para>
    De plus, le système ne doit pas fonctionner en mode mono-utilisateur.
    Comme le système de bases de données entier fonctionne alors avec un seul
    processus, aucun <foreignphrase>background
    worker</foreignphrase> ne sera disponible.
  </para>

  <para>
    Même quand il est habituellement possible de générer des plans pour
    des requêtes parallélisées, le planificateur n'en générera pas
    pour une requête donnée si une des conditions suivantes est
    remplie&nbsp;:
  </para>

  <itemizedlist>
    <listitem>
      <para>
        La requête écrit des données ou verrouille des lignes de la base. Si
        une requête contient une opération de modification de données, soit au
        niveau supérieur, soit dans une CTE, aucun plan parallèle ne peut être
        généré pour cette requête. Ceci est une limitation de l'implémentation
        actuelle qui pourrait être supprimée dans une prochaine version.
      </para>
    </listitem>

    <listitem>
      <para>
        La requête est susceptible d'être suspendue durant l'exécution. Dans des
        situations où le système pense qu'une exécution pourrait être partielle ou
        incrémentale, aucun plan parallèle n'est généré.
        Par exemple, un curseur créé avec <link
        linkend="sql-declare">DECLARE CURSOR</link> n'utilisera jamais un plan
        parallélisé. De façon similaire, une boucle PL/pgsql de la forme
        <literal>FOR x IN query LOOP .. END LOOP</literal> n'utilisera jamais
        un plan parallélisé, car le système est incapable de vérifier que le
        code dans la boucle peut s'exécuter en toute sécurité avec une requête
        parallélisée.
      </para>
    </listitem>

    <listitem>
      <para>
        La requête utilise une fonction marquée <literal>PARALLEL UNSAFE</literal> (à parallélisation sûre).
        La plupart des fonctions systèmes sont <literal>PARALLEL SAFE</literal>,
        mais les fonctions utilisateurs sont marquées <literal>PARALLEL UNSAFE</literal> 
	par défaut. Voir la discussion de <xref linkend="parallel-safety"/>.
      </para>
    </listitem>

    <listitem>
      <para>
        La requête est exécutée à l'intérieur d'une autre requête qui est déjà
        parallélisée. Par exemple, si une fonction appelée par une requête
        parallélisée exécute elle-même une requête SQL, celle-ci
        n'utilisera jamais un plan parallélisé. Ceci est une limitation de
        l'implémentation actuelle mais il ne serait pas forcément souhaitable de la
        supprimer car cela pourrait mener à ce que des requêtes
        simple utilisent un très grand nombre de processus.
      </para>
    </listitem>

    <listitem>
      <para>
        Le niveau d'isolation de la transaction est 
        <foreignphrase>serializable</foreignphrase>. Ceci est une limitation
        de l'implémentation actuelle.
      </para>
    </listitem>
  </itemizedlist>

  <para>
    Même quand un plan parallélisé est généré pour une requête donnée,
    différentes circonstances rendront impossible l'exécution en
    parallèle. Si cela arrive, le
    <foreignphrase>leader</foreignphrase> exécutera tout seul la portion du
    plan sous le n&oelig;ud <literal>Gather</literal>, pratiquement comme s'il
    n'était pas là. Ceci
    surviendra si une des conditions suivantes est vérifiée&nbsp;:
  </para>

  <itemizedlist>
    <listitem>
      <para> 
        Aucun <foreignphrase>background worker</foreignphrase> ne peut être
        obtenu à cause d'une limitation sur le nombre total de
        <foreignphrase>background workers</foreignphrase>, due au paramètre
        <xref linkend="guc-max-worker-processes"/>.
      </para>
    </listitem>

    <listitem>
      <para> 
        Le client envoie un message Execute avec un nombre à récupérer
        différent de zéro. Voir la discussion sur le <link
        linkend="protocol-flow-ext-query">protocole de requête étendu</link>.
        Comme la bibliothèque <link linkend="libpq">libpq</link> ne fournit
        actuellement aucun moyen pour envoyer ce type de message, cela peut
        seulement survenir suite à l'utilisation d'un client qui ne se base
        pas sur la libpq. Si cela arrive fréquemment, il pourrait être une
        bonne idée de configurer <xref
        linkend="guc-max-parallel-workers-per-gather"/> pour les sessions où
        cela pourrait survenir, pour éviter de générer des plans de requêtes
        non optimales s'ils sont exécutés de façon sérialisé.
      </para>
    </listitem>

    <listitem>
      <para>
        Une requête préparée est exécutée en utilisant une instruction
        <literal>CREATE TABLE .. AS EXECUTE ..</literal>. Cette construction
        convertit ce qui serait autrement une opération en lecture seule en
        une opération en lecture/écriture, la rendant ainsi inutilisable pour
        une requête parallélisée.
      </para>
    </listitem>

    <listitem>
      <para> 
        Le niveau de transaction est
        <foreignphrase>serializable</foreignphrase>. Cette situation ne doit
        normalement pas survenir car des plans de requêtes parallélisés ne
        sont pas générés dans une transaction
        <foreignphrase>serializable</foreignphrase>. Néanmoins, il peut
        arriver que le niveau d'isolation de la transaction soit modifié après
        la génération du plan et avant son exécution.
      </para>
    </listitem>
  </itemizedlist>
 </sect1>

 <sect1 id="parallel-plans">
  <title>Plans parallélisés</title>

  <para>
    Comme chaque <foreignphrase>worker</foreignphrase> exécute la portion
    parallélisée du plan jusqu'à la fin, il n'est pas possible de prendre un
    plan de requête ordinaire et de l'exécuter en utilisant plusieurs
    <foreignphrase>workers</foreignphrase>. Chaque
    <foreignphrase>worker</foreignphrase> produirait une copie complète du
    jeu de résultats, donc la requête ne s'exécuterait pas
    plus rapidement qu'à la normale, et produirait des résultats incorrects.
    À la place, la portion parallélisée du plan est considéré en
    interne par l'optimiseur comme un <firstterm>plan
    partiel</firstterm>&nbsp;; c'est-à-dire construit de façon
    à ce que chaque processus exécutant le plan ne génère qu'un
    sous-ensemble des lignes en sortie, et que chacune
    ait la garantie d'être générée par exactement un des
    processus participants.
  </para>

 <sect2 id="parallel-scans">
  <title>Parcours parallélisés</title>

  <para>
    Actuellement, le seul type de parcours qui ait été modifié pour fonctionner
    avec des requêtes parallélisées est le parcours séquentiel (<literal>Seq Scan</literal>). De ce fait, la
    table en question dans un plan parallélisé sera toujours parcourue en
    utilisant un <literal>Parallel Seq Scan</literal>. Les blocs de la
    relation sont répartis entre les processus participants. Les blocs sont
    gérés un par un, donc cet accès à la relation reste séquentiel. Chaque
    processus visite chaque ligne du bloc qui lui est assigné avant de
    réclamer un nouveau bloc.
  </para>
 </sect2>

 <sect2 id="parallel-joins">
  <title>Jointures parallélisées</title>

  <para>
    La table peut être jointe à une ou plusieurs autres tables en utilisant
    une boucle imbriquée (<foreignphrase>nested loop</foreignphrase> ou une
    jointure par hachage (<foreignphrase>hash join</foreignphrase> ). Le côté
    interne de la jointure peut être n'importe quel type de plan non
    parallélisé supporté par le planificateur par ailleurs, pourvu qu'il soit
    sûr de l'exécuter dans un <foreignphrase>worker</foreignphrase>
    parallélisé. Par exemple, ce peut être un parcours d'index recherchant une
    valeur prise dans la table externe. Chaque
    <foreignphrase>worker</foreignphrase> exécutera complètement le côté
    interne de la jointure, ce qui explique que les workers d'une jointure par
    hachage construisent chacun une table de hachage identique.
  </para>
 </sect2>

 <sect2 id="parallel-aggregation">
  <title>Agrégations parallélisées</title>
   <para>
    <productname>PostgreSQL</productname> procède à l'agrégation parallélisée
    en deux étapes. Tout d'abord, chaque processus de la
    partie parallélisée de la requête réalise une étape d'agrégation,
    produisant un résultat partiel pour chaque groupe qu'il
    connaît. Ceci se reflète dans le plan par le n&oelig;ud
    <literal>PartialAggregate</literal>. Puis les résultats partiels sont
    transférés au <foreignphrase>leader</foreignphrase> via le n&oelig;ud
    <literal>Gather</literal>. Enfin, le <foreignphrase>leader</foreignphrase>
    ré-agrège les résultats partiels de tous les
    <foreignphrase>workers</foreignphrase> pour produire le résultat final.
    Ceci apparaît dans le plan sous la forme d'un n&oelig;ud
    <literal>Finalize Aggregate</literal>.
   </para>
  
   <para>
    Comme le n&oelig;ud <literal>Finalize Aggregate</literal> s'exécute sur le
    processus leader, les requêtes produisant un nombre relativement important
    de groupes en comparaison du nombre de lignes en entrée apparaîtront moins
    favorable au planificateur de requêtes. Par exemple, dans le pire
    scénario, le nombre de groupes vus par le n&oelig;ud <literal>Finalize
    Aggregate</literal> pourrait être aussi grand que le nombre de lignes en
    entrée qui ont été traitées par les processus worker à l'étape
    <literal>Partial Aggregate</literal>. Dans de tels cas, il n'y aura
    clairement aucun intérêt au niveau des performances à utiliser
    l'agrégation parallélisée. Le planificateur de requêtes prend cela en
    compte lors du processus de planification et a peu de chance de choisir un
    agrégat parallélisé sur ce scénario.
   </para>

   <para>
    L'agrégation parallélisée n'est pas supportée dans toutes les situations.
    Chaque agrégat doit être <link linkend="parallel-safety">sûr à la parallélisation</link>
    et doit avoir une fonction de combinaison. Si
    l'agrégat a un état de transition de type <literal>internal</literal>, il
    doit avoir des fonctions de sérialisation et de désérialisation. Voir
    <xref linkend="sql-createaggregate"/> pour plus de détails. L'agrégation
    parallélisée n'est pas supportée si un appel à la fonction d'agrégat
    contient une clause <literal>DISTINCT</literal> ou <literal>ORDER
    BY</literal> ainsi que pour les agrégats d'ensembles triés ou quand la
    requête contient une clause <literal>GROUPING SETS</literal>. Elle ne peut
    être utilisée que si toutes les jointures impliquées dans la requête sont
    dans la partie parallélisée du plan.
   </para>
  </sect2>

 <sect2 id="parallel-plan-tips">
  <title>Conseils pour les plans parallélisés</title>

  <para>
    Si une requête ne produit pas un plan parallélisé comme attendu,
    vous pouvez tenter de réduire <xref
    linkend="guc-parallel-setup-cost"/> ou <xref linkend="guc-parallel-tuple-cost"/>.
    Bien sûr, ce plan pourrait bien finir par être plus lent que le plan sériel
    préféré par le planificateur mais ce ne sera pas toujours le cas. Si
    vous n'obtenez pas un plan parallélisé même pour de très petites valeurs
    de ces paramètres (par exemple après les avoir définis tous les deux
    à zéro), le planificateur a peut-être une bonne raison pour ne pas le faire
    pour votre requête. Voir <xref linkend="when-can-parallel-query-be-used"/>
    et <xref linkend="parallel-safety"/> pour
    des explications sur les causes possibles.
  </para>

  <para>
    Lors de l'exécution d'un plan parallélisé, vous pouvez utiliser
    <literal>EXPLAIN (ANALYZE, VERBOSE)</literal> qui affichera des
    statistiques par <foreignphrase>worker</foreignphrase> pour chaque
    n&oelig;ud du plan. Ce peut être utile pour déterminer si le travail
    est correctement distribué entre les n&oelig;uds du plan et plus
    généralement pour comprendre les caractéristiques de performance du plan.
  </para>

 </sect2>
 </sect1>

 <sect1 id="parallel-safety">
  <title>Sécurité sur la parallélisation</title>

  <para>
    Le planificateur classifie les opérations impliquées dans une requête
    comme étant <firstterm>à parallélisation sûre</firstterm>,
    <firstterm>restreintes</firstterm>, ou
	<firstterm>non sûres</firstterm>. Une opération
    à parallélisation sûre
    est une opération n'entrant pas en conflit avec une
    requête parallélisée. Une opération à parallélisation restreinte
    ne peut pas être exécutée par un
    <foreignphrase>worker</foreignphrase> parallélisé, mais peut l'être
    par le <foreignphrase>leader</foreignphrase> pendant
    l'exécution. De ce fait, les opérations à parallélisation
    restreinte ne peuvent jamais survenir sous un n&oelig;ud
    <literal>Gather</literal>. Une opération à parallélisation non sûre ne
    peut être exécutée dans une requête
    parallélisée, y compris au niveau du
    <foreignphrase>leader</foreignphrase>. Quand une requête contient quoi que
    ce soit non sûr à paralléliser, la parallélisation y est
    complètement désactivée.
  </para>

  <para>
    Les opérations suivantes sont toujours à parallélisation restreinte.
  </para>

  <itemizedlist>
    <listitem>
      <para>
        Parcours de CTE (<foreignphrase>Common Table Expressions</foreignphrase>).
      </para>
    </listitem>

    <listitem>
      <para>
        Parcours de tables temporaires.
      </para>
    </listitem>

    <listitem>
      <para>
        Parcours de tables externes, sauf si le wrapper de données distantes a
        une API <literal>IsForeignScanParallelSafe</literal> qui indique le
        contraire.
      </para>
    </listitem>

    <listitem>
      <para>
        Accès à un <literal>InitPlan</literal> ou à un
        <literal>SubPlan</literal>.
      </para>
    </listitem>
  </itemizedlist>

 <sect2 id="parallel-labeling">
  <title>Marquage de parallélisation pour les fonctions et agrégats</title>

  <para>
    Le planificateur ne peut pas déterminer automatiquement si une fonction ou
    un agrégat défini par un utilisateur est à parallélisation sûre, restreinte ou non sûre
    car cela nécessiterait de pouvoir prédire chaque opération
    réalisée par la fonction. En général, c'est équivalent au
    problème de l'arrêt et de ce fait, impossible.
    Même pour des fonctions simples où cela pourrait se faire, nous n'essayons
    pas car cela serait coûteux et sujet à erreurs. À la place, toutes les
    fonctions définies par des utilisateurs sont supposées à parallélisation non sûre
    sauf indication contraire. Lors de l'utilisation des
    instructions <xref linkend="sql-createfunction"/> et <xref
    linkend="sql-alterfunction"/>, un marquage est possible en spécifiant
    <literal>PARALLEL SAFE</literal>, <literal>PARALLEL RESTRICTED</literal>
    ou <literal>PARALLEL UNSAFE</literal> suivant ce qui est approprié. Lors
    de l'utilisation de <xref linkend="sql-createaggregate"/>, l'option
    <literal>PARALLEL</literal> peut être spécifiée comme 
    <literal>SAFE</literal>, <literal>RESTRICTED</literal> ou
    <literal>UNSAFE</literal>.
  </para>

  <para>
    Les fonctions et agrégats doivent être marqués <literal>PARALLEL
    UNSAFE</literal> s'ils écrivent dans la base, accèdent à des séquences,
    modifient l'état de la transaction même temporairement (par exemple, une
    fonction PL/pgsql qui définit un bloc <literal>EXCEPTION</literal> pour
    récupérer des erreurs), ou font des modifications persistentes sur les
    paramètres. De façon similaire, les fonctions doivent être marquées
    <literal>PARALLEL RESTRICTED</literal> si elles accèdent à des tables
    temporaires, à l'état de connexion du client, à des curseurs, à des
    requêtes préparées ou à un quelconque état local du processus serveur que le système
    ne peut pas synchroniser entre les différents
    <foreignphrase>workers</foreignphrase>. Par exemple,
    <literal>setseed</literal> et <literal>random</literal> sont à
    parallélisation restreinte pour cette dernière raison.
  </para>

  <para>
    En général, si une fonction est marquée comme étant sûre alors qu'elle ne
    l'est pas (et même si elle est seulement restreinte), ou si une fonction
    est marquée restreinte alors que sa parallélisation en fait n'est pas sûre, elle
    peut être cause d'erreurs ou de réponses fausses à
    l'utilisation dans une requête parallélisée. Les fonctions en langage C
    peuvent en théorie avoir des comportements indéfinis en cas de mauvais
    marquage, car le système n'a aucun moyen de se défendre contre du code C
    arbitraire. Cela étant dit, dans la plupart des cas, le résultat ne sera pas
    pire qu'avec toute autre fonction. En cas de doute, le mieux est probablement
    de marquer les fonctions en tant que <literal>UNSAFE</literal>.
  </para>

  <para>
    Si une fonction exécutée avec un <foreignphrase>worker</foreignphrase>
    parallèle acquiert des verrous non détenus par le
    <foreignphrase>leader</foreignphrase>, par exemple en exécutant une
    requête sur une table non référencée dans la requête, ces verrous seront
    relâchés à la sortie du <foreignphrase>worker</foreignphrase>, et non pas
    à la fin de la transaction. Si vous écrivez une fonction qui fait cela et
    que cette différence de comportement a une importance pour vous, marquez ces
    fonctions comme <literal>PARALLEL RESTRICTED</literal> pour vous assurer
    qu'elles ne s'exécutent qu'au sein du
    <foreignphrase>leader</foreignphrase>.
  </para>

  <para>
    Notez que le planificateur de requêtes ne cherche pas à différer
    l'évaluation des fonctions ou agrégats à parallélisation restreinte
    impliqués dans la requête pour obtenir un meilleur plan. Donc, par
    exemple, si une clause <literal>WHERE</literal> appliquée à une table
    particulière est à parallélisation restreinte, le planificateur ne
    tentera pas de placer le parcours de cette table sous un n&oelig;ud
    <literal>Gather</literal>. Dans certains cas, il serait possible 
    (voire efficace) d'inclure le parcours de cette table dans la
    partie parallèlisée de la requête et de différer l'évaluation de la 
    clause <literal>WHERE</literal> afin qu'elle se déroule au-dessus du
    n&oelig;ud <literal>Gather</literal>. Néanmoins, le planificateur ne le
    fait pas.
  </para>

 </sect2>

 </sect1>

 </chapter>
