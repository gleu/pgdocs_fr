<?xml version="1.0" encoding="UTF-8"?>
<!-- doc/src/sgml/parallel.sgml -->

 <chapter id="parallel-query">
  <title>Requêtes parallélisées</title>

  <indexterm zone="parallel-query">
   <primary>requête parallélisée</primary>
  </indexterm>

  <para>
   <productname>PostgreSQL</productname> peut préparer des plans de requêtes
   utilisant plusieurs CPU pour répondre plus rapidement à certaines requêtes.
   Cette fonctionnalité est connue sous le nom de requêtes parallélisées. Un
   grand nombre de requêtes ne peuvent pas bénéficier de cette fonctionnalité,
   soit à cause de la limitation de l'implémentation actuelle soit parce qu'il
   n'existe pas de plan imaginable qui soit plus rapide qu'un plan
   sériel. Néanmoins, pour les requêtes pouvant en bénéficier, l'accélération
   due à une requête parallélisée est souvent très significative. Beaucoup de
   ces requêtes peuvent s'exécuter au moins deux fois plus rapidement grâce à
   la parallélisation, et certaines requêtes quatre fois
   voire plus. Les requêtes touchant à une grande quantité de données mais
   ne retournant que quelques lignes à l'utilisateur sont généralement celles
   qui bénéficient le plus de cette fonctionnalité. Ce chapitre explique
   quelques détails sur le fonctionnement des requêtes parallélisées et dans
   quelles situations elles peuvent être utilisées pour que les
   utilisateurs intéressés sachent quoi en attendre.
  </para>

 <sect1 id="how-parallel-query-works">
  <title>Comment fonctionne la parallélisation des requêtes</title>

   <para>
    Quand l'optimiseur détermine que la parallélisation est la stratégie la
    plus rapide pour une requête particulière, il crée un plan d'exécution
    incluant un <firstterm>n&oelig;ud Gather</firstterm> ou un
    <firstterm>n&oelig;ud Gather Merge</firstterm>. En voici un exemple
    simple&nbsp;:

<screen>
EXPLAIN SELECT * FROM pgbench_accounts WHERE filler LIKE '%x%';
                                     QUERY PLAN                                      
-------------------------------------------------------------------------------------
 Gather  (cost=1000.00..217018.43 rows=1 width=97)
   Workers Planned: 2
   -&gt;  Parallel Seq Scan on pgbench_accounts  (cost=0.00..216018.33 rows=1 width=97)
         Filter: (filler ~~ '%x%'::text)
(4 rows)
</screen>
   </para>

   <para>
    Dans tous les cas, le n&oelig;ud <literal>Gather</literal> ou
    <literal>Gather Merge</literal> aura exactement un no&oelig;ud enfant, qui
    est la portion du plan exécutée en parallèle. Si le n&oelig;ud
    <literal>Gather</literal> ou <literal>Gather Merge</literal> est à la
    racine du
    plan, alors la requête entière est parallélisée. S'il est placé ailleurs
    dans le plan, alors seulement cette portion du plan s'exécutera en
    parallèle. Dans l'exemple ci-dessus, la requête accède à une seule
    table, donc il n'existe qu'un seul autre n&oelig;ud de plan que le
    n&oelig;ud <literal>Gather</literal> lui-même&nbsp;; comme ce n&oelig;ud
    est un enfant du n&oelig;ud <literal>Gather</literal>, il
    s'exécutera en parallèle.
   </para>

   <para>
    En <link linkend="using-explain">utilisant EXPLAIN</link>, vous pouvez
    voir le nombre de processus d'aide (appelés
    <foreignphrase>workers</foreignphrase>) choisis par le planificateur.
    Quand le n&oelig;ud <literal>Gather</literal> est atteint lors de
    l'exécution de la requête, le processus en charge de la session
    demandera un nombre de processus d'arrière plan (<link
    linkend="bgworker">background workers</link>) égal au nombre de workers
    choisi par le planificateur. Le nombre de workers en tache de fond que le
    planificateur considèrera utiliser est limité à au plus la valeur de
    <xref linkend="guc-max-parallel-workers-per-gather"/> . Le nombre total de
    <foreignphrase>background workers</foreignphrase> pouvant exister à un
    même moment est limité par les paramètres <xref
    linkend="guc-max-worker-processes"/> et <xref
    linkend="guc-max-parallel-workers"/>. De ce fait, il est possible qu'une
    requête parallélisée s'exécute avec moins de
    <foreignphrase>workers</foreignphrase> que prévu, voire même sans
    <foreignphrase>worker</foreignphrase> du tout. Le plan optimal peut
    dépendre du nombre de <foreignphrase>workers</foreignphrase> disponibles,
    ce qui peut résulter en de médiocres performances des
    requêtes. Si cela survient fréquemment, étudiez l'augmentation de
    <varname>max_worker_processes</varname>  et de
    <varname>max_parallel_workers</varname> pour qu'un plus grand nombre de
    <foreignphrase>workers</foreignphrase> puissent travailler simultanément
    ou la diminution de <varname>max_parallel_workers_per_gather</varname> pour que
    le planificateur réclame moins de <foreignphrase>workers</foreignphrase>.
   </para>

   <para>
    Chaque processus <foreignphrase>background worker</foreignphrase> démarré
    avec succès dans une requête parallélisée donnée exécutera la
    portion parallélisée du plan. Le processus principal, appelé
    <foreignphrase>leader</foreignphrase>, exécutera aussi cette portion du
    plan bien qu'il ait des responsabilités supplémentaires&nbsp;: il doit
    aussi lire toutes les lignes générées par les
    <foreignphrase>workers</foreignphrase>. Quand la portion parallélisée du
    plan ne génère qu'un petit nombre de lignes, le
    <foreignphrase>leader</foreignphrase> se comportera souvent comme un
    <foreignphrase>worker</foreignphrase> supplémentaire, accélérant
    l'exécution de la requête. Par contre, quand la portion parallèle du plan
    génère un grand nombre de lignes, le <foreignphrase>leader</foreignphrase>
    peut être accaparé par la lecture des lignes générées par
    les <foreignphrase>workers</foreignphrase> et par le traitement
    des autres étapes au-dessus du n&oelig;ud <literal>Gather</literal> ou du
    n&oelig;ud <literal>Gather Merge</literal>. Dans de
    tels cas, le <foreignphrase>leader</foreignphrase> travaillera très peu sur la
    portion parallélisée du plan.
   </para>

   <para>
    Quand le n&oelig;ud principal de la portion parallélisée est
    <literal>Gather Merge</literal> au lieu de <literal>Gather</literal>, cela
    indique que chaque processus exécutant la portion parallélisée du plan
    produit des lignes triées, et que le processus principal s'occupe de
    conserver l'ordre des lignes pendant leur assemblage. Par contre,
    <literal>Gather</literal> lit les lignes de processus d'aide dans
    n'importe quel ordre, détruisant tout ordre qui aurait pu exister.
   </para>   
 </sect1>

 <sect1 id="when-can-parallel-query-be-used">
  <title>Quand la parallélisation des requêtes peut-elle être utilisée&nbsp;?</title>

  <para>
    Il existe plusieurs paramètres pouvant empêcher le planificateur
    de la requête de générer un plan parallélisé quelque soient les
    circonstances. Pour faire en sorte que des plans parallélisés puissent
    être générés, les paramètres suivants doivent être configurés ainsi&nbsp;:
  </para>

  <itemizedlist>
    <listitem>
      <para>
        <xref linkend="guc-max-parallel-workers-per-gather"/> doit être
        configuré à une valeur strictement positive. Ceci est un cas spécial
        du principe plus général qu'il n'y aura pas plus de
        <foreignphrase>workers</foreignphrase> que le nombre configuré via
        <varname>max_parallel_workers_per_gather</varname>.
      </para>
    </listitem>

    <listitem>
      <para>
        <xref linkend="guc-dynamic-shared-memory-type"/> doit être configuré à
        une valeur autre que <literal>none</literal>. Les requêtes
        parallélisées nécessitent de la mémoire partagée dynamique pour
        fournir des données entre les processus participant à la
        parallélisation.
      </para>
    </listitem>
  </itemizedlist>

  <para>
    De plus, le système ne doit pas fonctionner en mode mono-utilisateur.
    Comme le système de bases de données entier fonctionne alors avec un seul
    processus, aucun <foreignphrase>background
    worker</foreignphrase> ne sera disponible.
  </para>

  <para>
    Même quand il est habituellement possible de générer des plans pour
    des requêtes parallélisées, le planificateur n'en générera pas
    pour une requête donnée si une des conditions suivantes est
    remplie&nbsp;:
  </para>

  <itemizedlist>
    <listitem>
      <para>
        La requête écrit des données ou verrouille des lignes de la base. Si
        une requête contient une opération de modification de données, soit au
        niveau supérieur, soit dans une CTE, aucun plan parallèle ne peut être
        généré pour cette requête. Ceci est une limitation de l'implémentation
        actuelle qui pourrait être supprimée dans une prochaine version.
      </para>
    </listitem>

    <listitem>
      <para>
        La requête est susceptible d'être suspendue durant l'exécution. Dans des
        situations où le système pense qu'une exécution pourrait être partielle ou
        incrémentale, aucun plan parallèle n'est généré.
        Par exemple, un curseur créé avec <link
        linkend="sql-declare">DECLARE CURSOR</link> n'utilisera jamais un plan
        parallélisé. De façon similaire, une boucle PL/pgsql de la forme
        <literal>FOR x IN query LOOP .. END LOOP</literal> n'utilisera jamais
        un plan parallélisé car le système est incapable de vérifier que le
        code dans la boucle peut s'exécuter en toute sécurité avec une requête
        parallélisée.
      </para>
    </listitem>

    <listitem>
      <para>
        La requête utilise une fonction marquée <literal>PARALLEL UNSAFE</literal> (à parallélisation sûre).
        La plupart des fonctions systèmes sont <literal>PARALLEL SAFE</literal>,
        mais les fonctions utilisateurs sont marquées <literal>PARALLEL UNSAFE</literal> 
	par défaut. Voir la discussion de <xref linkend="parallel-safety"/>.
      </para>
    </listitem>

    <listitem>
      <para>
        La requête est exécutée à l'intérieur d'une autre requête qui est déjà
        parallélisée. Par exemple, si une fonction appelée par une requête
        parallélisée exécute elle-même une requête SQL, celle-ci
        n'utilisera jamais un plan parallélisé. Ceci est une limitation de
        l'implémentation actuelle mais il ne serait pas forcément souhaitable de la
        supprimer car cela pourrait mener à ce que des requêtes
        simple utilisent un très grand nombre de processus.
      </para>
    </listitem>

    <listitem>
      <para>
        Le niveau d'isolation de la transaction est 
        <foreignphrase>serializable</foreignphrase>. Ceci est une limitation
        de l'implémentation actuelle.
      </para>
    </listitem>
  </itemizedlist>

  <para>
    Même quand un plan parallélisé est généré pour une requête donnée,
    différentes circonstances rendront impossible l'exécution en
    parallèle. Si cela arrive, le
    <foreignphrase>leader</foreignphrase> exécutera tout seul la portion du
    plan sous le n&oelig;ud <literal>Gather</literal>, pratiquement comme s'il
    n'était pas là. Ceci
    surviendra si une des conditions suivantes est vérifiée&nbsp;:
  </para>

  <itemizedlist>
    <listitem>
      <para>
        Aucun <foreignphrase>background worker</foreignphrase> ne peut être
        obtenu à cause d'une limitation sur le nombre total de
        <foreignphrase>background workers</foreignphrase>, due au paramètre
        <xref linkend="guc-max-worker-processes"/>.
      </para>
    </listitem>

    <listitem>
      <para>
        Aucun background worker ne peut être obtenu à cause de la limitation
        sur le nombre total de background workers qui peuvent être démarrés
        dans le cadre de requêtes parallèles qui ne peut pas dépasser
        <xref linkend="guc-max-parallel-workers"/>.
      </para>
    </listitem>

    <listitem>
      <para>
        Le client envoie un message Execute avec un nombre à récupérer
        différent de zéro. Voir la discussion sur le <link
        linkend="protocol-flow-ext-query">protocole de requête étendu</link>.
        Comme la bibliothèque <link linkend="libpq">libpq</link> ne fournit
        actuellement aucun moyen pour envoyer ce type de message, cela peut
        seulement survenir suite à l'utilisation d'un client qui ne se base
        pas sur la libpq. Si cela arrive fréquemment, il pourrait être une
        bonne idée de configurer <xref
        linkend="guc-max-parallel-workers-per-gather"/> à zéro pour les
        sessions où cela pourrait survenir, pour éviter de générer des plans
        de requêtes non optimales s'ils sont exécutés de façon sérialisé.
      </para>
    </listitem>

    <listitem>
      <para>
        Une requête préparée est exécutée en utilisant une instruction
        <literal>CREATE TABLE .. AS EXECUTE ..</literal>. Cette construction
        convertit ce qui serait autrement une opération en lecture seule en
        une opération en lecture/écriture, la rendant ainsi inutilisable pour
        une requête parallélisée.
      </para>
    </listitem>

    <listitem>
      <para> 
        Le niveau de transaction est
        <foreignphrase>serializable</foreignphrase>. Cette situation ne doit
        normalement pas survenir car des plans de requêtes parallélisés ne
        sont pas générés dans une transaction
        <foreignphrase>serializable</foreignphrase>. Néanmoins, il peut
        arriver que le niveau d'isolation de la transaction soit modifié après
        la génération du plan et avant son exécution.
      </para>
    </listitem>
  </itemizedlist>
 </sect1>

 <sect1 id="parallel-plans">
  <title>Plans parallélisés</title>

  <para>
    Comme chaque <foreignphrase>worker</foreignphrase> exécute la portion
    parallélisée du plan jusqu'à la fin, il n'est pas possible de prendre un
    plan de requête ordinaire et de l'exécuter en utilisant plusieurs
    <foreignphrase>workers</foreignphrase>. Chaque
    <foreignphrase>worker</foreignphrase> produirait une copie complète du
    jeu de résultats, donc la requête ne s'exécuterait pas
    plus rapidement qu'à la normale, et produirait des résultats incorrects.
    À la place, la portion parallélisée du plan est considéré en
    interne par l'optimiseur comme un <firstterm>plan
    partiel</firstterm>&nbsp;; c'est-à-dire construit de façon
    à ce que chaque processus exécutant le plan ne génère qu'un
    sous-ensemble des lignes en sortie, et que chacune ait la garantie d'être
    générée par exactement un des processus participants. Habituellement, cela
    signifie que le parcours de la table pour cette requête sera un parcours
    parallélisé sûr.
  </para>

 <sect2 id="parallel-scans">
  <title>Parcours parallélisées</title>

  <para>
    Les types suivants de parcours parallèles de table sont actuellement
    supportés.

  <itemizedlist>
    <listitem>
      <para>
        Lors d'un <emphasis>parcours séquentiel parallèle</emphasis>, les blocs
        de la table seront divisés entre les processus participant au parcours.
        Les blocs sont retournés un à la fois, afin que l'accès à la table
        reste séquentiel.
      </para>
    </listitem>
    <listitem>
      <para>
        Lors d'un <emphasis>parcours de bitmap parallèle</emphasis>, un
        processus est choisi pour être le dirigeant.  Ce processus effectue le
        parcours d'un ou plusieurs index et créer un bitmap indiquant les blocs
        de la table devant être visités.  Ces blocs sont alors divisés entre
        les processus participant au parcours comme lors d'un parcours d'accès
        séquentiel.  En d'autres termes, le parcours de la table est effectué
        en parallèle, mais le parcours d'index associé ne l'est pas.
      </para>
    </listitem>
    <listitem>
      <para>
        Lors d'un <emphasis>parcours d'index parallèle</emphasis> ou d'un
        <emphasis>parcours d'index seul parallèle</emphasis>, les processus
        participant au parcours se relaient pour lire les données depuis
        l'index.  Actuellement, les parcours d'index parallèles ne sont
        supportés que pour les index btree.  Chaque processus réclamera un seul
        bloc de l'index et scannera et retournera toutes les lignes référencées
        par ce bloc; les autres processus peuvent être en train de retourner
        des lignes d'un bloc différent de l'index au même moment.  Les
        résultats d'un parcours d'index parallèle sont retournés triés au sein
        de chaque worker parallèle.
      </para>
    </listitem>
  </itemizedlist>

    Les autres types de parcours, comme les parcours d'index autre que btree,
    pourraient supportés la parallélisation dans le futur.
  </para>
 </sect2>

 <sect2 id="parallel-joins">
  <title>Jointures parallélisées</title>

  <para>
    Tout comme les plans non parallèles, la table conductrice peut être jointe
    à une ou plusieurs autres tables en utilisant une boucle imbriquée, une
    jointure par hashage ou une jointure par tri-fusion.  Le côté interne de la
    jointure peut être n'importe quel type de plan non parallèle qui est par
    ailleurs supportés par l'optimiseur pourvu qu'il soit sûr de le lancer au
    sein d'un worker parallèle.  Par exemple, si une boucle imbriquée est
    choisie, le côté interne pourrait être un parcours d'index dont la valeur
    de recherche est prise depuis le côté externe de la jointure.
  </para>

  <para>
    Chaque worker exécutera la partie interne de la jointure en entier. Ce
    n'est généralement pas un problème pour les boucles imbriquées, mais cela
    peut se révéler inefficace pour les cas impliquant des jointures par
    hashage ou tri-fusion.  Par exemple, pour une jointure par hashage, cette
    restriction signifie qu'une table de hashage identique est créé dans chaque
    worker, ce qui fonctionne bien pour les jointures de petites tables mais
    qui pourrait ne pas être efficace quand la table interne est grande.  Pour
    une jointure par tri-fusion, cela pourrait signifier que chaque worker
    réalise un tri séparé de la relation interne, ce qui pourrait être lent.
    Bien entendu, dans les cas où un plan parallèle de ce type ne serait pas
    efficace, l'optimiseur de requête choisira normalement un autre type de
    plan (peut-être un qui n'utilise pas de parallélisme) à la place.
  </para>
 </sect2>

 <sect2 id="parallel-aggregation">
  <title>Agrégations parallélisées</title>
   <para>
    <productname>PostgreSQL</productname> procède à l'agrégation parallélisée
    en deux étapes. Tout d'abord, chaque processus de la
    partie parallélisée de la requête réalise une étape d'agrégation,
    produisant un résultat partiel pour chaque groupe qu'il
    connaît. Ceci se reflète dans le plan par le n&oelig;ud
    <literal>PartialAggregate</literal>. Puis les résultats partiels sont
    transférés au <foreignphrase>leader</foreignphrase> via le n&oelig;ud
    <literal>Gather</literal> ou <literal>Gather Merge</literal>. Enfin, le
    <foreignphrase>leader</foreignphrase> ré-agrège les résultats partiels de
    tous les
    <foreignphrase>workers</foreignphrase> pour produire le résultat final.
    Ceci apparaît dans le plan sous la forme d'un n&oelig;ud
    <literal>Finalize Aggregate</literal>.
   </para>
  
   <para>
    Comme le n&oelig;ud <literal>Finalize Aggregate</literal> s'exécute sur le
    processus leader, les requêtes produisant un nombre relativement important
    de groupes en comparaison du nombre de lignes en entrée apparaîtront moins
    favorable au planificateur de requêtes. Par exemple, dans le pire
    scénario, le nombre de groupes vus par le n&oelig;ud <literal>Finalize
    Aggregate</literal> pourrait être aussi grand que le nombre de lignes en
    entrée qui ont été traitées par les processus worker à l'étape
    <literal>Partial Aggregate</literal>. Dans de tels cas, il n'y aura
    clairement aucun intérêt au niveau des performances à utiliser
    l'agrégation parallélisée. Le planificateur de requêtes prend cela en
    compte lors du processus de planification et a peu de chance de choisir un
    agrégat parallélisé sur ce scénario.
   </para>

   <para>
    L'agrégation parallélisée n'est pas supportée dans toutes les situations.
    Chaque agrégat doit être <link linkend="parallel-safety">sûr à la parallélisation</link>
    et doit avoir une fonction de combinaison. Si
    l'agrégat a un état de transition de type <literal>internal</literal>, il
    doit avoir des fonctions de sérialisation et de désérialisation. Voir
    <xref linkend="sql-createaggregate"/> pour plus de détails. L'agrégation
    parallélisée n'est pas supportée si un appel à la fonction d'agrégat
    contient une clause <literal>DISTINCT</literal> ou <literal>ORDER
    BY</literal> ainsi que pour les agrégats d'ensembles triés ou quand la
    requête contient une clause <literal>GROUPING SETS</literal>. Elle ne peut
    être utilisée que si toutes les jointures impliquées dans la requête sont
    dans la partie parallélisée du plan.
   </para>
  </sect2>

 <sect2 id="parallel-plan-tips">
  <title>Conseils pour les plans parallélisés</title>

  <para>
    Si une requête ne produit pas un plan parallélisé comme attendu,
    vous pouvez tenter de réduire <xref
    linkend="guc-parallel-setup-cost"/> ou <xref linkend="guc-parallel-tuple-cost"/>.
    Bien sûr, ce plan pourrait bien finir par être plus lent que le plan sériel
    préféré par le planificateur mais ce ne sera pas toujours le cas. Si
    vous n'obtenez pas un plan parallélisé même pour de très petites valeurs
    de ces paramètres (par exemple après les avoir définis tous les deux
    à zéro), le planificateur a peut-être une bonne raison pour ne pas le faire
    pour votre requête. Voir <xref linkend="when-can-parallel-query-be-used"/>
    et <xref linkend="parallel-safety"/> pour
    des explications sur les causes possibles.
  </para>

  <para>
    Lors de l'exécution d'un plan parallélisé, vous pouvez utiliser
    <literal>EXPLAIN (ANALYZE, VERBOSE)</literal> qui affichera des
    statistiques par <foreignphrase>worker</foreignphrase> pour chaque
    n&oelig;ud du plan. Ce peut être utile pour déterminer si le travail
    est correctement distribué entre les n&oelig;uds du plan et plus
    généralement pour comprendre les caractéristiques de performance du plan.
  </para>

 </sect2>
 </sect1>

 <sect1 id="parallel-safety">
  <title>Sécurité sur la parallélisation</title>

  <para>
    Le planificateur classifie les opérations impliquées dans une requête
    comme étant <firstterm>à parallélisation sûre</firstterm>,
    <firstterm>restreintes</firstterm>, ou
	<firstterm>non sûres</firstterm>. Une opération
    à parallélisation sûre
    est une opération n'entrant pas en conflit avec une
    requête parallélisée. Une opération à parallélisation restreinte
    ne peut pas être exécutée par un
    <foreignphrase>worker</foreignphrase> parallélisé, mais peut l'être
    par le <foreignphrase>leader</foreignphrase> pendant
    l'exécution. De ce fait, les opérations à parallélisation
    restreinte ne peuvent jamais survenir sous un n&oelig;ud
    <literal>Gather</literal> ou <literal>Gather Merge</literal>. Une
    opération à parallélisation non sûre ne peut être exécutée dans une
    requête parallélisée, y compris au niveau du
    <foreignphrase>leader</foreignphrase>. Quand une requête contient quoi que
    ce soit non sûr à paralléliser, la parallélisation y est
    complètement désactivée.
  </para>

  <para>
    Les opérations suivantes sont toujours à parallélisation restreinte.
  </para>

  <itemizedlist>
    <listitem>
      <para>
        Parcours de CTE (<foreignphrase>Common Table Expressions</foreignphrase>).
      </para>
    </listitem>

    <listitem>
      <para>
        Parcours de tables temporaires.
      </para>
    </listitem>

    <listitem>
      <para>
        Parcours de tables externes, sauf si le wrapper de données distantes a
        une API <literal>IsForeignScanParallelSafe</literal> qui indique le
        contraire.
      </para>
    </listitem>

    <listitem>
      <para>
        Accès à un <literal>InitPlan</literal> ou à un
        <literal>SubPlan</literal> corrélé.
      </para>
    </listitem>
  </itemizedlist>

 <sect2 id="parallel-labeling">
  <title>Marquage de parallélisation pour les fonctions et agrégats</title>

  <para>
    Le planificateur ne peut pas déterminer automatiquement si une fonction ou
    un agrégat défini par un utilisateur est à parallélisation sûre, restreinte ou non sûre
    car cela nécessiterait de pouvoir prédire chaque opération
    réalisée par la fonction. En général, c'est équivalent au
    problème de l'arrêt et de ce fait, impossible.
    Même pour des fonctions simples où cela pourrait se faire, nous n'essayons
    pas car cela serait coûteux et sujet à erreurs. À la place, toutes les
    fonctions définies par des utilisateurs sont supposées à parallélisation non sûre
    sauf indication contraire. Lors de l'utilisation des
    instructions <xref linkend="sql-createfunction"/> et <xref
    linkend="sql-alterfunction"/>, un marquage est possible en spécifiant
    <literal>PARALLEL SAFE</literal>, <literal>PARALLEL RESTRICTED</literal>
    ou <literal>PARALLEL UNSAFE</literal> suivant ce qui est approprié. Lors
    de l'utilisation de <xref linkend="sql-createaggregate"/>, l'option
    <literal>PARALLEL</literal> peut être spécifiée comme 
    <literal>SAFE</literal>, <literal>RESTRICTED</literal> ou
    <literal>UNSAFE</literal>.
  </para>

  <para>
    Les fonctions et agrégats doivent être marqués <literal>PARALLEL
    UNSAFE</literal> s'ils écrivent dans la base, accèdent à des séquences,
    modifient l'état de la transaction même temporairement (par exemple, une
    fonction PL/pgsql qui définit un bloc <literal>EXCEPTION</literal> pour
    récupérer des erreurs), ou font des modifications persistentes sur les
    paramètres. De façon similaire, les fonctions doivent être marquées
    <literal>PARALLEL RESTRICTED</literal> si elles accèdent à des tables
    temporaires, à l'état de connexion du client, à des curseurs, à des
    requêtes préparées ou à un quelconque état local du processus serveur que le système
    ne peut pas synchroniser entre les différents
    <foreignphrase>workers</foreignphrase>. Par exemple,
    <literal>setseed</literal> et <literal>random</literal> sont à
    parallélisation restreinte pour cette dernière raison.
  </para>

  <para>
    En général, si une fonction est marquée comme étant sûre alors qu'elle ne
    l'est pas (et même si elle est seulement restreinte), ou si une fonction
    est marquée restreinte alors que sa parallélisation en fait n'est pas sûre, elle
    peut être cause d'erreurs ou de réponses fausses à
    l'utilisation dans une requête parallélisée. Les fonctions en langage C
    peuvent en théorie avoir des comportements indéfinis en cas de mauvais
    marquage car le système n'a aucun moyen de se défendre contre du code C
    arbitraire. Cela étant dit, dans la plupart des cas, le résultat ne sera pas
    pire qu'avec toute autre fonction. En cas de doute, le mieux est probablement
    de marquer les fonctions en tant que <literal>UNSAFE</literal>.
  </para>

  <para>
    Si une fonction exécutée avec un <foreignphrase>worker</foreignphrase>
    parallèle acquiert des verrous non détenus par le
    <foreignphrase>leader</foreignphrase>, par exemple en exécutant une
    requête sur une table non référencée dans la requête, ces verrous seront
    relâchés à la sortie du <foreignphrase>worker</foreignphrase>, et non pas
    à la fin de la transaction. Si vous écrivez une fonction qui fait cela et
    que cette différence de comportement a une importance pour vous, marquez ces
    fonctions comme <literal>PARALLEL RESTRICTED</literal> pour vous assurer
    qu'elles ne s'exécutent qu'au sein du
    <foreignphrase>leader</foreignphrase>.
  </para>

  <para>
    Notez que le planificateur de requêtes ne cherche pas à différer
    l'évaluation des fonctions ou agrégats à parallélisation restreinte
    impliqués dans la requête pour obtenir un meilleur plan. Donc, par
    exemple, si une clause <literal>WHERE</literal> appliquée à une table
    particulière est à parallélisation restreinte, le planificateur ne
    tentera pas de placer le parcours de cette table dans une portion
    parallélisée du plan. Dans certains cas, il serait possible 
    (voire efficace) d'inclure le parcours de cette table dans la
    partie parallèlisée de la requête et de différer l'évaluation de la 
    clause <literal>WHERE</literal> afin qu'elle se déroule au-dessus du
    n&oelig;ud <literal>Gather</literal>. Néanmoins, le planificateur ne le
    fait pas.
  </para>

 </sect2>

 </sect1>

 </chapter>
