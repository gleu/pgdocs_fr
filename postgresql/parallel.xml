<?xml version="1.0" encoding="UTF-8"?>
<!-- doc/src/sgml/parallel.sgml -->

 <chapter id="parallel-query">
  <title>Requêtes parallélisées</title>

  <indexterm zone="parallel-query">
   <primary>requête parallélisée</primary>
  </indexterm>

  <para>
   <productname>PostgreSQL</productname> peut préparer des plans de requêtes
   utilisant plusieurs CPU pour répondre plus rapidement à certaines requêtes.
   Cette fonctionnalité est connue sous le nom de requêtes parallélisées. Un
   grand nombre de requêtes ne peuvent pas bénéficier de cette fonctionnalité,
   soit à cause de la limitation de l'implémentation actuelle soit parce qu'il
   n'existe pas de plans imaginables qui seraient plus rapides qu'un plan
   sériel. Néanmoins, pour les requêtes pouvant en bénéficier, l'accélération
   due à une requête parallélisée est souvent très significative. Beaucoup de
   ces requêtes peuvent s'exécuter au moins deux fois plus rapidement grâce à
   la parallélisation., et certaines requêtes voient une amélioration de 400%,
   voire plus. Les requêtes touchant une grande quantité de données mais
   renvoyant seulement quelques lignes à l'utilisateur ont généralement celles
   qui bénéficient le plus de cette fonctionnalité. Ce chapitre explique
   certains détails sur le fonctionnement des requêtes parallélisées et dans
   quelles situations la parallélisation peut être utilisée pour que les
   utilisateurs souhaitant en profiter puissent comprendre à quoi s'attendre.
  </para>

 <sect1 id="how-parallel-query-works">
  <title>Comment fonctionne la parallélisation des requêtes</title>

   <para>
    Quand l'optimiseur détermine que la parallélisation permettra une exécution
    plus rapide d'une requête particulière, il crée un plan de requête qui inclut
    un <firstterm>n&oelig;ud Gather</firstterm>. En voici un exemple simple&nbsp;:

<screen>
EXPLAIN SELECT * FROM pgbench_accounts WHERE filler LIKE '%x%';
                                     QUERY PLAN                                      
-------------------------------------------------------------------------------------
 Gather  (cost=1000.00..217018.43 rows=1 width=97)
   Workers Planned: 2
   -&gt;  Parallel Seq Scan on pgbench_accounts  (cost=0.00..216018.33 rows=1 width=97)
         Filter: (filler ~~ '%x%'::text)
(4 rows)
</screen>
   </para>

   <para>
    Dans tous les cas, le n&oelig;ud <literal>Gather</literal> aura
    extactement un no&oelig;ud enfant, qui est la portion du plan exécutée en
    parallèle. Si le n&oelig;ud <literal>Gather</literal> est à la racine du
    plan, alors la requête entière est parallélisée. S'il est placé ailleurs
    dans le plan, alors seulement cette portion du plan s'exécutera en
    parallélisé. Dans l'exemple ci-dessus, la requête accède seulement une
    table, donc il n'existe qu'un seul autre n&oelig;ud de plan que le
    n&oelig;ud <literal>Gather</literal> lui-même&nbsp;; comme le n&oelig;ud
    du plan est un enfant du n&oelig;ud <literal>Gather</literal>, il
    s'exécutera en parallèle.
   </para>

   <para>
    En <link linkend="using-explain">utilisant EXPLAIN</link>, vous pouvez
    voir le nombre de processus d'aide (appelés
    <foreignphrase>workers</foreignphrase>) choisis par le planificateur.
    Quand le n&oelig;ud <literal>Gather</literal> est atteint lors de
    l'exécution de la requête, le processus en charge de la session de
    l'utilisateur demandera un nombre de processus <link
    linkend="bgworker">background worker</link> égal au nombre de workers
    choisi par le planificateur. Le nombre total de <foreignphrase>background
    workers</foreignphrase> pouvant exister à un moment est limité par le
    paramètre <xref linkend="guc-max-worker-processes"/>, donc il est possible
    qu'une requête parallélisée s'exécute avec moins de
    <foreignphrase>workers</foreignphrase> que prévu, voire même sans
    <foreignphrase>workers</foreignphrase> du tout. Le plan optimal pourrait
    dépendre du nombre de <foreignphrase>workers</foreignphrase> disponibles,
    ce qui pourrait résulter en de pauvres performances au niveau des
    requêtes. Si cela survient fréquemment, considérez l'augmentation de
    <varname>max_worker_processes</varname> pour qu'un plus grand nombre de
    <foreignphrase>workers</foreignphrase> puissent travailler simultanément
    ou diminuer <xref linkend="guc-max-parallel-workers-per-gather"/> pour que
    le planificateur réclame moins de <foreignphrase>workers</foreignphrase>.
   </para>

   <para>
    Chaque processus <foreignphrase>background worker</foreignphrase> démarré
    avec succès pour une requête parallélisée particulière exécutera la
    portion du plan qui est un descendant du n&oelig;ud
    <literal>Gather</literal>. Le processus principal, appelé
    <foreignphrase>leader</foreignphrase>, exécutera aussi cette portion du
    plan bien qu'il ait des responsabilités supplémentaires&nbsp;: il doit
    aussi lire toutes les lignes générées par les
    <foreignphrase>workers</foreignphrase>. Quand la portion parallélisée du
    plan génère seulement un petit nombre de lignes, le
    <foreignphrase>leader</foreignphrase> se comportera souvent comme un
    <foreignphrase>worker</foreignphrase> supplémentaire, accélérant
    l'exécution de la requête. Par contre, quand la portion parallèle du plan
    génère un grand nombre de lignes, le <foreignphrase>leader</foreignphrase>
    pourrait être totalement occupée par la lecture des lignes générées par
    les <foreignphrase>workers</foreignphrase> et par le traitement de toute
    étape supplémntaire requis par les n&oelig;uds suivants du plan. Dans de
    tels cas, le <foreignphrase>leader</foreignphrase> travaillera peu sur la
    portion parallélisée du plan.
   </para>
 </sect1>

 <sect1 id="when-can-parallel-query-be-used">
  <title>Quand la parallélisation des requêtes peut-elle être utilisée&nbsp;?</title>

  <para>
    Il existe plusieurs paramètres pouvant faire en sorte que le planificateur
    de la requête ne génère pas un plan parallélisé quelque soit les
    circonstances. Pour faire en sorte que des plans parallélisés puissent
    être générés, les paramètres suivants doivent être configurés comme
    indiqués.
  </para>

  <itemizedlist>
    <listitem>
      <para>
        <xref linkend="guc-max-parallel-workers-per-gather"/> doit être
        configuré à une valeur strictement positive. Ceci est un cas spécial
        du principe plus général qu'il n'y aura pas plus de
        <foreignphrase>workers</foreignphrase> que le nombre configuré via
        <varname>max_parallel_workers_per_gather</varname>.
      </para>
    </listitem>

    <listitem>
      <para>
        <xref linkend="guc-dynamic-shared-memory-type"/> doit être configuré à
        une valeur autre que <literal>none</literal>. Les requêtes
        parallélisées nécessitent de la mémoire partagée dynamique pour
        fournir des données entre les processus participant à la
        parallélisation.
      </para>
    </listitem>
  </itemizedlist>

  <para>
    De plus, le système ne doit pas fonctionner en mode mono-utilisateur.
    Comme le système de bases de données entier fonctionne avec un seul
    processus dans cette situation, aucun <foreignphrase>background
    worker</foreignphrase> ne sera disponible dans ce cas.
  </para>

  <para>
    Même quand il est habituellement possible de générer des plans pour
    des requêtes parallélisées, le planificateur pourrait ne pas en générer
    pour une requête particulière si une des conditions suivantes est
    vérifiée&nbsp;:
  </para>

  <itemizedlist>
    <listitem>
      <para>
        La requête écrit des données ou verrouille des lignes de la base. Si
        une requête contient une opération de modification de données, soit au
        niveau supérieur, soit dans une CTE, aucun plan parallèle ne peut être
        généré pour cette requête. Ceci est une limitation de l'implémentation
        actuelle qui pourrait être supprimée dans une prochaine version.
      </para>
    </listitem>

    <listitem>
      <para>
        La requête pourrait être suspendue dans son exécution. Dans des
        situations où le système pense qu'une exécution partielle ou
        incrémentale pourrait survenir, aucun plan parallèle n'est proposé.
        Par exemple, un curseur créé en utilisant <link
        linkend="sql-declare">DECLARE CURSOR</link> n'utilisera jamais un plan
        parallélisé. De façon similaire, une boucle PL/pgsql de la forme
        <literal>FOR x IN query LOOP .. END LOOP</literal> n'utilisera jamais
        un plan parallélisé car le système est incapable de vérifier que le
        code dans la boucle peut s'exécuter en toute sécurité avec une requête
        parallélisée.
      </para>
    </listitem>

    <listitem>
      <para>
        La requête utilise une fonction marquée <literal>PARALLEL UNSAFE</literal>.
        La plupart des fonctions systèmes sont <literal>PARALLEL SAFE</literal>,
        mais les fonctions utilisateurs sont marquées <literal>PARALLEL
        UNSAFE</literal> par défaut. Voir la discussion de
        <xref linkend="parallel-safety"/>.
      </para>
    </listitem>

    <listitem>
      <para>
        La requête est exécutée à l'intérieur d'une autre requête qui est déjà
        parallélisée. Par exemple, si une fonction appelée par une requête
        parallélisée exécute elle-même une requête SQL, cette requête
        n'utilisera jamais un plan parallélisé. Ceci est une limitation de
        l'implémentation actuelle mais il n'est pas forcément souhaitable de
        supprimer cette limitation car cela pourrait résulter en une requête
        simple utilisant un très grand nombre de processus.
      </para>
    </listitem>

    <listitem>
      <para>
        Le niveau d'isolation de la transaction est le niveau
        <foreignphrase>serializable</foreignphrase>. Ceci est une limitation
        de l'implémentation actuelle.
      </para>
    </listitem>
  </itemizedlist>

  <para>
    Même quand un plan parallélisé est généré pour une requête particulière,
    différentes circonstances font qu'il sera impossible d'exécuter ce plan en
    parallèle au moment de l'exécution. Si cela survient, le
    <foreignphrase>leader</foreignphrase> exécutera tout seul la portion du
    plan sous le n&oelig;ud <literal>Gather</literal>, pratiquement comme si
    ce n&oelig;ud <literal>Gather</literal> n'était pas présent. Ceci
    surviendra si une des conditions suivantes est vérifiée&nbsp;:
  </para>

  <itemizedlist>
    <listitem>
      <para> 
        Aucun <foreignphrase>background worker</foreignphrase> ne peut être
        obtenu à cause d'une limitation sur le nombre total de
        <foreignphrase>background workers</foreignphrase>, due au paramètre
        <xref linkend="guc-max-worker-processes"/>.
      </para>
    </listitem>

    <listitem>
      <para> 
        Le client envoie un message Execute avec un nombre à récupérer
        différent de zéro. Voir la discussion sur le <link
        linkend="protocol-flow-ext-query">protocole de requête étendu</link>.
        Comme la bibliothèque <link linkend="libpq">libpq</link> ne fournit
        actuellement aucun moyen pour envoyer ce type de message, cela peut
        seulement survenir suite à l'utilisation d'un client qui ne se base
        pas sur la libpq. Si cela arrive fréquemment, il pourrait être une
        bonne idée de configurer <xref
        linkend="guc-max-parallel-workers-per-gather"/> pour les sessions où
        cela pourrait survenir, pour éviter de générer des plans de requêtes
        non optimales s'ils sont exécutés de façon sérialisé.
      </para>
    </listitem>

    <listitem>
      <para>
        Le niveau de transaction est
        <foreignphrase>serializable</foreignphrase>. Cette situation ne doit
        normalement pas survenir car les plans de requêtes parallélisées ne
        sont pas générés quand le niveau d'isolation de la transaction est
        <foreignphrase>serializable</foreignphrase>. Néanmoins, cela peut
        arriver si le niveau d'isolation de la transaction est modifié après
        la génération du plan et avant son exécution.
      </para>
    </listitem>
  </itemizedlist>
 </sect1>

 <sect1 id="parallel-plans">
  <title>Plans parallélisés</title>

  <para>
    Comme chaque <foreignphrase>worker</foreignphrase> exécute la portion
    parallélisée du plan jusqu'à la fin, il n'est pas possible de prendre un
    plan de requête ordinaire et de l'exécuter en utilisant plusieurs
    <foreignphrase>workers</foreignphrase>. Chaque
    <foreignphrase>worker</foreignphrase> produirait une copie complète du
    jeu de résultats, donc la requête  ne s'exécuterait pas
    plus rapidement qu'à la normale, et produirait des résultats incorrects.
    À la place, la portion parallélisée du plan doit être ce qui est connu en
    interne par l'optimiseur de requêtes comme un <firstterm>plan
    partiel</firstterm>&nbsp;; c'est-à-dire qu'il doit être construit de façon
    à ce que chaque processus exécutant le plan génère seulement un
    sous-ensemble des lignes en sortie et que chacune
    ait la garantie d'être générée par exactement un des
    processus participants.
  </para>

 <sect2 id="parallel-scans">
  <title>Parcours parallélisées</title>

  <para>
    Actuellement, le seul type de parcours qui ait été modifié pour fonctionner
    avec des requêtes parallélisées est le parcours séquentiel (<literal>Seq Scan</literal>). De ce fait, la
    table en question dans un plan parallélisé sera toujours parcourue en
    utilisant un <literal>Parallel Seq Scan</literal>. Les blocs de la
    relation sont répartis entre les processus participants. Les blocs sont
    gérés un par un, donc cet accès à la relation reste séquentiel. Chaque
    processus visite chaque ligne du bloc qui lui est assigné avant de
    réclamer un nouveau bloc.
  </para>
 </sect2>

 <sect2 id="parallel-joins">
  <title>Jointures parallélisées</title>

  <para>
    La table peut être jointe à une ou plusieurs autres tables en utilisant
    une boucle imbriquée (<foreignphrase>nested loop</foreignphrase>
    ou une jointure par hachage (<foreignphrase>hash join</foreignphrase> ). 
    Le côté externe de la
    jointure peut être n'importe quel type de plan non parallélisé
    supporté par le planificateur par ailleurs, pourvu qu'il soit sûr de l'exécuter
    dans un <foreignphrase>worker</foreignphrase> parallélisé. Par exemple,
    ce peut être un parcours d'index recherchant une valeur basée sur
    une colonne prise dans la table interne. Chaque
    <foreignphrase>worker</foreignphrase> exécutera le côté externe du plan en
    totalité, ce qui explique pourquoi les jointures par tri (<foreignphrase>merge join</foreignphrase>) ne sont pas
    supportées ici. Le côté externe d'une jointure par tri implique souvent
    le tri complet de la table interne&nbsp;; même avec un index, 
    plusieurs processus réalisant
    chacun un parcours d'index complet de la table intérieure est rarement efficace.
  </para>
 </sect2>

 <sect2 id="parallel-aggregation">
  <title>Agrégations parallélisées</title>
   <para>
    Il n'est pas possible de réaliser la portion agrégée d'une requête
    totalement en parallèle. Par exemple, si une requête implique la sélection
    de <literal>COUNT(*)</literal>, chaque
    <foreignphrase>worker</foreignphrase> peut calculer un total, mais ces
    totaux doivent être combinés pour produire la réponse finale. Si la
    requête implique une clause <literal>GROUP BY</literal>, un total séparé
    doit être calculé pour chaque groupe. Même si l'agrégat ne peut pas être
    entièrement fait en parallèle, les requêtes impliquant un agrégat sont
    souvent d'excellents candidats pour des requêtes parallélisées parce
    qu'elles vont typiquement lire beaucoup de lignes tout en en renvoyant peu
    au client. Les requêtes qui renvoient de nombreuses lignes au client sont
    souvent limitées par la vitesse à laquelle le client peut lire les
    données, auquel cas une requête parallélisée ne peut pas tellement aider.
   </para>

   <para>
    <productname>PostgreSQL</productname> supporte les agrégats parallélisés
    en agrégeant deux fois. Tout d'abord, chaque processus participant à la
    portion parallélisée de la requête réalise une étape d'agrégation,
    produisant un resultat partiel pour chaque groupe que ce processus
    connaît. Ceci est reflété dans le plan avec le n&oelig;ud
    <literal>PartialAggregate</literal>. Ensuite, les résultats partiels sont
    transférés au <foreignphrase>leader</foreignphrase> via le n&oelig;ud
    <literal>Gather</literal>. Enfin, le <foreignphrase>leader</foreignphrase>
    ré-agrège les résultats partiels de tous les
    <foreignphrase>workers</foreignphrase> pour produire le résultat final.
    Ceci est reflété dans le plan sous la forme d'un n&oelig;ud
    <literal>FinalizeAggregate</literal>.
   </para>

   <para>
    L'agrégation parallélisée n'est pas supportée dans toutes les situations.
    Chaque agrégat doit être <link linkend="parallel-safety">sûr</link> pour
    une bonne parallélisation et doit avoir une fonction de combinaison. Si
    l'agrégat a un état de transition de type <literal>internal</literal>, il
    doit avoir des fonctions de sérialisation et de désérialisation. Voir
    <xref linkend="sql-createaggregate"/> pour plus de détails. L'agrégation
    parallélisée n'est pas supportée pour les agrégats d'ensemble ordonné ou
    quand la requête implique la clause <literal>GROUPING SETS</literal>. Elle
    peut seulement être utilisée quand toutes les jointures impliquées dans la
    requêtes font partie de la portion parallélisée du plan.
   </para>
  </sect2>

 <sect2 id="parallel-plan-tips">
  <title>Conseils pour les plans parallélisés</title>

  <para>
    Si une requête qu'on s'attend à voir utiliser un plan parallélisé ne le
    fait pas, vous pouvez tenter de réduire <xref
    linkend="guc-parallel-setup-cost"/> ou <xref linkend="guc-parallel-tuple-cost"/>.
    Bien sûr, ce plan pourrait devenir plus lent que le plan sériel
    que le planificateur préfèrait mais ce ne sera pas toujours le cas. Si
    vous n'obtenez pas un plan parallélisé même pour de très petites valeurs
    de ces paramètres (c'est-à-dire après les avoir définies tous les deux
    à zéro), il pourrait exister une raison pour laquelle le
    planificateur de requêtes est incapable de générer un plan parallélisé
    pour votre requête. Voir <xref linkend="when-can-parallel-query-be-used"/>
    et <xref linkend="parallel-safety"/> pour des informations pouvant
    expliquer pourquoi cela serait le cas.
  </para>

  <para>
    Lors de l'exécution d'un plan parallélisé, vous pouvez utiliser
    <literal>EXPLAIN (ANALYZE, VERBOSE)</literal> qui affichera des
    statistiques par <foreignphrase>worker</foreignphrase> pour chaque
    n&oelig;ud du plan. Ce pourrait être utile pour déterminer si le travail
    est correctement distribué entre les n&oelig;uds du plan et plus
    généralement pour comprendre les caractéristiques de performance du plan.
  </para>

 </sect2>
 </sect1>

 <sect1 id="parallel-safety">
  <title>Sécurité sur la parallélisation</title>

  <para>
    Le planificateur classifie les opérations impliquées dans une requête
    comme étant soit <firstterm>sûres à paralléliser</firstterm>,
    <firstterm>restreintes pour la parallélisation</firstterm>, ou
	<firstterm>non sûres à la parallélisation</firstterm>. Une opération
	sûre à la parallélisation
    est une opération qui n'entre pas en conflit avec l'utilisation d'une
    requête parallélisée. Une opération restreinte à la parallélisation est
    une opération qui ne peut pas être exécutée par un
    <foreignphrase>worker</foreignphrase> parallélisé, mais qui peut l'être
    par le <foreignphrase>leader</foreignphrase> alors que la requête
    parallélisée est en cours d'exéuction. De ce fait, les opérations
    restreintes ne peuvent jamais survenir sous un n&oelig;ud
    <literal>Gather</literal>. Une opération non sûre à la parallélisation est
    une opération qui ne peut pas être réalisée quand une requête est
    parallélisée, y compris au niveau du
    <foreignphrase>leader</foreignphrase>. Quand une requête contient quoi que
    ce soit qui n'est pas sûr à la parallélisation, la parallélisation est
    globalement désactivée pour cette requête.
  </para>

  <para>
    Les opérations suivantes sont toujours restreintes en terme de
    parallélisation.
  </para>

  <itemizedlist>
    <listitem>
      <para>
        Parcours de CTE (<foreignphrase>Common Table Expressions</foreignphrase>).
      </para>
    </listitem>

    <listitem>
      <para>
        Parcours de tables temporaires.
      </para>
    </listitem>

    <listitem>
      <para>
        Parcours de tables externes, sauf si le wrapper de données distantes a
        une API <literal>IsForeignScanParallelSafe</literal> qui indique le
        contraire.
      </para>
    </listitem>

    <listitem>
      <para>
        Accès à un <literal>InitPlan</literal> ou à un
        <literal>SubPlan</literal>.
      </para>
    </listitem>
  </itemizedlist>

 <sect2 id="parallel-labeling">
  <title>Marquage de parallélisation pour les fonctions et agrégats</title>

  <para>
    Le planificateur ne peut pas déterminer automatiquement si une fonction ou
    un agrégat défini par un utilisateur est sûr, restreint ou non sûr pour la
    parallélisation car cela nécessiterait de pouvoir prédire chaque opération
    réalisée par la fonction. En général, c'est équivalent au
    problème de l'arrêt et de ce fait, impossible.
    Même pour des fonctions simples où cela pourrait se faire, nous n'essayons
    pas car cela serait coûteux et sujet à erreurs. À la place, toutes les
    fonctions définies par des utilisateurs sont supposées non sûres à la
    parallélisation sauf indication contraire. Lors de l'utilisation des
    instructions <xref linkend="sql-createfunction"/> et <xref
    linkend="sql-alterfunction"/>, un marquage est possible en spécifiant
    <literal>PARALLEL SAFE</literal>, <literal>PARALLEL RESTRICTED</literal>
    ou <literal>PARALLEL UNSAFE</literal> suivant ce qui est approprié. Lors
    de l'utilisation de <xref linkend="sql-createaggregate"/>, l'option
    <literal>PARALLEL</literal> peut être spécifiée comme 
    <literal>SAFE</literal>, <literal>RESTRICTED</literal> ou
    <literal>UNSAFE</literal>.
  </para>

  <para>
    Les fonctions et agrégats doivent être marqués <literal>PARALLEL
    UNSAFE</literal> s'ils écrivent dans la base, accèdent à des séquences,
    modifient l'état de la transaction même temporairement (par exemple, une
    fonction PL/pgsql qui définit un bloc <literal>EXCEPTION</literal> pour
    récupérer des erreurs), ou font des modifications persistentes sur les
    paramètres. De façon similaire, les fonctions doivent être marquées
    <literal>PARALLEL RESTRICTED</literal> si elles accèdent à des tables
    temporaires, à l'état de connexion du client, à des curseurs, à des
    requêtes préparées ou à un quelconque état local du processus serveur que le système
    ne peut pas synchroniser entre les différents
    <foreignphrase>workers</foreignphrase>. Par exemple,
    <literal>setseed</literal> et <literal>random</literal> sont restreints en
    terme de parallélisation pour cette dernière raison.
  </para>

  <para>
    En général, si une fonction est marquée comme étant sûre alors qu'elle ne
    l'est pas (et même si elle est seulement restreinte), ou si une fonction
    est marquée restreinte alors que sa parallélisation n'est pas sûre, elle
    pourrait être la cause d'erreurs ou de réponses fausses à
    l'utilisation dans une requête parallélisée. Les fonctions en langage C
    pourraient en théorie avoir des comportements indéfinis en cas de mauvais
    marquage car le système n'a aucun moyen de se défendre contre du code C
    arbitraire. Cela étant dit, dans la plupart des cas, le résultat ne sera pas
    pire qu'avec toute autre fonction. En cas de doute, le mieux est probablement
    de marquer les fonctions en tant que <literal>UNSAFE</literal>.
  </para>

  <para>
    Si une fonction exécutée avec un <foreignphrase>worker</foreignphrase>
    parallèle acquiert des verrous non détenus par le
    <foreignphrase>leader</foreignphrase>, par exemple en exécutant une
    requête sur une table non référencée dans la requête, ces verrous seront
    relâchés à la sortie du <foreignphrase>worker</foreignphrase>, et non pas
    à la fin de la transaction. Si vous écrivez une fonction qui fait cela et
    que cette différence de comportement a une importance pour vous, marquez ces
    fonctions comme <literal>PARALLEL RESTRICTED</literal> pour vous assurer
    qu'elles ne s'exécutent qu'au sein du
    <foreignphrase>leader</foreignphrase>.
  </para>

  <para>
    Notez que le planificateur de requêtes ne considère pas de différer
    l'évaluation des fonctions ou agrégats restreints en parallélisation
    impliquées dans la requête pour obtenir un plan supérieur. Donc, par
    exemple, si une clause <literal>WHERE</literal> appliquée à une table
    particulière est restreinte à la parallélisation, le planificateur ne
    tentera pas de placer le parcours de cette table sous un n&oelig;ud
    <literal>Gather</literal>. Dans certains cas, il serait possible 
    (voire efficace) d'inclure le parcours de cette table dans la
    partie parallèlisée de la requête et de différer l'évaluation de la 
    clause <literal>WHERE</literal> afin qu'elle se déroule au-dessus du
    n&oelig;ud <literal>Gather</literal>. Néanmoins, le planificateur ne le
    fait pas.
  </para>

 </sect2>

 </sect1>

 </chapter>
