<?xml version="1.0" encoding="ISO-8859-15"?>
<!-- Dernière modification
     le       $Date$
     par      $Author$
     révision $Revision$ -->

 <chapter id="performance-tips">
  <title>Conseils sur les performances</title>

  <indexterm zone="performance-tips">
    <primary>performance</primary>
  </indexterm>

  <para>
   La performance des requêtes peut être affectée par un grand nombre d'éléments.
   Certains peuvent être contrôlés par l'utilisateur, d'autres sont
   fondamentaux au concept sous-jacent du système. Ce chapitre fournit des
   conseils sur la compréhension et sur la configuration fine des performances
   de <productname>PostgreSQL</productname>.
  </para>

  <sect1 id="using-explain">
   <title>Utiliser <command>EXPLAIN</command></title>

   <indexterm zone="using-explain">
    <primary>EXPLAIN</primary>
   </indexterm>

   <indexterm zone="using-explain">
    <primary>plan de requête</primary>
   </indexterm>

   <para>
    <productname>PostgreSQL</productname> réalise un <firstterm>plan
    de requête</firstterm> pour chaque requête qu'il reçoit. Choisir le bon
    plan correspondant à la structure de la requête et aux propriétés des
    données est absolument critique pour de bonnes performances, donc le système
    inclut un <firstterm>planificateur</firstterm> complexe qui tente de choisir
    les bons plans. Vous pouvez
    utiliser la commande <xref linkend="sql-explain"/>
    pour voir quel plan de requête le planificateur crée pour une requête particulière.
    La lecture du plan est un art qui mérite un tutoriel complet, ce que vous
    n'aurez pas là&nbsp;; ici ne se trouvent que des informations de base.
   </para>

   <para>
    La structure d'un plan de requête est un arbre de <firstterm>n&oelig;uds
    de plan</firstterm>. Les n&oelig;uds de bas niveau sont les n&oelig;uds de parcours
    de tables&nbsp;: ils renvoient les lignes brutes d'une table. Il existe
    différents types de n&oelig;uds de parcours pour les différentes méthodes
    d'accès aux tables&nbsp;: parcours séquentiel, parcours d'index et parcours
    d'index bitmap. Si la requête requiert des jointures, agrégations, tris
    ou d'autres opérations sur les lignes brites, ce seront des n&oelig;uds
    supplémentaires au-dessus des n&oelig;uds de parcours pour réaliser ces
    opérations. Encore une fois, il existe plus d'une façon de réaliser ces
    opérations, donc différents types de n&oelig;uds peuvent aussi apparaître
    ici.  La sortie
    d'<command>EXPLAIN</command> comprend une ligne pour chaque n&oelig;ud dans
    l'arbre du plan, montrant le type de n&oelig;ud basique avec les estimations
    de coût que le planificateur a fait pour l'exécution de ce n&oelig;ud du
    plan. La première ligne (le n&oelig;ud tout en haut) comprend le coût
    d'exécution total estimé pour le plan&nbsp;; c'est ce nombre que le
    planificateur cherche à minimiser.
   </para>

   <para>
    Voici un exemple trivial, juste pour montrer à quoi ressemble l'affichage.
    <footnote>
     <para>
      Les exemples dans cette section sont récupérés de la base de données des
      tests de régression après avoir lancé un <command>VACUUM ANALYZE</command>, en
      utilisant les sources de la version 8.2. Vous devriez être capable
      d'obtenir des résultats similaires si vous essayez vous-même les exemples
      mais vos coûts estimés et les nombres de lignes varieront probablement
      légèrement car les statistiques d'<command>ANALYZE</command> se font à partir de
      valeurs prises au hasard.
     </para>
    </footnote>

<programlisting>EXPLAIN SELECT * FROM tenk1;

                         QUERY PLAN
-------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)</programlisting>
   </para>

   <para>
    Les nombres donnés par <command>EXPLAIN</command> sont (de gauche à droite)&nbsp;:

    <itemizedlist>
     <listitem>
      <para>
       Coût estimé du lancement (temps passé avant que l'affichage de
       la sortie ne commence, c'est-à-dire pour faire le tri dans un n&oelig;ud
       de tri)&nbsp;;
      </para>
     </listitem>

     <listitem>
      <para>
       Coût total estimé (si toutes les lignes doivent être récupérées, ce qui
       pourrait ne pas être le cas&nbsp;: par exemple une requête avec une
       clause <literal>LIMIT</literal> ne paiera pas le coût total du n&oelig;ud
       d'entrée du n&oelig;ud du plan <literal>Limit</literal>)&nbsp;;
      </para>
     </listitem>

     <listitem>
      <para>
       Nombre de lignes estimé en sortie par ce n&oelig;ud de plan (encore une
       fois, seulement si exécuté jusqu'au bout)&nbsp;;
      </para>
     </listitem>

     <listitem>
      <para>
       Largeur moyenne estimée (en octets) des lignes en sortie par ce
       n&oelig;ud de plan.
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
    Les coûts sont mesurés en unités arbitraires déterminées par les paramètres
    de coût du planificateur (voir <xref linkend="runtime-config-query-constants"/>).
    La pratique habituelle est de mesurer les coûts en unité de récupération de
    pages disque&nbsp;; autrement dit, <xref linkend="guc-seq-page-cost"/> est
    initialisé à <literal>1.0</literal> par convention et les autres paramètres
    de coût sont relatifs à cette valeur. Les exemples de cette section sont
    exécutés avec les paramètres de coût par défaut.
   </para>

   <para>
    Il est important de noter que le coût d'un n&oelig;ud de haut niveau inclut
    le coût de tous les n&oelig;uds fils. Il est aussi important de réaliser
    que le coût reflète seulement les éléments d'importance pour le
    planificateur. En particulier, le coût ne considère pas le temps
    dépensé dans la transmission des lignes de résultat au client, ce qui
    pourrait être un facteur important dans le temps réel passé&nbsp;; mais
    le planificateur l'ignore parce qu'il ne peut pas le changer en modifiant
    le plan (chaque plan correct sortira le même ensemble de lignes).
   </para>

   <para>
    La valeur <literal>rows</literal> est un peu difficile car il ne s'agit
    <emphasis>pas</emphasis> du nombre de lignes traitées ou parcourues par le
    plan de n&oelig;uds. C'est habituellement moins, reflétant la sélectivité
    estimée des conditions de la clause <literal>WHERE</literal> qui sont appliquées au
    n&oelig;ud. Idéalement, les estimations des lignes de haut niveau sera une
    approximation des nombres de lignes déjà renvoyées, mises à jour, supprimées
    par la requête.
   </para>

   <para>
    Pour revenir à notre exemple&nbsp;:

<programlisting>EXPLAIN SELECT * FROM tenk1;

                         QUERY PLAN
-------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)</programlisting>
   </para>

   <para>
    C'est aussi direct que ce que nous obtenons. Si vous faîtes&nbsp;:

<programlisting>SELECT relpages, reltuples FROM pg_class WHERE relname = 'tenk1';</programlisting>

    vous trouverez que <classname>tenk1</classname> a 358 pages disque et 10000
    lignes. Le coût estimé est calculé avec (nombre de pages lues *
    <xref linkend="guc-seq-page-cost"/>) + (lignes parcourues *
    <xref linkend="guc-cpu-tuple-cost"/>).  Par défaut,
    <varname>seq_page_cost</varname> vaut 1.0 et <varname>cpu_tuple_cost</varname>
    vaut 0.01. Donc le coût estimé est de (358 * 1.0) + (10000 * 0.01),
    soit 458.
   </para>

   <para>
    Maintenant, modifions la requête originale pour ajouter une condition
    <literal>WHERE</literal>&nbsp;:

<programlisting>EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 7000;

                         QUERY PLAN
------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..483.00 rows=7033 width=244)
   Filter: (unique1 &lt; 7000)</programlisting>

    Notez que l'affichage d'<command>EXPLAIN</command> montre la clause <literal>WHERE</literal>
    appliquée comme une condition de <quote>filtre</quote>&nbsp;; ceci signifie que le
    n&oelig;ud de plan vérifie la condition pour chaque ligne qu'il parcourt et
    ne conserve que celles qui satisfont la condition.
    L'estimation des lignes en sortie a baissé à cause de la clause
    <literal>WHERE</literal>. Néanmoins, le parcours devra toujours visiter les 10000
    lignes, donc le coût n'a pas baissé&nbsp;; en fait, il a un peu augmenté
    (par 10000 * <xref linkend="guc-cpu-operator-cost"/> pour être exact)
    dans le but de refléter le temps CPU supplémentaire dépensé pour vérifier
    la condition <literal>WHERE</literal>.
   </para>

   <para>
    Le nombre réel de lignes que cette requête sélectionnera est 7000 mais
    l'estimation <literal>rows</literal> est approximative. Si vous tentez
    de dupliquer cette
    expérience, vous obtiendrez probablement une estimation légèrement
    différente&nbsp;; de plus, elle changera après chaque commande
    <command>ANALYZE</command> parce que les statistiques produites par
    <command>ANALYZE</command> sont prises à partir d'un extrait au hasard de la
    table.
   </para>

   <para>
    Maintenant, rendons la condition plus restrictive&nbsp;:

<programlisting>EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100;

                                  QUERY PLAN
------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=2.37..232.35 rows=106 width=244)
   Recheck Cond: (unique1 &lt; 100)
   ->  Bitmap Index Scan on tenk1_unique1  (cost=0.00..2.37 rows=106 width=0)
         Index Cond: (unique1 &lt; 100)</programlisting>

    Ici, le planificateur a décidé d'utiliser un plan en deux étapes&nbsp;: le
    n&oelig;ud en bas du plan visite un index pour trouver l'emplacement des
    lignes correspondant à la condition de l'index, puis le n&oelig;ud du plan
    du dessus récupère réellement ces lignes de la table. Récupérer séparément
    les lignes est bien plus coûteux que de les lire séquentiellement mais
    comme toutes les pages de la table n'ont pas à être visitées, cela revient
    toujours moins cher qu'un parcours séquentiel (la raison de l'utilisation
    d'un plan à deux niveaux est que le n&oelig;ud du plan du dessus trie les
    emplacements des lignes identifiés par l'index dans l'ordre physique avant
    de les lire pour minimiser les coûts des récupérations séparés. Le
    <quote>bitmap</quote> mentionné dans les noms de n&oelig;uds est le mécanisme
    qui s'occupe du tri).
   </para>

   <para>
    Si la condition <literal>WHERE</literal> est assez sélective, le planificateur
    pourrait basculer vers un plan de parcours d'index
    <quote>simple</quote>&nbsp;:

<programlisting>EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 3;

                                  QUERY PLAN
------------------------------------------------------------------------------
 Index Scan using tenk1_unique1 on tenk1  (cost=0.00..10.00 rows=2 width=244)
   Index Cond: (unique1 &lt; 3)</programlisting>

    Dans ce cas, les lignes de la table sont récupérées dans l'ordre de l'index,
    ce qui les rend encore plus coûteuses à lire mais elles sont si peu
    nombreuses que le coût supplémentaire de triage des emplacements de lignes
    ne vaut pas le coup. Vous verrez plus fréquemment ce type de plan pour les
    requêtes qui récupèrent une seule ligne et pour les requêtes qui ont
    une condition <literal>ORDER BY</literal> correspondant à l'ordre de l'index.
   </para>

   <para>
    Ajoutez une autre condition à la clause <literal>WHERE</literal>&nbsp;:

<programlisting>EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 3 AND stringu1 = 'xxx';

                                  QUERY PLAN
-------------------------------------------------------------------------------
 Index Scan using tenk1_unique1 on tenk1  (cost=0.00..10.01 rows=1 width=244)
   Index Cond: (unique1 &lt; 3)
   Filter: (stringu1 = 'xxx'::name)</programlisting>

    La condition ajoutée <literal>stringu1 = 'xxx'</literal> réduit
    l'estimation du nombre de lignes en sortie mais pas le coût car nous devons
    toujours visiter le même ensemble de lignes. Notez que la clause
    <literal>stringu1</literal> ne peut pas être appliqué à une condition d'index (car
    cet index est seulement sur la colonne <literal>unique1</literal>). À la place, il
    est appliqué comme un filtre sur les lignes récupérées par l'index. Du coup,
    le coût a un peu augmenté pour refléter cette vérification supplémentaire.
   </para>

   <para>
    S'il existe des index sur plusieurs colonnes référencées dans la condition
    <literal>WHERE</literal>, le planificateur pourrait choisir d'utiliser une
    combinaison AND ou OR des index&nbsp;:

<programlisting>EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;

                                     QUERY PLAN
-------------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=11.27..49.11 rows=11 width=244)
   Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
   -&gt;  BitmapAnd  (cost=11.27..11.27 rows=11 width=0)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..2.37 rows=106 width=0)
               Index Cond: (unique1 &lt; 100)
         -&gt;  Bitmap Index Scan on tenk1_unique2  (cost=0.00..8.65 rows=1042 width=0)
               Index Cond: (unique2 &gt; 9000)</programlisting>

    Mais ceci requiert de visiter plusieurs index, donc ce n'est pas nécessaire
    un gain comparé à l'utilisation d'un seul index et au traitement de l'autre
    condition par un filtre. Si vous variez les échelles de valeurs impliquées,
    vous vous apercevrez que le plan change en accord.
   </para>

   <para>
    Maintenant, essayons de joindre deux tables, en utilisant les colonnes dont
    nous avons discuté&nbsp;:

<programlisting>EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                      QUERY PLAN
--------------------------------------------------------------------------------------
 Nested Loop  (cost=2.37..553.11 rows=106 width=488)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=2.37..232.35 rows=106 width=244)
         Recheck Cond: (unique1 &lt; 100)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..2.37 rows=106 width=0)
               Index Cond: (unique1 &lt; 100)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.00..3.01 rows=1 width=244)
         Index Cond: (t2.unique2 = t1.unique2)</programlisting>
   </para>

   <para>
    Dans cette jointure en boucle imbriquée, le parcours externe utilise le même
    parcours de bitmap que celui vu précédemment et donc son
    coût et le nombre de lignes sont les mêmes parce que nous appliquons la
    clause <literal>WHERE</literal> <literal>unique1 &lt; 100</literal> à ce n&oelig;ud.
    La clause <literal>t1.unique2 = t2.unique2</literal> n'a pas encore
    d'intérêt donc elle n'affecte pas le nombre de lignes du parcours externe.
    Pour le parcours interne, la valeur <literal>unique2</literal> de la ligne courante
    du parcours externe est connectée dans le parcours d'index interne pour
    produire une condition d'index identique à <literal>t2.unique2 =
    <replaceable>constante</replaceable></literal>. Donc, nous obtenons le même
    plan de parcours interne et les coûts que nous obtenons de, disons,
    <literal>EXPLAIN SELECT * FROM tenk2 WHERE unique2 = 42</literal>. Les coûts
    du n&oelig;ud correspondant à la boucle sont ensuite initialisés sur la base
    du coût du parcours externe, avec une répétition du parcours interne pour
    chaque ligne externe (ici, 106 * 3.01), plus un petit temps CPU pour traiter
    la jointure.
   </para>

   <para>
    Dans cet exemple, le nombre de lignes en sortie de la jointure est
    identique aux nombres de lignes des deux parcours mais ce n'est pas vrai
    en règle générale car vous pouvez avoir des clauses <literal>WHERE</literal>
    mentionnant les deux tables et qui, donc, peuvent seulement être appliquées au
    point de jointure, et non pas aux parcours d'index. Par exemple, si nous avions
    ajouté <literal>WHERE ... AND t1.hundred &lt; t2.hundred</literal>, cela
    aurait diminué le nombre de lignes en sortie du n&oelig;ud de jointure mais
    cela n'aurait pas changé les parcours d'index.
   </para>

   <para>
    Une façon de rechercher des plans différents est de forcer le planificateur
    à oublier certaines stratégies qu'il aurait trouvé moins coûteuses en
    utilisant les
    options d'activation (enable)/désactivation (disable) décrites dans la <xref
    linkend="runtime-config-query-enable"/> (c'est un outil complexe mais utile&nbsp;;
    voir aussi la <xref linkend="explicit-joins"/>).

<programlisting>SET enable_nestloop = off;
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                        QUERY PLAN
------------------------------------------------------------------------------------------
 Hash Join  (cost=232.61..741.67 rows=106 width=488)
   Hash Cond: (t2.unique2 = t1.unique2)
   -&gt;  Seq Scan on tenk2 t2  (cost=0.00..458.00 rows=10000 width=244)
   -&gt;  Hash  (cost=232.35..232.35 rows=106 width=244)
         -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=2.37..232.35 rows=106 width=244)
               Recheck Cond: (unique1 &lt; 100)
               -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..2.37 rows=106 width=0)
                     Index Cond: (unique1 &lt; 100)</programlisting>

    Ce plan propose d'extraire les 100 lignes intéressantes de
    <classname>tenk1</classname> en utilisant le même parcours d'index, de les
    placer dans une table de hachage en mémoire puis de faire un parcours
    séquentiel de <classname>tenk2</classname>, en cherchant dans la table de
    hachage des correspondances possibles de la ligne <literal>t1.unique2 =
    t2.unique2</literal> pour chaque <classname>tenk2</classname>. Le coût pour
    lire <classname>tenk1</classname> et pour initialiser la table de hachage
    correspond au coût de lancement complet pour la jointure hachée car nous
    n'obtiendrons pas de lignes jusqu'à avoir lu <classname>tenk2</classname>.
    Le temps total estimé pour la jointure inclut aussi une charge importante du
    temps CPU pour requêter la table de hachage 10000 fois. Néanmoins, notez
    que nous ne chargeons <emphasis>pas</emphasis> 10000 fois 232,35&nbsp;; la
    configuration de la table de hachage n'est exécutée qu'une fois dans ce type
    de plan.
   </para>

   <para>
    Il est possible de vérifier la précision des coûts estimés par le
    planificateur en utilisant <command>EXPLAIN ANALYZE</command>. Cette commande
    exécute réellement la requête puis affiche le vrai temps d'exécution
    accumulé par chaque n&oelig;ud du plan, avec les mêmes coûts estimés que
    ceux affichés par un simple <command>EXPLAIN</command>. Par exemple, nous
    pourrions obtenir un résultat comme celui-ci&nbsp;:

<screen>EXPLAIN ANALYZE SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                                            QUERY PLAN
----------------------------------------------------------------------------------------------------------------------------------
 Nested Loop  (cost=2.37..553.11 rows=106 width=488) (actual time=1.392..12.700 rows=100 loops=1)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=2.37..232.35 rows=106 width=244) (actual time=0.878..2.367 rows=100 loops=1)
         Recheck Cond: (unique1 &lt; 100)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..2.37 rows=106 width=0) (actual time=0.546..0.546 rows=100 loops=1)
               Index Cond: (unique1 &lt; 100)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.00..3.01 rows=1 width=244) (actual time=0.067..0.078 rows=1 loops=100)
         Index Cond: (t2.unique2 = t1.unique2)
 Total runtime: 14.452 ms</screen>

    Notez que les valeurs <quote>temps réel</quote> sont en millisecondes alors
    que les estimations de <quote>coût</quote> sont exprimées dans des unités
    arbitraires&nbsp;; donc il y a peu de chances qu'elles correspondent.
    L'important est de vérifier si les ratios temps réel et coûts estimés
    correspondent.
   </para>

   <para>
    Dans certains plans de requête, il est possible qu'un n&oelig;ud de
    sous-plan soit exécuté plus d'une fois. Par exemple, le parcours d'index
    interne est exécuté une fois par ligne externe dans le plan de boucle
    imbriquée ci-dessus. Dans de tels cas, la valeur <literal>loops</literal>
    renvoie le nombre total d'exécution du n&oelig;ud, et le temps réel et les
    valeurs des lignes affichées sont une moyenne par exécution. Ceci est fait
    pour que les nombres soient comparables avec la façon dont les estimations
    de coûts sont affichées. Multipliez par la valeur de <literal>loops</literal>
    pour obtenir le temps total réellement passé dans le n&oelig;ud.
   </para>

   <para>
    Le <literal>Total runtime</literal> (temps total d'exécution) affiché
    par <command>EXPLAIN ANALYZE</command> inclut les temps de lancement et
    d'arrêt de l'exécuteur ainsi que le temps passé lors du traitement des
    lignes de résultat. Il n'inclut pas le temps passé pour l'analyse, la
    réécriture ou la planification. Pour une requête <command>SELECT</command>, le
    temps total d'exécution sera juste un peu plus important que le temps total
    indiqué par le no&oelig;ud du plan de haut niveau. Pour les commandes
    <command>INSERT</command>, <command>UPDATE</command> et <command>DELETE</command>, le temps total
    d'exécution pourrait être considérablement plus important parce qu'il inclut
    le temps passé au traitement des lignes de résultat. Pour ces commandes, le
    temps pour le n&oelig;ud du plan principal est essentiellement le temps
    passé à trouver l'emplacement des anciennes lignes et/ou à calculer les
    nouvelles lignes mais
    il n'inclut pas le temps passé à faire des modifications.
    Le temps passé à lancer les déclencheurs, s'il y en a, est aussi en dehors
    du n&oelig;ud du plan principal et est affiché séparément pour chaque
    déclencheur.
   </para>

   <para>
    Il est bon de noter que les résultats de <command>EXPLAIN</command> ne devraient
    pas être extrapolés pour des situations autres que celles de vos tests en
    cours&nbsp;; par exemple, les résultats sur une petite table ne peuvent
    être appliqués à des tables bien plus importantes. Les estimations de coût
    du planificateur ne sont pas linéaires et, du coup, il pourrait bien
    choisir un plan différent pour une table plus petite ou plus grande. Un
    exemple extrême est celui d'une table occupant une page disque. Vous
    obtiendrez pratiquement toujours un parcours séquentiel que des index soient
    disponibles ou non. Le planificateur réalise que cela va nécessiter la
    lecture d'une seule page disque pour traiter la table dans ce cas, il n'y a
    donc pas d'intérêt à étendre des lectures de pages supplémentaires pour un
    index.
   </para>
  </sect1>

 <sect1 id="planner-stats">
  <title>Statistiques utilisées par le planificateur</title>

  <indexterm zone="planner-stats">
   <primary>statistiques</primary>
   <secondary>du planificateur</secondary>
  </indexterm>

  <para>
   Comme nous avons vu dans la section précédente, le planificateur de requêtes
   a besoin d'estimer le nombre de lignes récupérées par une requête pour faire
   les bons choix dans ses plans de requêtes. Cette section fournit un aperçu
   rapide sur les statistiques que le système utilise pour ces estimations.
  </para>

  <para>
   Un élément des statistiques est le nombre total d'entrées dans chaque
   table et index, ainsi que le nombre de blocs disque occupés par chaque table
   et index. Cette information est conservée dans la table
   <link linkend="catalog-pg-class"><structname>pg_class</structname></link>
   sur les colonnes <structfield>reltuples</structfield> et
   <structfield>relpages</structfield>. Nous pouvons la regarder avec des
   requêtes comme celle-ci&nbsp;:

<screen>SELECT relname, relkind, reltuples, relpages
FROM pg_class
WHERE relname LIKE 'tenk1%';

       relname        | relkind | reltuples | relpages
----------------------+---------+-----------+----------
 tenk1                | r       |     10000 |      358
 tenk1_hundred        | i       |     10000 |       30
 tenk1_thous_tenthous | i       |     10000 |       30
 tenk1_unique1        | i       |     10000 |       30
 tenk1_unique2        | i       |     10000 |       30
(5 rows)</screen>

   Ici, nous pouvons voir que <structname>tenk1</structname> contient 10000
   lignes, comme pour ses index, mais que les index sont bien plus petits que la
   table (ce qui n'est pas surprenant).
  </para>

  <para>
   Pour des raisons d'efficacité, <structfield>reltuples</structfield> et
   <structfield>relpages</structfield> ne sont pas mis à jour en temps réel, et
   du coup, elles contiennent habituellement des valeurs un peu obsolètes. Elles
   sont mises à jour par les commandes <command>VACUUM</command>, <command>ANALYZE</command>
   et quelques commandes DDL comme <command>CREATE INDEX</command>. Un
   <command>ANALYZE</command> seul, donc ne faisant pas partie d'un <command>VACUUM</command>,
   génère une valeur approximative de <structfield>reltuples</structfield> car
   il ne lit pas chaque ligne de la table. Le planificateur mettra à l'échelle
   les valeurs qu'il aura trouver dans <structname>pg_class</structname> pour
   correspondre à la taille physique de la table, obtenant ainsi une
   approximation plus proche de la réalité.
  </para>

  <indexterm>
   <primary>pg_statistic</primary>
  </indexterm>

  <para>
   La plupart des requêtes ne récupère qu'une fraction des lignes dans une
   table à cause de clauses <literal>WHERE</literal> qui restreignent les lignes à
   examiner. Du coup, le planificateur a besoin d'une estimation de la
   <firstterm>sélectivité</firstterm> des clauses <literal>WHERE</literal>, c'est-à-dire la
   fraction des lignes qui correspondent à chaque condition de la clause
   <literal>WHERE</literal>. L'information utilisée pour cette tâche est stockée dans
   le catalogue système <link
   linkend="catalog-pg-statistic"><structname>pg_statistic</structname></link>.
   Les entrées de <structname>pg_statistic</structname> sont mises à jour par
   les commandes <command>ANALYZE</command> et <command>VACUUM ANALYZE</command> et sont
   toujours approximatives même si elles ont été mises à jour récemment.
  </para>

  <indexterm>
   <primary>pg_stats</primary>
  </indexterm>

  <para>
   Plutôt que de regarder directement dans
   <structname>pg_statistic</structname>, il est mieux de visualiser sa vue
   <link linkend="view-pg-stats"><structname>pg_stats</structname></link>
   lors de l'examen manuel des statistiques.
   <structname>pg_stats</structname> est conçu pour être plus facilement
   lisible. De plus, <structname>pg_stats</structname> est lisible par tous
   alors que <structname>pg_statistic</structname> n'est lisible que par un
   superutilisateur (ceci empêche les utilisateurs non privilégiés d'apprendre
   certains choses sur le contenu des tables appartenant à d'autres personnes à
   partir des statistiques. La vue <structname>pg_stats</structname> est restreinte
   pour afficher seulement les lignes des tables lisibles par l'utilisateur courant).
   Par exemple, nous pourrions lancer&nbsp;:

<screen>SELECT attname, inherited, n_distinct,
       array_to_string(most_common_vals, E'\n') as most_common_vals
FROM pg_stats
WHERE tablename = 'road';

 attname | inherited | n_distinct |          most_common_vals          
---------+-----------+------------+------------------------------------
 name    | f         |  -0.363388 | I- 580                        Ramp+
         |           |            | I- 880                        Ramp+
         |           |            | Sp Railroad                       +
         |           |            | I- 580                            +
         |           |            | I- 680                        Ramp
 name    | t         |  -0.284859 | I- 880                        Ramp+
         |           |            | I- 580                        Ramp+
         |           |            | I- 680                        Ramp+
         |           |            | I- 580                            +
         |           |            | State Hwy 13                  Ramp
(2 rows)
</screen>

   Notez que deux lignes sont affichées pour la même colonne, une correspondant
   à la hiérarchie d'héritage complète commençant à la table
   <literal>road</literal> (<literal>inherited</literal>=<literal>t</literal>),
   et une autre incluant seulement la table <literal>road</literal> elle-même
   (<literal>inherited</literal>=<literal>f</literal>).

  </para>

  <para>
   Le nombre d'informations stockées dans
   <structname>pg_statistic</structname> par <command>ANALYZE</command>,
   en particulier le nombre maximum
   d'éléments dans les tableaux <structfield>most_common_vals</structfield> et
   <structfield>histogram_bounds</structfield> pour chaque colonne, peut être initialisé
   sur une base colonne-par-colonne en utilisant la commande <command>ALTER
   TABLE SET STATISTICS</command> ou globalement en initialisant la variable de
   configuration <xref linkend="guc-default-statistics-target"/>. La limite par
   défaut est actuellement de cent entrées. Augmenter la limite pourrait
   permettre des estimations plus précises du planificateur, en particulier
   pour les colonnes ayant des distributions de données irrégulières, au prix
   d'un plus grand espace consommé dans <structname>pg_statistic</structname> et
   en un temps plus long pour calculer les estimations. En revanche, une limite
   plus basse pourrait être suffisante pour les colonnes à distributions de
   données simples.
  </para>

  <para>
   Le <xref linkend="planner-stats-details"/> donne plus de détails sur
   l'utilisation des statistiques par le planificateur.
  </para>

 </sect1>

 <sect1 id="explicit-joins">
  <title>Contrôler le planificateur avec des clauses <literal>JOIN</literal>
   explicites</title>

  <indexterm zone="explicit-joins">
   <primary>jointure</primary>
   <secondary>contrôlant l'ordre</secondary>
  </indexterm>

  <para>
   Il est possible de contrôler le planificateur de requêtes à un certain
   point en utilisant une syntaxe <literal>JOIN</literal> explicite. Pour voir en
   quoi ceci est important, nous avons besoin de quelques connaissances.
  </para>

  <para>
   Dans une simple requête de jointure, telle que&nbsp;:
<programlisting>SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;</programlisting>
   le planificateur est libre de joindre les tables données dans n'importe
   quel ordre. Par exemple, il pourrait générer un plan de requête qui joint A à
   B en utilisant la condition <literal>WHERE</literal> <literal>a.id = b.id</literal>, puis
   joint C à cette nouvelle table jointe en utilisant l'autre condition
   <literal>WHERE</literal>. Ou il pourrait joindre B à C, puis A au résultat de cette
   jointure précédente. Ou il pourrait joindre A à C puis les joindre avec B
   mais cela pourrait ne pas être efficace car le produit cartésien complet de A
   et C devra être formé alors qu'il n'y a pas de condition applicable dans la
   clause <literal>WHERE</literal> pour permettre une optimisation de la jointure
   (toutes les jointures dans l'exécuteur <productname>PostgreSQL</productname>
   arrivent entre deux tables en entrées donc il est nécessaire de construire le
   résultat de l'une ou de l'autre de ces façons). Le point important est que
   ces différentes possibilités de jointures donnent des résultats
   sémantiquement équivalents mais pourraient avoir des coûts d'exécution
   grandement différents. Du coup, le planificateur va toutes les explorer pour
   trouver le plan de requête le plus efficace.
  </para>

  <para>
   Quand une requête implique seulement deux ou trois tables, il y a peu
   d'ordres de jointures à préparer. Mais le nombre d'ordres de jointures
   possibles grandit de façon exponentielle au fur et à mesure que le nombre de
   tables augmente. Au-delà de dix tables en entrée, il n'est plus possible de
   faire une recherche exhaustive de toutes les possibilités et même la
   planification de six ou sept tables pourrait prendre beaucoup de temps.
   Quand il y a trop de tables en entrée, le planificateur
   <productname>PostgreSQL</productname> basculera d'une recherche exhaustive à
   une recherche <firstterm>génétique</firstterm> probabiliste via un nombre
   limité de possibilités (la limite de bascule est initialisée par le paramètre
   en exécution <xref linkend="guc-geqo-threshold"/>). La recherche génétique prend
   moins de temps mais elle ne trouvera pas nécessairement le meilleur plan
   possible.
  </para>

  <para>
   Quand la requête implique des jointures externes, le planificateur est moins
   libre qu'il ne l'est lors de jointures internes. Par exemple, considérez&nbsp;:
<programlisting>SELECT * FROM a LEFT JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);</programlisting>
   Bien que les restrictions de cette requête semblent superficiellement
   similaires à l'exemple précédent, les sémantiques sont différentes car une
   ligne doit être émise pour chaque ligne de A qui n'a pas de ligne
   correspondante dans la jointure entre B et C. Du coup, le planificateur n'a
   pas de choix dans l'ordre de la jointure ici&nbsp;: il doit joindre B à C
   puis joindre A à ce résultat. Du coup, cette requête prend moins de temps à
   planifier que la requête précédente. Dans d'autres cas, le planificateur
   pourrait être capable de déterminer que plus d'un ordre de jointure est
   sûr. Par exemple, étant donné&nbsp;:
<programlisting>
SELECT * FROM a LEFT JOIN b ON (a.bid = b.id) LEFT JOIN c ON (a.cid = c.id);
</programlisting>
   il est valide de joindre A à soit B soit C en premier. Actuellement, seul un
   <literal>FULL JOIN</literal> contraint complètement l'ordre de jointure. La
   plupart des cas pratiques impliquant un <literal>LEFT JOIN</literal> ou un
   <literal>RIGHT JOIN</literal> peuvent être arrangés jusqu'à un certain degré.
  </para>

  <para>
   La syntaxe de jointure interne explicite (<literal>INNER
   JOIN</literal>, <literal>CROSS JOIN</literal> ou <literal>JOIN</literal>) est sémantiquement
   identique à lister les relations en entrées du <literal>FROM</literal>, donc il
   ne contraint pas l'ordre de la jointure.
  </para>

  <para>
   Même si la plupart des types de <literal>JOIN</literal> ne contraignent pas
   complètement l'ordre de jointure, il est possible d'instruire le planificateur
   de requête de <productname>PostgreSQL</productname> pour qu'il traite toutes
   les clauses <literal>JOIN</literal> de façon à contraindre quand même l'ordre
   de jointure.
   Par exemple, ces trois requêtes sont logiquement équivalentes&nbsp;:
<programlisting>SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a CROSS JOIN b CROSS JOIN c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);</programlisting>
   Mais si nous disons au planificateur d'honorer l'ordre des
   <literal>JOIN</literal>, la deuxième et la troisième prendront moins de temps à
   planifier que la première. Cet effet n'est pas inquiétant pour seulement
   trois tables mais cela pourrait bien nous aider avec un nombre important
   de tables.
  </para>

  <para>
   Pour forcer le planificateur à suivre l'ordre de jointure demandé par les
   <literal>JOIN</literal> explicites, initialisez le paramètre en exécution
   <xref linkend="guc-join-collapse-limit"/> à 1 (d'autres valeurs possibles
   sont discutées plus bas).
  </para>

  <para>
   Vous n'avez pas besoin de restreindre l'ordre de jointure pour diminuer le 
   temps de recherche car il est bien d'utiliser les opérateurs <literal>JOIN</literal>
   dans les éléments d'une liste <literal>FROM</literal>. Par exemple,
   considérez&nbsp;:
<programlisting>SELECT * FROM a CROSS JOIN b, c, d, e WHERE ...;</programlisting>
   Avec <varname>join_collapse_limit</varname> = 1, ceci force le planificateur à
   joindre A à B avant de les joindre aux autres tables mais sans restreindre
   ses choix. Dans cet exemple, le nombre d'ordres de jointures possibles
   est réduit par un facteur de cinq.
  </para>

  <para>
   Restreindre la recherche du planificateur de cette façon est une technique
   utile pour réduire les temps de planification et pour diriger le
   planificateur vers un bon plan de requêtes. Si le planificateur choisit un
   mauvais ordre de jointure par défaut, vous pouvez le forcer à choisir un
   meilleur ordre via la syntaxe <literal>JOIN</literal> &mdash; en supposant que vous
   connaissiez un meilleur ordre. Une expérimentation est recommandée.
  </para>

  <para>
   Un problème très proche et affectant le temps de planification est le
   regroupement de sous-requêtes dans leurs requêtes parents. Par exemple,
   considérez&nbsp;:
<programlisting>SELECT *
FROM x, y,
    (SELECT * FROM a, b, c WHERE quelquechose) AS ss
WHERE quelquechosedautre;</programlisting>
   Cette requête pourrait survenir suite à l'utilisation d'une vue contenant une
   jointure&nbsp;; la règle <literal>SELECT</literal> de la vue sera insérée à la
   place de la référence de la vue, demande une requête plutôt identique à celle
   ci-dessus. Normalement, le planificateur essaiera de regrouper la
   sous-requête avec son parent, donnant&nbsp;:
<programlisting>SELECT * FROM x, y, a, b, c WHERE quelquechose AND quelquechosedautre;</programlisting>
   Ceci résulte habituellement en un meilleur plan que de planifier séparément
   la sous-requête (par exemple, les conditions <literal>WHERE</literal> externes
   pourraient être telles que joindre X à A élimine en premier lieu un bon
   nombre de lignes de A, évitant ainsi le besoin de former la sortie complète
   de la sous-requête). Mais en même temps, nous avons accru le temps de
   planification&nbsp;; ici, nous avons une problème de jointure à cinq tables
   remplaçant un problème de deux jointures séparées à trois tables. À cause de
   l'augmentation exponentielle du nombre de possibilités, ceci fait une grande
   différence. Le planificateur essaie d'éviter de se retrouver coincé dans des
   problèmes de recherche de grosses jointures en ne regroupant pas une
   sous-requête sur plus de <varname>from_collapse_limit</varname>
   éléments sont la résultante de la requête parent. Vous
   pouvez comparer le temps de planification avec la qualité du plan en
   ajustant ce paramètre en exécution.
  </para>

  <para>
   <xref linkend="guc-from-collapse-limit"/> et <xref
   linkend="guc-join-collapse-limit"/> sont
   nommés de façon similaire parce qu'ils font pratiquement la même chose&nbsp;:
   l'un d'eux contrôle le moment où le planificateur <quote>aplatira</quote> les
   sous-requêtes et l'autre contrôle s'il y a aplatissement des jointures
   explicites. Typiquement, vous initialiserez 
   <varname>join_collapse_limit</varname> comme <varname>from_collapse_limit</varname> (de
   façon à ce que les jointures explicites et les sous-requêtes agissent de la
   même façon) ou vous initialiserez <varname>join_collapse_limit</varname> à 1 (si
   vous voulez contrôler l'ordre de jointure des jointures explicites). Mais
   vous pourriez les initialiser différemment si vous tentez de configurer
   finement la relation entre le temps de planification et le temps
   d'exécution.
  </para>
 </sect1>

 <sect1 id="populate">
  <title>Remplir une base de données</title>

  <para>
   Vous pourriez avoir besoin d'insérer un grand nombre de données pour
   remplir une base de données au tout début. Cette section contient quelques
   suggestions pour réaliser cela de la façon la plus efficace.
  </para>

  <sect2 id="disable-autocommit">
   <title>Désactivez la validation automatique (autocommit)</title>

   <indexterm>
    <primary>autocommit</primary>
    <secondary>gros chargement de données</secondary>
   </indexterm>

   <para>
    Lors d'<command>INSERT</command> multiples, désactivez la validation automatique et faites
    une seule validation à la
    fin (en SQL, ceci signifie de lancer <command>BEGIN</command> au début et
   <command>COMMIT</command> à la fin. Quelques bibliothèques client pourraient
   le faire derrière votre dos auquel cas vous devez vous assurer que la
   bibliothèque le fait quand vous le voulez). Si vous permettez à chaque
   insertion d'être validée séparément, <productname>PostgreSQL</productname>
   fait un gros travail pour chaque ligne ajoutée. Un bénéfice supplémentaire de
   réaliser toutes les insertions dans une seule transaction est que si l'insertion
   d'une ligne échoue alors les lignes insérées jusqu'à maintenant seront
   annulées. Vous ne serez donc pas bloqué avec des données partiellement
   chargées.
   </para>
  </sect2>

  <sect2 id="populate-copy-from">
   <title>Utilisez <command>COPY</command></title>

   <para>
    Utilisez <xref linkend="sql-copy"/> pour charger
    toutes les lignes en une seule commande, plutôt que d'utiliser une série
    de commandes <command>INSERT</command>. La commande <command>COPY</command>
    est optimisée pour charger un grand nombre de lignes&nbsp;; elle est moins
    flexible que <command>INSERT</command> mais introduit significativement moins
    de surcharge lors du chargement de grosses quantités de données. Comme
    <command>COPY</command> est une seule commande, il n'y a pas besoin de
    désactiver la validation automatique (autocommit) si vous utilisez cette
    méthode pour remplir une table.
   </para>

   <para>
    Si vous ne pouvez pas utiliser <command>COPY</command>, utiliser <xref
    linkend="sql-prepare"/> pourrait vous aider à
    créer une instruction préparée <command>INSERT</command>, puis utilisez
    <command>EXECUTE</command> autant de fois que nécessaire. Ceci évite
    certaines surcharges lors d'une analyse et d'une planification répétées
    de commandes <command>INSERT</command>. Différentes interfaces fournissent
    cette fonctionnalité de plusieurs façons&nbsp;; recherchez
    <quote>instructions préparées</quote> dans la documentation de l'interface.
   </para>

   <para>
    Notez que charger un grand nombre de lignes en utilisant
    <command>COPY</command> est pratiquement toujours plus rapide que d'utiliser
    <command>INSERT</command>, même si <command>PREPARE ... INSERT</command> est utilisé lorsque
    de nombreuses insertions sont groupées en une seule transaction.
   </para>

   <para>
    <command>COPY</command> est plus rapide quand il est utilisé dans la même
    transaction que la commande <command>CREATE TABLE</command> ou
    <command>TRUNCATE</command> précédente. Dans ce cas, les journaux de
    transactions ne sont pas impactés car, en cas d'erreur, les fichiers
    contenant les données nouvellement chargées seront supprimés de toute
    façon. Néanmoins, cette considération ne s'applique que quand
    <xref linkend="guc-wal-level"/> vaut <literal>minimal</literal>, car toutes les
    commandes doivent écrire dans les journaux de transaction dans ce cas.
   </para>

  </sect2>

  <sect2 id="populate-rm-indexes">
   <title>Supprimez les index</title>

   <para>
    Si vous chargez une table tout juste créée, la méthode la plus rapide est de
    créer la table, de charger en lot les données de cette table en utilisant
    <command>COPY</command>, puis de créer tous les index nécessaires pour la
    table. Créer un index sur des données déjà existantes est plus rapide que de
    mettre à jour de façon incrémentale à chaque ligne ajoutée.
   </para>

   <para>
    Si vous ajoutez beaucoup de données à une table existante, il pourrait être
    avantageux de supprimer l'index, de charger la table, puis de recréer l'index.
    Bien sûr, les performances de la base de données pour les autres utilisateurs
    pourraient souffrir tout le temps où l'index sera manquant. Vous devez aussi
    y penser à deux fois avant de supprimer des index uniques car la vérification
    d'erreur apportée par la contrainte unique sera perdue tout le temps où
    l'index est manquant.
   </para>
  </sect2>

  <sect2 id="populate-rm-fkeys">
   <title>Suppression des contraintes de clés étrangères</title>

   <para>
    Comme avec les index, une contrainte de clé étrangère peut être vérifiée
    <quote>en gros volume</quote> plus efficacement que ligne par ligne.
    Donc, il pourrait être utile de supprimer les contraintes de clés
    étrangères, de charger les données et de créer de nouveau les contraintes.
    De nouveau, il y a un compromis entre la vitesse de chargement des données
    et la perte de la vérification des erreurs lorsque la contrainte manque.
   </para>
  </sect2>

  <sect2 id="populate-work-mem">
   <title>Augmentez <varname>maintenance_work_mem</varname></title>

   <para>
    Augmentez temporairement la variable <xref linkend="guc-maintenance-work-mem"/>
    lors du chargement de grosses quantités de données peut amener une
    amélioration des performances. Ceci aidera à l'accélération des commandes
    <command>CREATE INDEX</command> et <command>ALTER TABLE ADD FOREIGN KEY</command>. Cela
    ne changera pas grand chose pour la commande <command>COPY</command>. Donc, ce
    conseil est seulement utile quand vous utilisez une des deux ou les deux
    techniques ci-dessus.
   </para>
  </sect2>

  <sect2 id="populate-checkpoint-segments">
   <title>Augmentez <varname>checkpoint_segments</varname></title>

   <para>
    Augmenter temporairement la variable de configuration <xref
    linkend="guc-checkpoint-segments"/> peut aussi aider à un chargement
    rapide de grosses quantités de données. Ceci est dû au fait que charger
    une grosse quantité de données dans <productname>PostgreSQL</productname>
    causera la venue trop fréquente de points de vérification (la
    fréquence de ces points de vérification est spécifiée par la variable de
    configuration <varname>checkpoint_timeout</varname>). Quand survient un
    point de vérification, toutes les pages modifiées sont écrites sur le
    disque. En augmentant <varname>checkpoint_segments</varname> temporairement
    lors du chargement des données, le nombre de points de vérification requis
    peut être diminué.
   </para>
  </sect2>

  <sect2 id="populate-pitr">
   <title>Désactiver l'archivage des journaux de transactions et la
     réplication en flux</title>

   <para>
    Lors du chargement de grosse quantité de données dans une instance qui
    utilise l'archivage des journaux de transactions ou la réplication en
    flux, il pourrait être plus rapide de prendre une nouvelle sauvegarde de
    base après que le chargement ait terminé, plutôt que de traiter une grosse
    quantité de données incrémentales dans les journaux de transactions. Vous
    pouvez désactiver l'archivage et la réplication en flux lors du chargement
    en configurant <xref linkend="guc-wal-level"/> à <literal>minimal</literal>,
    <xref linkend="guc-archive-mode"/> à <literal>off</literal> et
    <xref linkend="guc-max-wal-senders"/> à zéro). Mais notez que le changement
    de ces paramètres requiert un redémarrage du serveur.
   </para>

   <para>
    En dehors d'éviter le temps de traitement des données des journaux de
    transactions par l'archiveur ou l'émetteur des journaux de transactions,
    le faire rendrait certaines commandes plus rapides parce qu'elles sont
    conçues pour ne pas écrire du tout dans les journaux de transactions si
    <varname>wal_level</varname> vaut <literal>minimal</literal>. (Elles
    peuvent garantir la sûreté des données de façon moins coûteuse en exécutant
    un <function>fsync</function> à la fin plutôt qu'en écrivant les journaux
    de transactions&nbsp;:
    <itemizedlist>
     <listitem>
      <para>
       <command>CREATE TABLE AS SELECT</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>CREATE INDEX</command> (et les variantes telles que
       <command>ALTER TABLE ADD PRIMARY KEY</command>)
      </para>
     </listitem>
     <listitem>
      <para>
       <command>ALTER TABLE SET TABLESPACE</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>CLUSTER</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>COPY FROM</command>, quand la table cible vient d'être créée
       ou vidée auparavant dans la transaction
      </para>
     </listitem>
    </itemizedlist>
   </para>
  </sect2>

  <sect2 id="populate-analyze">
   <title>Lancez <command>ANALYZE</command> après</title>

   <para>
     Quand vous avez changé significativement la distribution des données à
     l'intérieur d'une table, lancer <xref linkend="sql-analyze"/> est fortement
     recommandée. Ceci inclut le
     chargement de grosses quantités de données dans la table. Lancer
     <command>ANALYZE</command> (ou <command>VACUUM ANALYZE</command>) vous
     assure que le planificateur dispose de statistiques à jour sur la table.
     Sans statistiques ou avec des statistiques obsolètes, le planificateur
     pourrait prendre de mauvaises décisions lors de la planification de la
     requête, amenant des performances pauvres sur toutes les tables sans
     statistiques ou avec des statistiques inexactes. Notez que si le démon
     autovacuum est désactivée, il pourrait exécuter <command>ANALYZE</command>
     automatiquement&nbsp;; voir <xref linkend="vacuum-for-statistics"/> et
     <xref linkend="autovacuum"/> pour plus d'informations.
   </para>
  </sect2>

  <sect2 id="populate-pg-dump">
   <title>Quelques notes sur <application>pg_dump</application></title>

   <para>
    Les scripts de sauvegarde générés par <application>pg_dump</application> appliquent
    automatiquement plusieurs des indications ci-dessus, mais pas toutes. Pour
    recharger une sauvegarde <application>pg_dump</application> aussi rapidement que
    possible, vous avez besoin de faire quelques étapes supplémentaires
    manuellement (notez que ces points s'appliquent lors de la
    <emphasis>restauration</emphasis> d'une sauvegarde, et non pas lors de sa
    <emphasis>création</emphasis>. Les mêmes points s'appliquent lors de l'utilisation
    de <application>pg_restore</application> pour charger un fichier de sauvegarde
    <application>pg_dump</application>).
   </para>

   <para>
    Par défaut, <application>pg_dump</application> utilise
    <command>COPY</command> et, lorsqu'il génère une sauvegarde complexe,
    schéma et données, il est préférable de charger les données avant de créer
    les index et les clés étrangères. Donc, dans ce cas, plusieurs lignes de
    conduite sont gérées automatiquement. Ce qui vous reste à faire est
    de&nbsp;:
    <itemizedlist>
     <listitem>
      <para>
       Configurez des valeurs appropriées (c'est-à-dire plus importante que la
       normale) pour <varname>maintenance_work_mem</varname> et
       <varname>checkpoint_segments</varname>.
      </para>
     </listitem>
     <listitem>
      <para>
       Si vous utilisez l'archivage des journaux de transactions ou la
       réplication en flux, considérez leur désactivation lors de la
       restauration. Pour faire cela, configurez
       <varname>archive_mode</varname> à off, <varname>wal_level</varname> à
       <literal>minimal</literal> et <varname>max_wal_senders</varname> à zéro
       avant de charger le script de sauvegarde. Après coup, remettez les
       anciennes valeurs et effectuez une nouvelle sauvegarde de base.
      </para>
     </listitem>
     <listitem>
      <para>
       Demandez-vous si la sauvegarde complète doit être restaurée dans une
       seule transaction. Pour cela, passez l'option <option>-1</option> ou
       <option>--single-transaction</option> à
       <application>psql</application> pi <application>pg_restore</application>.
       Lors de l'utilisation de ce mode, même les erreurs les plus petites
       annuleront la restauration complète, peut-être en annulant des heures de
       traitement. Suivant à quel point les données sont en relation, il peut
       être préférable de faire un nettoyage manuel. Les commandes
       <command>COPY</command> s'exécuteront plus rapidement si vous utilisez une
       transaction simple et que vous avez désactivé l'archivage des journaux de
       transaction. <application>pg_restore</application> a aussi une option
       <option>--jobs</option> qui permet un chargement parallèle des données
       et une création parallèle des index, tout en conservant les avantages
       en performance du COPY en une seule transaction.
      </para>
     </listitem>
     <listitem>
      <para>
       Exécutez <command>ANALYZE</command> après coup.
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
    Une sauvegarde des données seules utilise toujours <command>COPY</command> mais
    elle ne supprime ni ne recrée les index et elle ne touche généralement pas
    les clés étrangères.

     <footnote>
      <para>
       Vous pouvez obtenir l'effet de désactivation des clés étrangères en
       utilisant l'option <option>--disable-triggers</option> &mdash; mais réalisez
       que cela élimine, plutôt que repousse, la validation des clés étrangères
       et qu'il est du coup possible d'insérer des données mauvaises si vous
       l'utilisez.
      </para>
     </footnote>

    Donc, lorsque vous chargez une sauvegarde ne contenant que les données,
    c'est à vous de supprimer et recréer les index et clés étrangères si vous
    souhaitez utiliser ces techniques. Il est toujours utile d'augmenter
    <varname>checkpoint_segments</varname> lors du chargement des données
    mais ne vous embêtez pas à augmenter
    <varname>maintenance_work_mem</varname>&nbsp;; en fait, vous le ferez lors
    d'une nouvelle création manuelle des index et des clés étrangères. Et
    n'oubliez pas <command>ANALYZE</command> une fois que vous avez terminé&nbsp;;
    voir <xref linkend="vacuum-for-statistics"/> et <xref linkend="autovacuum"/>
    pour plus d'informations.
   </para>
  </sect2>
 </sect1>
</chapter>
