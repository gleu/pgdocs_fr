<?xml version="1.0" encoding="UTF-8"?>
<!-- Dernière modification
     le       $Date$
     par      $Author$
     révision $Revision$ -->

 <chapter id="performance-tips">
  <title>Conseils sur les performances</title>

  <indexterm zone="performance-tips">
    <primary>performance</primary>
  </indexterm>

  <para>
   La performance des requêtes peut être affectée par un grand nombre d'éléments.
   Certains peuvent être contrôlés par l'utilisateur, d'autres sont
   fondamentaux au concept sous-jacent du système. Ce chapitre fournit des
   conseils sur la compréhension et sur la configuration fine des performances
   de <productname>PostgreSQL</productname>.
  </para>

  <sect1 id="using-explain">
   <title>Utiliser <command>EXPLAIN</command></title>

   <indexterm zone="using-explain">
    <primary>EXPLAIN</primary>
   </indexterm>

   <indexterm zone="using-explain">
    <primary>plan de requête</primary>
   </indexterm>

   <para>
    <productname>PostgreSQL</productname> réalise un <firstterm>plan
    de requête</firstterm> pour chaque requête qu'il reçoit. Choisir le bon
    plan correspondant à la structure de la requête et aux propriétés des
    données est absolument critique pour de bonnes performances, donc le système
    inclut un <firstterm>planificateur</firstterm> complexe qui tente de choisir
    les bons plans. Vous pouvez
    utiliser la commande <xref linkend="sql-explain"/>
    pour voir quel plan de requête le planificateur crée pour une requête particulière.
	La lecture du plan est un art qui requiert de l'expérience pour le maîtriser,
	mais cette section essaie de couvrir les bases.
   </para>
 
   <para>
    Les exemples dans cette section sont tirés de la base de donnée pour les tests de
	régression après avoir effectué un <command>VACUUM ANALYZE</command>, avec les sources
	de la version de développement 9.2. Vous devriez obtenir des résultats similaires si
	vous essayez les exemples vous-même, mais vos estimations de coût et de nombre de lignes
	pourraient légèrement varier car les statistiques d'<command>ANALYZE</command> sont basées
	sur des échantillons aléatoires, et parce que les coûts sont dépendants de la plateforme utilisée.
   </para>

   <para>
    Les exemples utilisent le format de sortie par défaut (<quote>text</quote>)
	d'<command>EXPLAIN</command>, qui est compact et pratique pour la lecture.
    Si vous voulez utiliser la sortie d'<command>EXPLAIN</command> avec un
    programme pour une analyse ultérieure, vous devriez utiliser un des formats
    de sortie au format machine (XML,JSON ou YAML) à la place.
   </para>

  <sect2 id="using-explain-basics">
   <title><command>EXPLAIN</command> Basics</title>

   <para>
    La structure d'un plan de requête est un arbre de <firstterm>n&oelig;uds
    de plan</firstterm>. Les n&oelig;uds de bas niveau sont les n&oelig;uds
    de parcours&nbsp;: ils renvoient les lignes brutes d'une table. Il existe
    différents types de n&oelig;uds de parcours pour les différentes méthodes
    d'accès aux tables&nbsp;: parcours séquentiel, parcours d'index et parcours
    d'index bitmap. Il y a également des sources de lignes qui ne
	proviennent pas de tables, telles que les clauses <literal>VALUES</literal>
	ainsi que les fonctions renvoyant des ensembles dans un <literal>FROM</literal>,
	qui ont leurs propre type de n&oelig;uds de parcours.
	Si la requête requiert des jointures, agrégations, tris
    ou d'autres opérations sur les lignes brites, ce seront des n&oelig;uds
    supplémentaires au-dessus des n&oelig;uds de parcours pour réaliser ces
    opérations. Encore une fois, il existe plus d'une façon de réaliser ces
    opérations, donc différents types de n&oelig;uds peuvent aussi apparaître
    ici.  La sortie
    d'<command>EXPLAIN</command> comprend une ligne pour chaque n&oelig;ud dans
    l'arbre du plan, montrant le type de n&oelig;ud basique avec les estimations
    de coût que le planificateur a fait pour l'exécution de ce n&oelig;ud du
    plan. Des lignes supplémentaires peuvent apparaître, indentées par rapport
	à la ligne de résumé du n&oelig;ud, pour montrer les propriétés supplémentaires
	du n&oelig;ud.
    La première ligne (le n&oelig;ud tout en haut) comprend le coût
    d'exécution total estimé pour le plan&nbsp;; c'est ce nombre que le
    planificateur cherche à minimiser.
   </para>

   <para>
    Voici un exemple trivial, juste pour montrer à quoi ressemble l'affichage.

<screen>EXPLAIN SELECT * FROM tenk1;

                         QUERY PLAN
-------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)</screen>
   </para>

   <para>
   Puisque la requête n'a pas de clause <literal>WHERE</literal>, il faut
   parcourir toutes les lignes de la table, c'est pourquoi le planificateur
   a choisi d'utiliser un plan avec un simple parcours séquentiel. Les nombres
   affichés entre parenthèse sont (de gauche à droite)&nbsp;:

    <itemizedlist>
     <listitem>
      <para>
       Coût estimé du lancement. Cela correspond au temps passé avant que
	   l'affichage de la sortie ne commence, par exemple le temps de faire un
	   tri dans un n&oelig;ud de tri&nbsp;;
      </para>
     </listitem>

     <listitem>
      <para>
       Coût total estimé. Cela suppose que le n&oelig;ud du plan d'exécution est
	   exécuté entièrement, c'est-à-dire que toutes les lignes disponibles sont
	   récupérées. En pratique, un n&oelig;ud parent peut arrêter la récupération
	   de toutes les lignes disponibles avant la fin (voir l'exemple
       <literal>LIMIT</literal> ci-dessous)&nbsp;;
      </para>
     </listitem>

     <listitem>
      <para>
       Nombre de lignes estimé en sortie par ce n&oelig;ud de plan. Encore une fois,
	   on suppose que le n&oelig;ud est exécuté entièrement.
      </para>
     </listitem>

     <listitem>
      <para>
       Largeur moyenne estimée (en octets) des lignes en sortie par ce
       n&oelig;ud de plan.
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
    Les coûts sont mesurés en unités arbitraires déterminées par les paramètres
    de coût du planificateur (voir <xref linkend="runtime-config-query-constants"/>).
    La pratique habituelle est de mesurer les coûts en unité de récupération de
    pages disque&nbsp;; autrement dit, <xref linkend="guc-seq-page-cost"/> est
    initialisé à <literal>1.0</literal> par convention et les autres paramètres
    de coût sont relatifs à cette valeur. Les exemples de cette section sont
    exécutés avec les paramètres de coût par défaut.
   </para>

   <para>
    Il est important de comprendre que le coût d'un n&oelig;ud de haut niveau inclut
    le coût de tous les n&oelig;uds fils. Il est aussi important de réaliser
    que le coût reflète seulement les éléments d'importance pour le
    planificateur. En particulier, le coût ne considère pas le temps
    dépensé dans la transmission des lignes de résultat au client, ce qui
    pourrait être un facteur important dans le temps réel passé&nbsp;; mais
    le planificateur l'ignore parce qu'il ne peut pas le changer en modifiant
    le plan (chaque plan correct sortira le même ensemble de lignes).
   </para>

   <para>
    La valeur <literal>rows</literal> est un peu difficile car il ne s'agit
    pas du nombre de lignes traitées ou parcourues par le
    plan de n&oelig;uds, mais plutôt le nombre émis par le n&oelig;ud. C'est
	habituellement moins, reflétant la sélectivité estimée des conditions de
	la clause <literal>WHERE</literal> qui sont appliquées au n&oelig;ud.
	Idéalement, les estimations des lignes de haut niveau seront une approximation
	des nombres de lignes déjà renvoyées, mises à jour, supprimées par la requête.
   </para>

   <para>
    Pour revenir à notre exemple&nbsp;:

<screen>EXPLAIN SELECT * FROM tenk1;

                         QUERY PLAN
-------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)</screen>
   </para>

   <para>
    Ces nombres sont directement dérivés. Si vous faites&nbsp;:

<screen>SELECT relpages, reltuples FROM pg_class WHERE relname = 'tenk1';</screen>

    vous trouverez que <classname>tenk1</classname> a 358 pages disque et 10000
    lignes. Le coût estimé est calculé avec (nombre de pages lues *
    <xref linkend="guc-seq-page-cost"/>) + (lignes parcourues *
    <xref linkend="guc-cpu-tuple-cost"/>).  Par défaut,
    <varname>seq_page_cost</varname> vaut 1.0 et <varname>cpu_tuple_cost</varname>
    vaut 0.01. Donc le coût estimé est de (358 * 1.0) + (10000 * 0.01),
    soit 458.
   </para>

   <para>
    Maintenant, modifions la requête originale pour ajouter une condition
    <literal>WHERE</literal>&nbsp;:

<screen>EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 7000;

                         QUERY PLAN
------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..483.00 rows=7001 width=244)
   Filter: (unique1 &lt; 7000)</screen>

    Notez que l'affichage d'<command>EXPLAIN</command> montre la clause <literal>WHERE</literal>
    appliquée comme une condition de <quote>filtre</quote> rattaché au n&oelig;ud de
	parcours séquentiel&nbsp;; ceci signifie que le
    n&oelig;ud de plan vérifie la condition pour chaque ligne qu'il parcourt et
    ne conserve que celles qui satisfont la condition.
    L'estimation des lignes en sortie a baissé à cause de la clause
    <literal>WHERE</literal>. Néanmoins, le parcours devra toujours visiter les 10000
    lignes, donc le coût n'a pas baissé&nbsp;; en fait, il a un peu augmenté
    (par 10000 * <xref linkend="guc-cpu-operator-cost"/> pour être exact)
    dans le but de refléter le temps CPU supplémentaire dépensé pour vérifier
    la condition <literal>WHERE</literal>.
   </para>

   <para>
    Le nombre réel de lignes que cette requête sélectionnera est 7000 mais
    l'estimation <literal>rows</literal> est approximative. Si vous tentez
    de dupliquer cette
    expérience, vous obtiendrez probablement une estimation légèrement
    différente&nbsp;; de plus, elle changera après chaque commande
    <command>ANALYZE</command> parce que les statistiques produites par
    <command>ANALYZE</command> sont prises à partir d'un extrait au hasard de la
    table.
   </para>

   <para>
    Maintenant, rendons la condition plus restrictive&nbsp;:

<screen>EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100;

                                  QUERY PLAN
------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=5.03..229.17 rows=101 width=244)
   Recheck Cond: (unique1 &lt; 100)
   ->  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.01 rows=101 width=0)
         Index Cond: (unique1 &lt; 100)</screen>

    Ici, le planificateur a décidé d'utiliser un plan en deux étapes&nbsp;: le
    n&oelig;ud en bas du plan visite un index pour trouver l'emplacement des
    lignes correspondant à la condition de l'index, puis le n&oelig;ud du plan
    du dessus récupère réellement ces lignes de la table. Récupérer séparément
    les lignes est bien plus coûteux que de les lire séquentiellement mais
    comme toutes les pages de la table n'ont pas à être visitées, cela revient
    toujours moins cher qu'un parcours séquentiel (la raison de l'utilisation
    d'un plan à deux niveaux est que le n&oelig;ud du plan du dessus trie les
    emplacements des lignes identifiés par l'index dans l'ordre physique avant
    de les lire pour minimiser les coûts des récupérations séparés. Le
    <quote>bitmap</quote> mentionné dans les noms de n&oelig;uds est le mécanisme
    qui s'occupe du tri).
   </para>

   <para>
    Maintenant ajoutons une autre condition à la clause <literal>WHERE</literal>&nbsp;:

<screen>EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND stringu1 = 'xxx';

                                  QUERY PLAN
------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=5.01..229.40 rows=1 width=244)
   Recheck Cond: (unique1 &lt; 100)
   Filter: (stringu1 = 'xxx'::name)
   -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.01 rows=101 width=0)
         Index Cond: (unique1 &lt; 100)
</screen>
 
    L'ajout de la condition <literal>stringu1 = 'xxx'</literal> réduit l'estimation
	du nombre de lignes renvoyées, mais pas son coût car il faut toujours parcourir
	le même ensemble de lignes. Notez que la clause <literal>stringu1</literal>
	ne peut être appliquée comme une condition d'index car l'index ne porte que
	sur la colonne <literal>unique1</literal>. À la place, un filtre a été appliqué
	sur les lignes récupérées par l'index. C'est pourquoi le coût a légèrement augmenté
	pour refléter la vérification supplémentaire.
   </para>

   <para>
    Dans certains cas, le planificateur préfèrera un plan <quote>simple</quote> de
	d'index :

<screen>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 = 42;
 
                                 QUERY PLAN
-----------------------------------------------------------------------------
 Index Scan using tenk1_unique1 on tenk1  (cost=0.00..8.27 rows=1 width=244)
   Index Cond: (unique1 = 42)
</screen>
 
    Dans ce type de plan, les lignes de la table sont récupérées dans l'ordre
	de l'index, ce qui les rend encore plus coûteuses à récupérer, mais il y
	en a tellement peu que le coût supplémentaire pour trier l'ordre des lignes
	n'est pas rentable. Vous verrez principalement ce type de plan pour les
	requêtes qui ne récupèrent qu'une seule ligne, ou pour les requêtes qui
	ont une condition <literal>ORDER BY</literal> qui correspond à l'ordre
	de l'index car cela ne nécessite aucune étape supplémentaire pour satisfaire
	l'<literal>ORDER BY</literal>.
    </para>
 
    <para>
    S'il y a des index sur plusieurs colonnes référencées dans la clause
    <literal>WHERE</literal>, le planificateur pourrait choisir d'utiliser
    une combinaison binaire (AND et OR) des index&nbsp;:
 
<screen>
 EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;
 
                                      QUERY PLAN
 -------------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=25.01..60.14 rows=10 width=244)
    Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
   -&gt;  BitmapAnd  (cost=25.01..25.01 rows=10 width=0)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.01 rows=101 width=0)
                Index Cond: (unique1 &lt; 100)
         -&gt;  Bitmap Index Scan on tenk1_unique2  (cost=0.00..19.74 rows=999 width=0)
                Index Cond: (unique2 &gt; 9000)
</screen>
    Mais ceci requiert de visiter plusieurs index, donc ce n'est pas nécessairement
    un gain comparé à l'utilisation d'un seul index et au traitement de l'autre
    condition par un filtre. Si vous variez les échelles de valeurs impliquées,
    vous vous apercevrez que le plan change en accord.
   </para>

   <para>
    Voici un exemple montrant les effets d'un <literal>LIMIT</literal>&nbsp;:

<screen>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000 LIMIT 2;

                                     QUERY PLAN
-------------------------------------------------------------------------------------
 Limit  (cost=0.00..14.25 rows=2 width=244)
   -&gt;  Index Scan using tenk1_unique2 on tenk1  (cost=0.00..71.23 rows=10 width=244)
         Index Cond: (unique2 &gt; 9000)
         Filter: (unique1 &lt; 100)
</screen>
   </para>

   <para>
   C'est la même requête qu'au dessus, mais avec l'ajout de <literal>LIMIT</literal>,
   ce qui fait que toutes les lignes ne seront pas récupérées, et donc que le planificateur
   change sa façon de procéder. Notez que le coût total ainsi que le nombre de lignes
   du n&oelig;ud de parcours d'index sont affichés comme si le n&oelig;ud devait être
   exécuté
   entièrement. Cependant, le n&oelig;ud Limit s'attend à s'arrêter après avoir
   récupéré seulement un cinquième de ces lignes, c'est pourquoi son coût total
   n'est qu'un cinquième du coût précédent, ce qui est le vrai coût estimé de la
   requête. Ce plan est préférable à l'ajout d'un n&oelig;ud Limit au plan précédant
   car le Limit ne pourrait pas empêcher le coût de départ du parcours d'index Bitmap,
   ce qui augmenterait le coût d'environ 25 unités avec cette approche.
   </para>

   <para>
    Maintenant, essayons de joindre deux tables, en utilisant les colonnes dont
    nous avons discuté&nbsp;:

<screen>
 EXPLAIN SELECT *
 FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2;
 
                                       QUERY PLAN
 --------------------------------------------------------------------------------------
 Nested Loop  (cost=4.33..118.25 rows=10 width=488)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=4.33..39.44 rows=10 width=244)
         Recheck Cond: (unique1 &lt; 10)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..4.33 rows=10 width=0)
               Index Cond: (unique1 &lt; 10)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.00..7.87 rows=1 width=244)
          Index Cond: (unique2 = t1.unique2)
</screen>
    </para>
 
    <para>
	Dans ce plan, nous avons un n&oelig;ud de jointure en boucle imbriquée
	sur deux parcours de tables en entrée. L'indentation des lignes
	de sommaire des n&oelig;uds reflètent la structure en arbre du plan. Le premier
    n&oelig;ud, ou n&oelig;ud <quote>externe</quote>, utilise le même parcours de bitmap que celui vu
	précédemment, et donc ses coût et nombre de ligne sont les mêmes que ce que
	l'on aurait	obtenu avec <literal>SELECT ... WHERE unique1 &lt; 10</literal>
	car la même clause <literal>WHERE</literal> <literal>unique1 &lt; 10</literal>
	est appliquée à ce n&oelig;ud.
	La clause <literal>t1.unique2 = t2.unique2</literal> n'a pas encore d'intérêt,
	elle n'affecte donc pas le nombre de lignes du parcours externe.  Le n&oelig;ud
	de jointure en boucle imbriquée s'exécutera sur le deuxième n&oelig;ud, ou
	n&oelig;ud <quote>interne</quote>, pour chaque ligne obtenue du n&oelig;ud externe.
	Les valeurs de colonne de la ligne externe courante peuvent être utilisées
	dans le parcours interne&nbsp;; ici, la valeur <literal>t1.unique2</literal> de la ligne
	externe est disponible, et on peut obtenir un plan et un coût similaire à ce que
	l'on a vu plus haut pour le cas simple <literal>SELECT ... WHERE t2.unique2 =
	<replaceable>constant</replaceable></literal>.
	(Le coût estimé est ici un peu plus faible que celui vu précédemment, en prévision
	de la mise en cache des données durant les parcours d'index répétés sur
	<literal>t2</literal>.) Les coûts du n&oelig;ud correspondant à la boucle sont
	ensuite initialisés sur la base du coût du parcours externe, avec une répétition
	du parcours interne pour chaque ligne externe (ici 10 * 7.87), plus un petit temps
	CPU pour traiter la jointure.
    </para>

   <para>
    Dans cet exemple, le nombre de lignes en sortie de la jointure est
    identique aux nombres de lignes des deux parcours mais ce n'est pas vrai
    en règle générale car vous pouvez avoir des clauses <literal>WHERE</literal>
    mentionnant les deux tables et qui, donc, peuvent seulement être appliquées au
    point de jointure, et non pas aux parcours d'index.
    Par exemple, si nous ajoutons une condition de plus&nbsp;:

<screen>
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2 AND t1.hundred &lt; t2.hundred;

                                      QUERY PLAN
--------------------------------------------------------------------------------------
 Nested Loop  (cost=4.33..118.28 rows=3 width=488)
   Join Filter: (t1.hundred &lt; t2.hundred)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=4.33..39.44 rows=10 width=244)
         Recheck Cond: (unique1 &lt; 10)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..4.33 rows=10 width=0)
               Index Cond: (unique1 &lt; 10)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.00..7.87 rows=1 width=244)
         Index Cond: (unique2 = t1.unique2)
</screen>

    La condition supplémentaire <literal>t1.hundred &lt; t2.hundred</literal> ne peut
	être testée dans l'index <literal>tenk2_unique2</literal>, il est donc appliqué
	au n&oelig;ud de jointure. Cela réduit l'estimation du nombre de lignes dans
	le n&oelig;ud de jointure, mais ne change aucun parcours d'entrée.
   </para>

   <para>
    Quand vous utilisez des jointures externes, vous pourrez voir des n&oelig;ud
	de plan de jointure avec à la fois des conditions <quote>Join Filter</quote>
	et <quote>Filter</quote> simple attachées.
	Les conditions Join Filter viennent des clauses de jointures externe
	<litteral>ON</litteral>, pour qu'une ligne ne satisfaisant pas la condition
	Join Filter puisse toujours être récupérée comme une colonne null-extended.
	Mais une condition Filter simple est appliquée après la règle de jointure
	externe et supprime donc les lignes de manière inconditionnelles. Dans
	une jointure interne, il n'y a pas de différence sémantique entre ces types
	de filtre.
   </para>

   <para>
    Si nous changeons un peu la sélectivité de la requête, on pourrait obtenir
	un plan de jointure très différent&nbsp;:

<screen>
EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                        QUERY PLAN
------------------------------------------------------------------------------------------
 Hash Join  (cost=230.43..713.94 rows=101 width=488)
   Hash Cond: (t2.unique2 = t1.unique2)
   -&gt;  Seq Scan on tenk2 t2  (cost=0.00..445.00 rows=10000 width=244)
   -&gt;  Hash  (cost=229.17..229.17 rows=101 width=244)
         -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=5.03..229.17 rows=101 width=244)
               Recheck Cond: (unique1 &lt; 100)
               -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.01 rows=101 width=0)
                     Index Cond: (unique1 &lt; 100)
</screen>
   </para>

   <para>
   Ici, le planificateur a choisi d'utiliser une jointure de hachage, dans
   laquelle les lignes d'une table sont entrées dans une table de hachage en
   mémoire, après quoi l'autre table est parcourue et la table de hachage
   sondée pour faire correspondre chaque ligne. Notez encore une fois
   comment l'indentation reflète la structure du plan&nbsp;: le parcours d'index
   bitmap sur <literal>tenk1</literal> est l'entrée du n&oelig;ud de hachage,
   qui construit la table de hachage.  C'est alors retourné au n&oelig;ud
   de jointure de hachage, qui lit les lignes depuis le plan du fils externe
   et cherche dans la table de hachage pour chaque ligne.
   </para>

   <para>
    Un autre type de jointure possible est la jointure d'assemblage, illustrée
    ici&nbsp;:

<screen>
EXPLAIN SELECT *
FROM tenk1 t1, onek t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                        QUERY PLAN
------------------------------------------------------------------------------------------
 Merge Join  (cost=197.83..267.93 rows=10 width=488)
   Merge Cond: (t1.unique2 = t2.unique2)
   -&gt;  Index Scan using tenk1_unique2 on tenk1 t1  (cost=0.00..656.25 rows=101 width=244)
         Filter: (unique1 &lt; 100)
   -&gt;  Sort  (cost=197.83..200.33 rows=1000 width=244)
         Sort Key: t2.unique2
         -&gt;  Seq Scan on onek t2  (cost=0.00..148.00 rows=1000 width=244)
</screen>
   </para>

   <para>
    La jointure d'assemblage nécessite que les données en entrée soient triées
	sur	la clé de jointure. Dans ce plan, les données de <literal>tenk1</literal>
	sont triées grâce à l'utilisation d'un parcours d'index pour visiter les
	lignes dans le bon ordre, mais un parcours séquentiel suivi d'un tri sont
	préférables pour <literal>onek</literal> car il y a beaucoup plus de
	lignes à visiter dans cette table.
	(Un parcours séquentiel suivi d'un tri bat fréquemment un parcours d'index
	pour trier de nombreuses lignes, du fait des accès disques non séquentiels
	requis par le parcours d'index.)
   </para>

   <para>
    Une façon de rechercher des plans différents est de forcer le planificateur
    à oublier certaines stratégies qu'il aurait trouvé moins coûteuses en
    utilisant les
    options d'activation (enable)/désactivation (disable) décrites dans la <xref
    linkend="runtime-config-query-enable"/> (c'est un outil complexe mais utile&nbsp;;
    voir aussi la <xref linkend="explicit-joins"/>).
	Par exemple, si nous n'étions pas convaincu qu'un parcours séquentiel suivi d'un tri
	soit la meilleure façon de parcourir la table <literal>onek</literal> dans
	l'exemple précédent, nous pourrions essayer

<screen>
SET enable_sort = off;
EXPLAIN SELECT *
FROM tenk1 t1, onek t2
 WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;
 
                                         QUERY PLAN
 ------------------------------------------------------------------------------------------
 Merge Join  (cost=0.00..292.36 rows=10 width=488)
   Merge Cond: (t1.unique2 = t2.unique2)
   -&gt;  Index Scan using tenk1_unique2 on tenk1 t1  (cost=0.00..656.25 rows=101 width=244)
         Filter: (unique1 &lt; 100)
   -&gt;  Index Scan using onek_unique2 on onek t2  (cost=0.00..224.76 rows=1000 width=244)
</screen>
 
    ce qui montre que le planificateur pense que le tri de <literal>onek</literal>
	par un parcours d'index est plus coûteux d'environ 12% par rapport à un
    parcours séquentiel suivi d'un tri.
	Bien sûr, la question suivante est de savoir s'il a raison sur ce point.
	Nous pourrions vérifier cela en utilisant <command>EXPLAIN ANALYZE</command>,
	comme expliqué ci-dessous.
    </para>
 
  </sect2>

  <sect2 id="using-explain-analyze">
   <title><command>EXPLAIN ANALYZE</command></title>

    <para>
	Il est possible de vérifier l'exactitude des estimations du
	planificateur en utilisant l'opption <literal>ANALYZE</literal> de
	<command>EXPLAIN</command>. Avec cette option, <command>EXPLAIN</command>
	exécute vraiment la requête, puis affiche le vrai nombre de lignes et les
	vrais temps passés dans chaque n&oelig;ud, avec ceux estimés par un
	simple <command>EXPLAIN</command>. Par exemple, nous pourrions avoir
	un résultat tel que&nbsp;:
	
 <screen>
 EXPLAIN ANALYZE SELECT *
 FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2;

                                                           QUERY PLAN
---------------------------------------------------------------------------------------------------------------------------------
 Nested Loop  (cost=4.33..118.25 rows=10 width=488) (actual time=0.370..1.126 rows=10 loops=1)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=4.33..39.44 rows=10 width=244) (actual time=0.254..0.380 rows=10 loops=1)
         Recheck Cond: (unique1 &lt; 10)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..4.33 rows=10 width=0) (actual time=0.164..0.164 rows=10 loops=1)
               Index Cond: (unique1 &lt; 10)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.00..7.87 rows=1 width=244) (actual time=0.041..0.048 rows=1 loops=10)
          Index Cond: (unique2 = t1.unique2)
 Total runtime: 2.414 ms</screen>

    Notez que les valeurs <quote>temps réel</quote> sont en millisecondes alors
    que les estimations de <quote>coût</quote> sont exprimées dans des unités
    arbitraires&nbsp;; il y a donc peu de chances qu'elles correspondent.
	L'information qu'il faut généralement rechercher est si le nombre de lignes
	estimées est raisonnablement proche de la réalité. Dans cet exemple,
	les estimations étaient toutes rigoureusement exactes, mais c'est en
	pratique plutôt inhabituel.
   </para>

   <para>
    Dans certains plans de requête, il est possible qu'un n&oelig;ud de
    sous-plan soit exécuté plus d'une fois. Par exemple, le parcours d'index
    interne est exécuté une fois par ligne externe dans le plan de boucle
    imbriquée ci-dessus. Dans de tels cas, la valeur <literal>loops</literal>
    renvoie le nombre total d'exécutions du n&oelig;ud, et le temps réel et les
    valeurs des lignes affichées sont une moyenne par exécution. Ceci est fait
    pour que les nombres soient comparables avec la façon dont les estimations
    de coûts sont affichées. Multipliez par la valeur de <literal>loops</literal>
    pour obtenir le temps total réellement passé dans le n&oelig;ud.
	Dans l'exemple précédent, le parcours d'index sur <literal>tenk2</literal>
	a pris un total de 0,480 millisecondes.
   </para>

   <para>
    Dans certains cas, <command>EXPLAIN ANALYZE</command> affiche des
	statistiques d'exécution supplémentaires après le temps et nombre de lignes
	de l'exécution d'un n&oelig;ud du plan.
	Par exemple, les n&oelig;ud de tri et de hachage fournissent
	des informations supplémentaires&nbsp;:

<screen>
EXPLAIN ANALYZE SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2 ORDER BY t1.fivethous;

                                                                 QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------------------------
 Sort  (cost=717.30..717.56 rows=101 width=488) (actual time=104.950..105.327 rows=100 loops=1)
   Sort Key: t1.fivethous
   Sort Method: quicksort  Memory: 68kB
   -&gt;  Hash Join  (cost=230.43..713.94 rows=101 width=488) (actual time=3.680..102.396 rows=100 loops=1)
         Hash Cond: (t2.unique2 = t1.unique2)
         -&gt;  Seq Scan on tenk2 t2  (cost=0.00..445.00 rows=10000 width=244) (actual time=0.046..46.219 rows=10000 loops=1)
         -&gt;  Hash  (cost=229.17..229.17 rows=101 width=244) (actual time=3.184..3.184 rows=100 loops=1)
               Buckets: 1024  Batches: 1  Memory Usage: 27kB
               -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=5.03..229.17 rows=101 width=244) (actual time=0.612..1.959 rows=100 loops=1)
                     Recheck Cond: (unique1 &lt; 100)
                     -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.01 rows=101 width=0) (actual time=0.390..0.390 rows=100 loops=1)
                           Index Cond: (unique1 &lt; 100)
 Total runtime: 107.392 ms
</screen>

    Le n&oelig;ud de tri donne la méthode de tri utilisée (en particulier, si
	le tri s'est effectué en mémoire ou sur disque) ainsi que la quantité de
	mémoire ou d'espace disque requis.
	Le n&oelig;ud de hachage montre le nombre de paquets de hachage, le nombre
	de lots ainsi la quantité maximum de mémoire utilisée pour la table de
	hachage (si le nombre de lots est supérieur à un, il y aura également
	l'utilisation de l'espace disque impliqué, mais cela n'est pas montré
    dans cet exemple).
   </para>

   <para>
    Un autre type d'information supplémentaire est le nombre de lignes
    supprimé par une condition de filtrage&nbsp;:

<screen>
EXPLAIN ANALYZE SELECT * FROM tenk1 WHERE ten &lt; 7;

                                                QUERY PLAN
----------------------------------------------------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..483.00 rows=7000 width=244) (actual time=0.111..59.249 rows=7000 loops=1)
   Filter: (ten &lt; 7)
   Rows Removed by Filter: 3000
 Total runtime: 85.340 ms
</screen>

    Ces nombres peuvent être particulièrement précieux pour les conditions de
	filtres appliquées aux n&oelig;uds de jointure.
	La ligne <quote>Rows Removed</quote> n'apparait que si au moins une ligne
	parcourue, ou une ligne potentiellement appairée dans le cas d'un n&oelig;ud
	de jointure, est rejetée par la condition de filtre.
   </para>

   <para>
    Un cas similaire aux conditions de filtre apparait avec des parcours
	d'index <quote>avec perte</quote>. Par exemple, regardez cette recherche
	de poligone contenant un point spécifique&nbsp;:

<screen>
EXPLAIN ANALYZE SELECT * FROM polygon_tbl WHERE f1 @&gt; polygon '(0.5,2.0)';

                                              QUERY PLAN
------------------------------------------------------------------------------------------------------
 Seq Scan on polygon_tbl  (cost=0.00..1.05 rows=1 width=32) (actual time=0.251..0.251 rows=0 loops=1)
   Filter: (f1 @&gt; '((0.5,2))'::polygon)
   Rows Removed by Filter: 4
 Total runtime: 0.517 ms
</screen>

    Le planificateur pense (plutôt correctement) que cette table d'échantillon
	est trop petite pour s'embêter avec un parcours d'index, et utilise donc un
	parcours séquentiel dans lequel toutes les lignes sont rejetées par la condition
	de filtre. Mais si nous forçons l'utilisation d'un parcours d'index, nous voyons&nbsp;:
	
<screen>
SET enable_seqscan TO off;

EXPLAIN ANALYZE SELECT * FROM polygon_tbl WHERE f1 @&gt; polygon '(0.5,2.0)';

                                                        QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------
 Index Scan using gpolygonind on polygon_tbl  (cost=0.00..8.27 rows=1 width=32) (actual time=0.293..0.293 rows=0 loops=1)
   Index Cond: (f1 @&gt; '((0.5,2))'::polygon)
   Rows Removed by Index Recheck: 1
 Total runtime: 1.054 ms
</screen>

    L'index retourne une ligne candidate, qui est ensuite rejetée par une
    deuxième vérification de la condition de l'index. Cela
	arrive car un index GiST est <quote>avec perte</quote> pour les tests
	de contenance de polygone&nbsp;: il retourne en fait les lignes pour lequelles
	les polygones chevauchent la cible, ce qui nécessite après coup un test de
	contenance exacte sur ces lignes.
   </para>

   <para>
    <command>EXPLAIN</command> a une option <literal>BUFFERS</literal> qui peut être utilisée avec 
    <literal>ANALYZE</literal> pour obtenir encore plus de statistiques	d'exécution:

<screen>
EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;

                                                            QUERY PLAN
-----------------------------------------------------------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=25.07..60.23 rows=10 width=244) (actual time=3.069..3.213 rows=10 loops=1)
   Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
   Buffers: shared hit=16
   -&gt;  BitmapAnd  (cost=25.07..25.07 rows=10 width=0) (actual time=2.967..2.967 rows=0 loops=1)
         Buffers: shared hit=7
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.02 rows=102 width=0) (actual time=0.732..0.732 rows=200 loops=1)
               Index Cond: (unique1 &lt; 100)
               Buffers: shared hit=2
         -&gt;  Bitmap Index Scan on tenk1_unique2  (cost=0.00..19.80 rows=1007 width=0) (actual time=2.015..2.015 rows=1009 loops=1)
               Index Cond: (unique2 &gt; 9000)
               Buffers: shared hit=5
 Total runtime: 3.917 ms
</screen>

    Les nombres fournis par <literal>BUFFERS</literal> aident à identifier
	les parties de la requête les plus intensives en terme d'entrées sorties.
   </para>

   <para>
    Il faut garder en tête que comme <command>EXPLAIN ANALYZE</command> exécute
    vraiment la requête, tous les effets secondaires se produiront comme
	d'habitude, même si quel que soit l'affichage de la requête, il est remplacé
	par la sortie des données d'<command>EXPLAIN</command>. Si vous voulez
	analyser une requête modifiant les données sans changer les données en table,
	vous pouvez annuler les modifications après, par exemple&nbsp;:

<screen>
BEGIN;

EXPLAIN ANALYZE UPDATE tenk1 SET hundred = hundred + 1 WHERE unique1 &lt; 100;

                                                           QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------------
 Update on tenk1  (cost=5.03..229.42 rows=101 width=250) (actual time=81.055..81.055 rows=0 loops=1)
   -&gt;  Bitmap Heap Scan on tenk1  (cost=5.03..229.42 rows=101 width=250) (actual time=0.766..3.396 rows=100 loops=1)
         Recheck Cond: (unique1 &lt; 100)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.01 rows=101 width=0) (actual time=0.461..0.461 rows=100 loops=1)
               Index Cond: (unique1 &lt; 100)
 Total runtime: 81.922 ms

ROLLBACK;
</screen>
   </para>

   <para>
   Comme vous pouvez le voir dans cet exemple, quand la requête contient une commande 
   <command>INSERT</command>, <command>UPDATE</command> ou <command>DELETE</command>
   l'application des changements est fait au niveau du n&oelig;ud principal
   Insert, Update ou Delete du plan.  Les n&oelig;uds du plan sous celui-ci
   effectuent le travail de recherche des anciennes lignes et/ou le calcul
   des nouvelles données. Ainsi au-dessus, on peut voir les même tris de
   parcours de bitmap déjà vu précédemment, et leur sortie est envoyée
   à un n&oelig;ud de mise à jour qui stocke les lignes modifiées.
   Il est intéressant de noter que bien que le n&oelig;ud de modification
   de données puisse prendre une part considérable sur le temps d'exécution
   (ici, c'est la partie la plus gourmande), le planificateur n'ajoute rien
   au coût estimé pour considérer ce travail. C'est dû au fait que le travail
   à effectuer est le même pour chaque plan de requête correct, et n'affecte
   donc pas les décisions du planificateur.
   </para>

   <para>
     Le <literal>Temps total d'exécution</literal> donné par <command>EXPLAIN
    ANALYZE</command> inclut le temps de démarrage et d'arrêt de l'exécuteur,
	ainsi que le temps d'exécution de tous les triggers pouvant être déclenchés,
    mais n'inclut pas les temps d'analyse, de réécriture ou de planification.
	Le temps passé a exécuter les triggers <literal>BEFORE</literal>, s'il y
	en a, est inclus dans le temps passé à l'exécution des n&oelig;uds Insert,
	Update ou Delete associés mais le temps passé a exécuter les triggers
	<literal>AFTER</literal> n'est pas compté car les triggers
	<literal>AFTER</literal> sont déclenchés après l'achèvement du plan entier.
	Le temps total passé dans chaque trigger (que ce soit <literal>BEFORE</literal>
	ou <literal>AFTER</literal>) est affiché séparément.
	Notez que les triggers de contrainte ne seront pas exécutés avant la fin
	de la transaction et par conséquent ne seront pas affichés du tout par
	 <command>EXPLAIN ANALYZE</command>.
    </para>
 
  </sect2>

  <sect2 id="using-explain-caveats">
   <title>Caveats</title>

   <para>
    Il existe deux raisons importantes pour lesquelles les temps d'exécution
    mesurés par <command>EXPLAIN ANALYZE</command> peuvent dévier de l'exécution
    normale de la même requête. Tout d'abord, comme aucune ligne n'est
    réellement envoyée au client, les coûts de conversion réseau et les coûts
    de formatage des entrées/sorties ne sont pas inclus.
	Ensuite, le surcoût de mesure induit par <command>EXPLAIN ANALYZE</command>
	peut être significatif, plus particlièrement sur les machines avec
	un appel système <function>gettimeofday()</function> lent. Vous pouvez
	utiliser l'outil <xref linkend="pgtesttiming"/> pour mesurer le surcoût
	du calcul du temps sur votre système.
   </para>

   <para>
    Les résultats de <command>EXPLAIN</command> ne devraient
    pas être extrapolés pour des situations autres que celles de vos tests en
    cours&nbsp;; par exemple, les résultats sur une petite table ne peuvent
    être appliqués à des tables bien plus importantes. Les estimations de coût
    du planificateur ne sont pas linéaires et, du coup, il pourrait bien
    choisir un plan différent pour une table plus petite ou plus grande. Un
    exemple extrême est celui d'une table occupant une page disque. Vous
    obtiendrez pratiquement toujours un parcours séquentiel que des index soient
    disponibles ou non. Le planificateur réalise que cela va nécessiter la
    lecture d'une seule page disque pour traiter la table dans ce cas, il n'y a
    donc pas d'intérêt à étendre des lectures de pages supplémentaires pour un
    index. (Nous voyons cela arriver dans l'exemple
    <literal>polygon_tbl</literal> au dessus.)
   </para>

   <para>
    Ici sont des cas dans lesquels les valeurs réelles et estimées ne
	correspondent pas vraiment, mais qui ne sont pas totalement fausses.
	Un tel cas peut se produire quand un n&oelig;ud d'exécution d'un plan
	est arrêté par un <literal>LIMIT</literal> ou effet similaire.  Par
	exemple, dans la requête <literal>LIMIT</literal> utilisée précédemment,

<screen>
EXPLAIN ANALYZE SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000 LIMIT 2;

                                                          QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.00..14.25 rows=2 width=244) (actual time=1.652..2.293 rows=2 loops=1)
   -&gt;  Index Scan using tenk1_unique2 on tenk1  (cost=0.00..71.23 rows=10 width=244) (actual time=1.631..2.259 rows=2 loops=1)
         Index Cond: (unique2 &gt; 9000)
         Filter: (unique1 &lt; 100)
         Rows Removed by Filter: 287
 Total runtime: 2.857 ms
</screen>

    les estimations de coût et de nombre de lignes pour le n&oelig;ud
	de parcours d'index sont affichées comme s'ils devaient s'exécuter
	jusqu'à	la fin. Mais en réalité le n&oelig;ud Limit arrête la
	récupération des lignes après la seconde, et donc le vrai nombre
	de lignes n'est que de 2 et le temps d'exécution est moins que
	suggérait le coût estimé.  Ce n'est pas une erreur d'estimation,
	juste une contradiction entre la façon dont l'estimation et les
	valeurs réelles sont affichées.
   </para>

   <para>
    Les jointures d'assemblage ont également leurs artefacts de mesure qui
	peuvent embrouiller une personne non avertie.
	Une jointure d'assemblage arrêtera la lecture d'une entrée si l'autre
	entrée est épuisée et que la prochaine valeur clé dans la première
	entrée est supérieure à la dernière valeur clé de l'autre entrée&nbsp;;
	dans un cas comme ça, il ne peut plus y avoir de correspondance et
	il est donc inutile de parcourir le reste de la première entrée.
	Cela a donc pour conséquence de ne pas lire entièrement un des fils,
	avec des résultats similaires à ceux mentionnés pour <literal>LIMIT</literal>.
	De même, si le fils externe (premier fils) contient des lignes avec
	des valeurs de clé dupliquées, le fils externe (second fils) est
	sauvegardé et les lignes correspondant à cette valeur clé sont
	parcourues de nouveau.  <command>EXPLAIN ANALYZE</command> compte ces
	émissions répétées de même lignes internes comme si elles étaient
	de vraies lignes supplémentaires.  Quand il y a de nombreux
	doublons externes, le nombre réel de lignes affiché pour le n&oelig;ud
	de plan du fils interne peut être significativement plus grand que le
	nombre de lignes qu'il y a vraiment dans la relation interne.
   </para>

   <para>
    Les n&oelig;uds BitmapAnd et BitmapOr affichent toujours un nombre de
	lignes réel à 0, du fait des limitations d'implémentation.
   </para>
  </sect2>

 </sect1>

 <sect1 id="planner-stats">
  <title>Statistiques utilisées par le planificateur</title>

  <indexterm zone="planner-stats">
   <primary>statistiques</primary>
   <secondary>du planificateur</secondary>
  </indexterm>

  <para>
   Comme nous avons vu dans la section précédente, le planificateur de requêtes
   a besoin d'estimer le nombre de lignes récupérées par une requête pour faire
   les bons choix dans ses plans de requêtes. Cette section fournit un aperçu
   rapide sur les statistiques que le système utilise pour ces estimations.
  </para>

  <para>
   Un élément des statistiques est le nombre total d'entrées dans chaque
   table et index, ainsi que le nombre de blocs disque occupés par chaque table
   et index. Cette information est conservée dans la table
   <link linkend="catalog-pg-class"><structname>pg_class</structname></link>
   sur les colonnes <structfield>reltuples</structfield> et
   <structfield>relpages</structfield>. Nous pouvons la regarder avec des
   requêtes comme celle-ci&nbsp;:

<screen>SELECT relname, relkind, reltuples, relpages
FROM pg_class
WHERE relname LIKE 'tenk1%';

       relname        | relkind | reltuples | relpages
----------------------+---------+-----------+----------
 tenk1                | r       |     10000 |      358
 tenk1_hundred        | i       |     10000 |       30
 tenk1_thous_tenthous | i       |     10000 |       30
 tenk1_unique1        | i       |     10000 |       30
 tenk1_unique2        | i       |     10000 |       30
(5 rows)</screen>

   Ici, nous pouvons voir que <structname>tenk1</structname> contient 10000
   lignes, comme pour ses index, mais que les index sont bien plus petits que la
   table (ce qui n'est pas surprenant).
  </para>

  <para>
   Pour des raisons d'efficacité, <structfield>reltuples</structfield> et
   <structfield>relpages</structfield> ne sont pas mises à jour en temps réel, et
   du coup, elles contiennent habituellement des valeurs un peu obsolètes. Elles
   sont mises à jour par les commandes <command>VACUUM</command>, <command>ANALYZE</command>
   et quelques commandes DDL comme <command>CREATE INDEX</command>. 
   Une opération <command>VACUUM</command>
   ou <command>ANALYZE</command> qui ne parcourt pas la table entièrement
   (ce qui est le cas le plus fréquent) augmentera de façon incrémentale
   la valeur de <structfield>reltuples</structfield> sur la base de la partie
   de la table qu'elle a parcouru, résultant en une valeur approximative.
   Dans tous les cas, le planificateur mettra à l'échelle
   les valeurs qu'il aura trouver dans <structname>pg_class</structname> pour
   correspondre à la taille physique de la table, obtenant ainsi une
   approximation plus proche de la réalité.
  </para>

  <indexterm>
   <primary>pg_statistic</primary>
  </indexterm>

  <para>
   La plupart des requêtes ne récupère qu'une fraction des lignes dans une
   table à cause de clauses <literal>WHERE</literal> qui restreignent les lignes à
   examiner. Du coup, le planificateur a besoin d'une estimation de la
   <firstterm>sélectivité</firstterm> des clauses <literal>WHERE</literal>, c'est-à-dire la
   fraction des lignes qui correspondent à chaque condition de la clause
   <literal>WHERE</literal>. L'information utilisée pour cette tâche est stockée dans
   le catalogue système <link
   linkend="catalog-pg-statistic"><structname>pg_statistic</structname></link>.
   Les entrées de <structname>pg_statistic</structname> sont mises à jour par
   les commandes <command>ANALYZE</command> et <command>VACUUM ANALYZE</command> et sont
   toujours approximatives même si elles ont été mises à jour récemment.
  </para>

  <indexterm>
   <primary>pg_stats</primary>
  </indexterm>

  <para>
   Plutôt que de regarder directement dans
   <structname>pg_statistic</structname>, il est mieux de visualiser sa vue
   <link linkend="view-pg-stats"><structname>pg_stats</structname></link>
   lors de l'examen manuel des statistiques.
   <structname>pg_stats</structname> est conçu pour être plus facilement
   lisible. De plus, <structname>pg_stats</structname> est lisible par tous
   alors que <structname>pg_statistic</structname> n'est lisible que par un
   superutilisateur (ceci empêche les utilisateurs non privilégiés d'apprendre
   certains choses sur le contenu des tables appartenant à d'autres personnes à
   partir des statistiques. La vue <structname>pg_stats</structname> est restreinte
   pour afficher seulement les lignes des tables lisibles par l'utilisateur courant).
   Par exemple, nous pourrions lancer&nbsp;:

<screen>SELECT attname, inherited, n_distinct,
       array_to_string(most_common_vals, E'\n') as most_common_vals
FROM pg_stats
WHERE tablename = 'road';

 attname | inherited | n_distinct |          most_common_vals          
---------+-----------+------------+------------------------------------
 name    | f         |  -0.363388 | I- 580                        Ramp+
         |           |            | I- 880                        Ramp+
         |           |            | Sp Railroad                       +
         |           |            | I- 580                            +
         |           |            | I- 680                        Ramp
 name    | t         |  -0.284859 | I- 880                        Ramp+
         |           |            | I- 580                        Ramp+
         |           |            | I- 680                        Ramp+
         |           |            | I- 580                            +
         |           |            | State Hwy 13                  Ramp
(2 rows)
</screen>

   Notez que deux lignes sont affichées pour la même colonne, une correspondant
   à la hiérarchie d'héritage complète commençant à la table
   <literal>road</literal> (<literal>inherited</literal>=<literal>t</literal>),
   et une autre incluant seulement la table <literal>road</literal> elle-même
   (<literal>inherited</literal>=<literal>f</literal>).

  </para>

  <para>
   Le nombre d'informations stockées dans
   <structname>pg_statistic</structname> par <command>ANALYZE</command>,
   en particulier le nombre maximum
   d'éléments dans les tableaux <structfield>most_common_vals</structfield> et
   <structfield>histogram_bounds</structfield> pour chaque colonne, peut être initialisé
   sur une base colonne-par-colonne en utilisant la commande <command>ALTER
   TABLE SET STATISTICS</command> ou globalement en initialisant la variable de
   configuration <xref linkend="guc-default-statistics-target"/>. La limite par
   défaut est actuellement de cent entrées. Augmenter la limite pourrait
   permettre des estimations plus précises du planificateur, en particulier
   pour les colonnes ayant des distributions de données irrégulières, au prix
   d'un plus grand espace consommé dans <structname>pg_statistic</structname> et
   en un temps plus long pour calculer les estimations. En revanche, une limite
   plus basse pourrait être suffisante pour les colonnes à distributions de
   données simples.
  </para>

  <para>
   Le <xref linkend="planner-stats-details"/> donne plus de détails sur
   l'utilisation des statistiques par le planificateur.
  </para>

 </sect1>

 <sect1 id="explicit-joins">
  <title>Contrôler le planificateur avec des clauses <literal>JOIN</literal>
   explicites</title>

  <indexterm zone="explicit-joins">
   <primary>jointure</primary>
   <secondary>contrôlant l'ordre</secondary>
  </indexterm>

  <para>
   Il est possible de contrôler le planificateur de requêtes à un certain
   point en utilisant une syntaxe <literal>JOIN</literal> explicite. Pour voir en
   quoi ceci est important, nous avons besoin de quelques connaissances.
  </para>

  <para>
   Dans une simple requête de jointure, telle que&nbsp;:
<programlisting>SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;</programlisting>
   le planificateur est libre de joindre les tables données dans n'importe
   quel ordre. Par exemple, il pourrait générer un plan de requête qui joint A à
   B en utilisant la condition <literal>WHERE</literal> <literal>a.id = b.id</literal>, puis
   joint C à cette nouvelle table jointe en utilisant l'autre condition
   <literal>WHERE</literal>. Ou il pourrait joindre B à C, puis A au résultat de cette
   jointure précédente. Ou il pourrait joindre A à C puis les joindre avec B
   mais cela pourrait ne pas être efficace car le produit cartésien complet de A
   et C devra être formé alors qu'il n'y a pas de condition applicable dans la
   clause <literal>WHERE</literal> pour permettre une optimisation de la jointure
   (toutes les jointures dans l'exécuteur <productname>PostgreSQL</productname>
   arrivent entre deux tables en entrées donc il est nécessaire de construire le
   résultat de l'une ou de l'autre de ces façons). Le point important est que
   ces différentes possibilités de jointures donnent des résultats
   sémantiquement équivalents mais pourraient avoir des coûts d'exécution
   grandement différents. Du coup, le planificateur va toutes les explorer pour
   trouver le plan de requête le plus efficace.
  </para>

  <para>
   Quand une requête implique seulement deux ou trois tables, il y a peu
   d'ordres de jointures à préparer. Mais le nombre d'ordres de jointures
   possibles grandit de façon exponentielle au fur et à mesure que le nombre de
   tables augmente. Au-delà de dix tables en entrée, il n'est plus possible de
   faire une recherche exhaustive de toutes les possibilités et même la
   planification de six ou sept tables pourrait prendre beaucoup de temps.
   Quand il y a trop de tables en entrée, le planificateur
   <productname>PostgreSQL</productname> basculera d'une recherche exhaustive à
   une recherche <firstterm>génétique</firstterm> probabiliste via un nombre
   limité de possibilités (la limite de bascule est initialisée par le paramètre
   en exécution <xref linkend="guc-geqo-threshold"/>). La recherche génétique prend
   moins de temps mais elle ne trouvera pas nécessairement le meilleur plan
   possible.
  </para>

  <para>
   Quand la requête implique des jointures externes, le planificateur est moins
   libre qu'il ne l'est lors de jointures internes. Par exemple, considérez&nbsp;:
<programlisting>SELECT * FROM a LEFT JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);</programlisting>
   Bien que les restrictions de cette requête semblent superficiellement
   similaires à l'exemple précédent, les sémantiques sont différentes car une
   ligne doit être émise pour chaque ligne de A qui n'a pas de ligne
   correspondante dans la jointure entre B et C. Du coup, le planificateur n'a
   pas de choix dans l'ordre de la jointure ici&nbsp;: il doit joindre B à C
   puis joindre A à ce résultat. Du coup, cette requête prend moins de temps à
   planifier que la requête précédente. Dans d'autres cas, le planificateur
   pourrait être capable de déterminer que plus d'un ordre de jointure est
   sûr. Par exemple, étant donné&nbsp;:
<programlisting>
SELECT * FROM a LEFT JOIN b ON (a.bid = b.id) LEFT JOIN c ON (a.cid = c.id);
</programlisting>
   il est valide de joindre A à soit B soit C en premier. Actuellement, seul un
   <literal>FULL JOIN</literal> contraint complètement l'ordre de jointure. La
   plupart des cas pratiques impliquant un <literal>LEFT JOIN</literal> ou un
   <literal>RIGHT JOIN</literal> peuvent être arrangés jusqu'à un certain degré.
  </para>

  <para>
   La syntaxe de jointure interne explicite (<literal>INNER
   JOIN</literal>, <literal>CROSS JOIN</literal> ou <literal>JOIN</literal>) est sémantiquement
   identique à lister les relations en entrées du <literal>FROM</literal>, donc il
   ne contraint pas l'ordre de la jointure.
  </para>

  <para>
   Même si la plupart des types de <literal>JOIN</literal> ne contraignent pas
   complètement l'ordre de jointure, il est possible d'instruire le planificateur
   de requête de <productname>PostgreSQL</productname> pour qu'il traite toutes
   les clauses <literal>JOIN</literal> de façon à contraindre quand même l'ordre
   de jointure.
   Par exemple, ces trois requêtes sont logiquement équivalentes&nbsp;:
<programlisting>SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a CROSS JOIN b CROSS JOIN c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);</programlisting>
   Mais si nous disons au planificateur d'honorer l'ordre des
   <literal>JOIN</literal>, la deuxième et la troisième prendront moins de temps à
   planifier que la première. Cet effet n'est pas inquiétant pour seulement
   trois tables mais cela pourrait bien nous aider avec un nombre important
   de tables.
  </para>

  <para>
   Pour forcer le planificateur à suivre l'ordre de jointure demandé par les
   <literal>JOIN</literal> explicites, initialisez le paramètre en exécution
   <xref linkend="guc-join-collapse-limit"/> à 1 (d'autres valeurs possibles
   sont discutées plus bas).
  </para>

  <para>
   Vous n'avez pas besoin de restreindre l'ordre de jointure pour diminuer le 
   temps de recherche car il est bien d'utiliser les opérateurs <literal>JOIN</literal>
   dans les éléments d'une liste <literal>FROM</literal>. Par exemple,
   considérez&nbsp;:
<programlisting>SELECT * FROM a CROSS JOIN b, c, d, e WHERE ...;</programlisting>
   Avec <varname>join_collapse_limit</varname> = 1, ceci force le planificateur à
   joindre A à B avant de les joindre aux autres tables mais sans restreindre
   ses choix. Dans cet exemple, le nombre d'ordres de jointures possibles
   est réduit par un facteur de cinq.
  </para>

  <para>
   Restreindre la recherche du planificateur de cette façon est une technique
   utile pour réduire les temps de planification et pour diriger le
   planificateur vers un bon plan de requêtes. Si le planificateur choisit un
   mauvais ordre de jointure par défaut, vous pouvez le forcer à choisir un
   meilleur ordre via la syntaxe <literal>JOIN</literal> &mdash; en supposant que vous
   connaissiez un meilleur ordre. Une expérimentation est recommandée.
  </para>

  <para>
   Un problème très proche et affectant le temps de planification est le
   regroupement de sous-requêtes dans leurs requêtes parents. Par exemple,
   considérez&nbsp;:
<programlisting>SELECT *
FROM x, y,
    (SELECT * FROM a, b, c WHERE quelquechose) AS ss
WHERE quelquechosedautre;</programlisting>
   Cette requête pourrait survenir suite à l'utilisation d'une vue contenant une
   jointure&nbsp;; la règle <literal>SELECT</literal> de la vue sera insérée à la
   place de la référence de la vue, demande une requête plutôt identique à celle
   ci-dessus. Normalement, le planificateur essaiera de regrouper la
   sous-requête avec son parent, donnant&nbsp;:
<programlisting>SELECT * FROM x, y, a, b, c WHERE quelquechose AND quelquechosedautre;</programlisting>
   Ceci résulte habituellement en un meilleur plan que de planifier séparément
   la sous-requête (par exemple, les conditions <literal>WHERE</literal> externes
   pourraient être telles que joindre X à A élimine en premier lieu un bon
   nombre de lignes de A, évitant ainsi le besoin de former la sortie complète
   de la sous-requête). Mais en même temps, nous avons accru le temps de
   planification&nbsp;; ici, nous avons une problème de jointure à cinq tables
   remplaçant un problème de deux jointures séparées à trois tables. À cause de
   l'augmentation exponentielle du nombre de possibilités, ceci fait une grande
   différence. Le planificateur essaie d'éviter de se retrouver coincé dans des
   problèmes de recherche de grosses jointures en ne regroupant pas une
   sous-requête sur plus de <varname>from_collapse_limit</varname>
   éléments sont la résultante de la requête parent. Vous
   pouvez comparer le temps de planification avec la qualité du plan en
   ajustant ce paramètre en exécution.
  </para>

  <para>
   <xref linkend="guc-from-collapse-limit"/> et <xref
   linkend="guc-join-collapse-limit"/> sont
   nommés de façon similaire parce qu'ils font pratiquement la même chose&nbsp;:
   l'un d'eux contrôle le moment où le planificateur <quote>aplatira</quote> les
   sous-requêtes et l'autre contrôle s'il y a aplatissement des jointures
   explicites. Typiquement, vous initialiserez 
   <varname>join_collapse_limit</varname> comme <varname>from_collapse_limit</varname> (de
   façon à ce que les jointures explicites et les sous-requêtes agissent de la
   même façon) ou vous initialiserez <varname>join_collapse_limit</varname> à 1 (si
   vous voulez contrôler l'ordre de jointure des jointures explicites). Mais
   vous pourriez les initialiser différemment si vous tentez de configurer
   finement la relation entre le temps de planification et le temps
   d'exécution.
  </para>
 </sect1>

 <sect1 id="populate">
  <title>Remplir une base de données</title>

  <para>
   Vous pourriez avoir besoin d'insérer un grand nombre de données pour
   remplir une base de données au tout début. Cette section contient quelques
   suggestions pour réaliser cela de la façon la plus efficace.
  </para>

  <sect2 id="disable-autocommit">
   <title>Désactivez la validation automatique (autocommit)</title>

   <indexterm>
    <primary>autocommit</primary>
    <secondary>gros chargement de données</secondary>
   </indexterm>

   <para>
    Lors d'<command>INSERT</command> multiples, désactivez la validation automatique et faites
    une seule validation à la
    fin (en SQL, ceci signifie de lancer <command>BEGIN</command> au début et
   <command>COMMIT</command> à la fin. Quelques bibliothèques client pourraient
   le faire derrière votre dos auquel cas vous devez vous assurer que la
   bibliothèque le fait quand vous le voulez). Si vous permettez à chaque
   insertion d'être validée séparément, <productname>PostgreSQL</productname>
   fait un gros travail pour chaque ligne ajoutée. Un bénéfice supplémentaire de
   réaliser toutes les insertions dans une seule transaction est que si l'insertion
   d'une ligne échoue alors les lignes insérées jusqu'à maintenant seront
   annulées. Vous ne serez donc pas bloqué avec des données partiellement
   chargées.
   </para>
  </sect2>

  <sect2 id="populate-copy-from">
   <title>Utilisez <command>COPY</command></title>

   <para>
    Utilisez <xref linkend="sql-copy"/> pour charger
    toutes les lignes en une seule commande, plutôt que d'utiliser une série
    de commandes <command>INSERT</command>. La commande <command>COPY</command>
    est optimisée pour charger un grand nombre de lignes&nbsp;; elle est moins
    flexible que <command>INSERT</command> mais introduit significativement moins
    de surcharge lors du chargement de grosses quantités de données. Comme
    <command>COPY</command> est une seule commande, il n'y a pas besoin de
    désactiver la validation automatique (autocommit) si vous utilisez cette
    méthode pour remplir une table.
   </para>

   <para>
    Si vous ne pouvez pas utiliser <command>COPY</command>, utiliser <xref
    linkend="sql-prepare"/> pourrait vous aider à
    créer une instruction préparée <command>INSERT</command>, puis utilisez
    <command>EXECUTE</command> autant de fois que nécessaire. Ceci évite
    certaines surcharges lors d'une analyse et d'une planification répétées
    de commandes <command>INSERT</command>. Différentes interfaces fournissent
    cette fonctionnalité de plusieurs façons&nbsp;; recherchez
    <quote>instructions préparées</quote> dans la documentation de l'interface.
   </para>

   <para>
    Notez que charger un grand nombre de lignes en utilisant
    <command>COPY</command> est pratiquement toujours plus rapide que d'utiliser
    <command>INSERT</command>, même si <command>PREPARE ... INSERT</command> est utilisé lorsque
    de nombreuses insertions sont groupées en une seule transaction.
   </para>

   <para>
    <command>COPY</command> est plus rapide quand il est utilisé dans la même
    transaction que la commande <command>CREATE TABLE</command> ou
    <command>TRUNCATE</command> précédente. Dans ce cas, les journaux de
    transactions ne sont pas impactés car, en cas d'erreur, les fichiers
    contenant les données nouvellement chargées seront supprimés de toute
    façon. Néanmoins, cette considération ne s'applique que quand
    <xref linkend="guc-wal-level"/> vaut <literal>minimal</literal>, car toutes les
    commandes doivent écrire dans les journaux de transaction dans ce cas.
   </para>

  </sect2>

  <sect2 id="populate-rm-indexes">
   <title>Supprimez les index</title>

   <para>
    Si vous chargez une table tout juste créée, la méthode la plus rapide est de
    créer la table, de charger en lot les données de cette table en utilisant
    <command>COPY</command>, puis de créer tous les index nécessaires pour la
    table. Créer un index sur des données déjà existantes est plus rapide que de
    mettre à jour de façon incrémentale à chaque ligne ajoutée.
   </para>

   <para>
    Si vous ajoutez beaucoup de données à une table existante, il pourrait être
    avantageux de supprimer les index, de charger la table, puis de recréer les
    index.
    Bien sûr, les performances de la base de données pour les autres utilisateurs
    pourraient souffrir tout le temps où les index seront manquant. Vous devez aussi
    y penser à deux fois avant de supprimer des index uniques car la vérification
    d'erreur apportée par la contrainte unique sera perdue tout le temps où
    l'index est manquant.
   </para>
  </sect2>

  <sect2 id="populate-rm-fkeys">
   <title>Suppression des contraintes de clés étrangères</title>

   <para>
    Comme avec les index, une contrainte de clé étrangère peut être vérifiée
    <quote>en gros volume</quote> plus efficacement que ligne par ligne.
    Donc, il pourrait être utile de supprimer les contraintes de clés
    étrangères, de charger les données et de créer de nouveau les contraintes.
    De nouveau, il y a un compromis entre la vitesse de chargement des données
    et la perte de la vérification des erreurs lorsque la contrainte manque.
   </para>

   <para>
    De plus, quand vous chargez des données dans une table contenant des
	contraintes de clés étrangères, chaque nouvelle ligne requiert une
	entrée dans la liste des évènements de déclencheur en attente
	(puisque c'est le lancement d'un déclencheur qui vérifie la contrainte
	de clé étrangère de la ligne). Le chargement de plusieurs millions de lignes
	peut amener la taille de la file d'attente des déclencheurs à dépasser
	la mémoire disponible, causant ainsi une mise en mémoire swap intolérable,
	voire même l'échec de la commande. Dans ce cas, il peut être
	<emphasis>nécessaire</emphasis>, pas seulement souhaitable, de supprimer
	et recréer la clé étrangère lors de chargements de grandes quantités de
	données. Si la suppression temporaire de la contrainte n'est pas acceptable,
	le seul recours possible est de découper les opérations de chargement
	en de plus petites transactions.
   </para>
  </sect2>

  <sect2 id="populate-work-mem">
   <title>Augmentez <varname>maintenance_work_mem</varname></title>

   <para>
    Augmentez temporairement la variable <xref linkend="guc-maintenance-work-mem"/>
    lors du chargement de grosses quantités de données peut amener une
    amélioration des performances. Ceci aidera à l'accélération des commandes
    <command>CREATE INDEX</command> et <command>ALTER TABLE ADD FOREIGN KEY</command>. Cela
    ne changera pas grand chose pour la commande <command>COPY</command>. Donc, ce
    conseil est seulement utile quand vous utilisez une des deux ou les deux
    techniques ci-dessus.
   </para>
  </sect2>

  <sect2 id="populate-checkpoint-segments">
   <title>Augmentez <varname>checkpoint_segments</varname></title>

   <para>
    Augmenter temporairement la variable de configuration <xref
    linkend="guc-checkpoint-segments"/> peut aussi aider à un chargement
    rapide de grosses quantités de données. Ceci est dû au fait que charger
    une grosse quantité de données dans <productname>PostgreSQL</productname>
    causera la venue trop fréquente de points de vérification (la
    fréquence de ces points de vérification est spécifiée par la variable de
    configuration <varname>checkpoint_timeout</varname>). Quand survient un
    point de vérification, toutes les pages modifiées sont écrites sur le
    disque. En augmentant <varname>checkpoint_segments</varname> temporairement
    lors du chargement des données, le nombre de points de vérification requis
    peut être diminué.
   </para>
  </sect2>

  <sect2 id="populate-pitr">
   <title>Désactiver l'archivage des journaux de transactions et la
     réplication en flux</title>

   <para>
    Lors du chargement de grosse quantité de données dans une instance qui
    utilise l'archivage des journaux de transactions ou la réplication en
    flux, il pourrait être plus rapide de prendre une nouvelle sauvegarde de
    base après que le chargement ait terminé, plutôt que de traiter une grosse
    quantité de données incrémentales dans les journaux de transactions. Pour
    empêcher un accroissement de la journalisation des transactions lors du
    chargement, vous
    pouvez désactiver l'archivage et la réplication en flux lors du chargement
    en configurant <xref linkend="guc-wal-level"/> à <literal>minimal</literal>,
    <xref linkend="guc-archive-mode"/> à <literal>off</literal> et
    <xref linkend="guc-max-wal-senders"/> à zéro). Mais notez que le changement
    de ces paramètres requiert un redémarrage du serveur.
   </para>

   <para>
    En dehors d'éviter le temps de traitement des données des journaux de
    transactions par l'archiveur ou l'émetteur des journaux de transactions,
    le faire rendrait certaines commandes plus rapides parce qu'elles sont
    conçues pour ne pas écrire du tout dans les journaux de transactions si
    <varname>wal_level</varname> vaut <literal>minimal</literal>. (Elles
    peuvent garantir la sûreté des données de façon moins coûteuse en exécutant
    un <function>fsync</function> à la fin plutôt qu'en écrivant les journaux
    de transactions&nbsp;:
    <itemizedlist>
     <listitem>
      <para>
       <command>CREATE TABLE AS SELECT</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>CREATE INDEX</command> (et les variantes telles que
       <command>ALTER TABLE ADD PRIMARY KEY</command>)
      </para>
     </listitem>
     <listitem>
      <para>
       <command>ALTER TABLE SET TABLESPACE</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>CLUSTER</command>
      </para>
     </listitem>
     <listitem>
      <para>
       <command>COPY FROM</command>, quand la table cible vient d'être créée
       ou vidée auparavant dans la transaction
      </para>
     </listitem>
    </itemizedlist>
   </para>
  </sect2>

  <sect2 id="populate-analyze">
   <title>Lancez <command>ANALYZE</command> après</title>

   <para>
     Quand vous avez changé significativement la distribution des données à
     l'intérieur d'une table, lancer <xref linkend="sql-analyze"/> est fortement
     recommandée. Ceci inclut le
     chargement de grosses quantités de données dans la table. Lancer
     <command>ANALYZE</command> (ou <command>VACUUM ANALYZE</command>) vous
     assure que le planificateur dispose de statistiques à jour sur la table.
     Sans statistiques ou avec des statistiques obsolètes, le planificateur
     pourrait prendre de mauvaises décisions lors de la planification de la
     requête, amenant des performances pauvres sur toutes les tables sans
     statistiques ou avec des statistiques inexactes. Notez que si le démon
     autovacuum est désactivée, il pourrait exécuter <command>ANALYZE</command>
     automatiquement&nbsp;; voir <xref linkend="vacuum-for-statistics"/> et
     <xref linkend="autovacuum"/> pour plus d'informations.
   </para>
  </sect2>

  <sect2 id="populate-pg-dump">
   <title>Quelques notes sur <application>pg_dump</application></title>

   <para>
    Les scripts de sauvegarde générés par <application>pg_dump</application> appliquent
    automatiquement plusieurs des indications ci-dessus, mais pas toutes. Pour
    recharger une sauvegarde <application>pg_dump</application> aussi rapidement que
    possible, vous avez besoin de faire quelques étapes supplémentaires
    manuellement (notez que ces points s'appliquent lors de la
    <emphasis>restauration</emphasis> d'une sauvegarde, et non pas lors de sa
    <emphasis>création</emphasis>. Les mêmes points s'appliquent soit lors de
    la restauration d'une sauvegarde texte avec <application>psql</application> soit lors
    de l'utilisation
    de <application>pg_restore</application> pour charger un fichier de sauvegarde
    <application>pg_dump</application>).
   </para>

   <para>
    Par défaut, <application>pg_dump</application> utilise
    <command>COPY</command> et, lorsqu'il génère une sauvegarde complexe,
    schéma et données, il est préférable de charger les données avant de créer
    les index et les clés étrangères. Donc, dans ce cas, plusieurs lignes de
    conduite sont gérées automatiquement. Ce qui vous reste à faire est
    de&nbsp;:
    <itemizedlist>
     <listitem>
      <para>
       Configurez des valeurs appropriées (c'est-à-dire plus importante que la
       normale) pour <varname>maintenance_work_mem</varname> et
       <varname>checkpoint_segments</varname>.
      </para>
     </listitem>
     <listitem>
      <para>
       Si vous utilisez l'archivage des journaux de transactions ou la
       réplication en flux, considérez leur désactivation lors de la
       restauration. Pour faire cela, configurez
       <varname>archive_mode</varname> à <literal>off</literal>, <varname>wal_level</varname> à
       <literal>minimal</literal> et <varname>max_wal_senders</varname> à zéro
       avant de charger le script de sauvegarde. Après coup, remettez les
       anciennes valeurs et effectuez une nouvelle sauvegarde de base.
      </para>
     </listitem>
     <listitem>
      <para>
       Demandez-vous si la sauvegarde complète doit être restaurée dans une
       seule transaction. Pour cela, passez l'option <option>-1</option> ou
       <option>--single-transaction</option> à
       <application>psql</application> pi <application>pg_restore</application>.
       Lors de l'utilisation de ce mode, même les erreurs les plus petites
       annuleront la restauration complète, peut-être en annulant des heures de
       traitement. Suivant à quel point les données sont en relation, il peut
       être préférable de faire un nettoyage manuel. Les commandes
       <command>COPY</command> s'exécuteront plus rapidement si vous utilisez une
       transaction simple et que vous avez désactivé l'archivage des journaux de
       transaction.
      </para>
     </listitem>
     <listitem>
      <para>
       Si plusieurs processeurs sont disponibles sur le serveur, pensez à
       utiliser l'option <option>--jobs</option> de
       <application>pg_restore</application>. Cela permet la parallélisation
       du chargement des données et de la création des index.
      </para>
     </listitem>
     <listitem>
      <para>
       Exécutez <command>ANALYZE</command> après coup.
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
    Une sauvegarde des données seules utilise toujours <command>COPY</command> mais
    elle ne supprime ni ne recrée les index et elle ne touche généralement pas
    les clés étrangères.

     <footnote>
      <para>
       Vous pouvez obtenir l'effet de désactivation des clés étrangères en
       utilisant l'option <option>--disable-triggers</option> &mdash; mais réalisez
       que cela élimine, plutôt que repousse, la validation des clés étrangères
       et qu'il est du coup possible d'insérer des données mauvaises si vous
       l'utilisez.
      </para>
     </footnote>

    Donc, lorsque vous chargez une sauvegarde ne contenant que les données,
    c'est à vous de supprimer et recréer les index et clés étrangères si vous
    souhaitez utiliser ces techniques. Il est toujours utile d'augmenter
    <varname>checkpoint_segments</varname> lors du chargement des données
    mais ne vous embêtez pas à augmenter
    <varname>maintenance_work_mem</varname>&nbsp;; en fait, vous le ferez lors
    d'une nouvelle création manuelle des index et des clés étrangères. Et
    n'oubliez pas <command>ANALYZE</command> une fois que vous avez terminé&nbsp;;
    voir <xref linkend="vacuum-for-statistics"/> et <xref linkend="autovacuum"/>
    pour plus d'informations.
   </para>
  </sect2>
 </sect1>

  <sect1 id="non-durability">
   <title>Configuration avec une perte acceptée</title>

   <indexterm zone="non-durability">
    <primary>perte acceptée</primary>
   </indexterm>

   <para>
    La durabilité est une fonctionnalité des serveurs de bases de données
    permettant de garantir l'enregistrement des transactions validées même si
    le serveur s'arrête brutalement, par exemple en cas de coupure électrique.
    Néanmoins, la durabilité ajoute une surcharge significative. Si votre
    base de données n'a pas besoin de cette ganratie,
    <productname>PostgreSQL</productname> peut être configuré pour fonctionner
    bien plus rapidement. Voici des modifications de configuration que vous
    pouvez faire pour améliorer les performances dans ce cas. Sauf indication
    contraire, la durabilité des transactions est garantie dans le cas d'un
    crash du serveur de bases de données&nbsp;; seul un arrêt brutal du
    système d'exploitation crée un risque de perte de données ou de
    corruption quand ses paramètres sont utilisés.

    <itemizedlist>
     <listitem>
      <para>
       Placer le répertoire des données dans un système de fichiers en
       mémoire (par exemple un disque <acronym>RAM</acronym>). Ceci élimine
       toutes les entrées/sorties disque de la base de données. Cela limite
       aussi la quantité de mémoire disponible (et peut-être aussi du swap).
      </para>
     </listitem>

     <listitem>
      <para>
       Désactiver <xref linkend="guc-fsync"/>&nbsp;; il n'est pas nécessaire
       d'écrire les données sur disque.
      </para>
     </listitem>

     <listitem>
      <para>
       Désactiver <xref linkend="guc-full-page-writes"/>&nbsp;; il n'est pas
       nécessaire de se prémunir contre les écritures de pages partielles.
      </para>
     </listitem>

     <listitem>
      <para>
       Augmenter <xref linkend="guc-checkpoint-segments"/> et <xref
       linkend="guc-checkpoint-timeout"/>&nbsp;; cela réduit les fréquences
       des CHECKPOINT mais augmente l'espace disque nécessaire dans
       <filename>pg_xlog</filename>.
      </para>
     </listitem>

     <listitem>
      <para>
       Désactiver <xref linkend="guc-synchronous-commit"/>&nbsp;; il n'est
       pas forcément nécessaire d'écrire les journaux de transactions
       (<acronym>WAL</acronym>) à chaque validation de transactions. Ce
       paramètre engendre un risque de perte de transactions (mais pas de
       corruption de données) dans le cas d'un crash de la
       <emphasis>base de données</emphasis> seule.
      </para>
     </listitem>
    </itemizedlist>
   </para>
  </sect1>
</chapter>
