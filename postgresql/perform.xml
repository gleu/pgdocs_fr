<?xml version="1.0" encoding="UTF-8"?>
<chapter id="performance-tips">
 <title>Conseils sur les performances</title>

 <indexterm zone="performance-tips">
  <primary>performance</primary>
 </indexterm>

 <para>
  La performance des requêtes peut être affectée par un grand nombre
  d'éléments. Certains peuvent être contrôlés par l'utilisateur, d'autres
  sont fondamentaux au concept sous-jacent du système. Ce chapitre fournit
  des conseils sur la compréhension et sur la configuration fine des
  performances de <productname>PostgreSQL</productname>.
 </para>

 <sect1 id="using-explain">
  <title>Utiliser <command>EXPLAIN</command></title>

  <indexterm zone="using-explain">
   <primary>EXPLAIN</primary>
  </indexterm>

  <indexterm zone="using-explain">
   <primary>plan de requête</primary>
  </indexterm>

  <para>
   <productname>PostgreSQL</productname> réalise un <firstterm>plan de
   requête</firstterm> pour chaque requête qu'il reçoit. Choisir le bon plan
   correspondant à la structure de la requête et aux propriétés des données
   est absolument critique pour de bonnes performances, donc le système
   inclut un <firstterm>planificateur</firstterm> ou
   <firstterm>optimiseur</firstterm> complexe qui tente de choisir les bons
   plans. Vous pouvez utiliser la commande <link
   linkend="sql-explain"><command>EXPLAIN</command></link> pour voir quel
   plan de requête le planificateur crée pour une requête particulière. La
   lecture du plan est un art qui requiert de l'expérience pour le maîtriser,
   mais cette section essaie de couvrir les bases.
  </para>

  <para>
   Les exemples dans cette section sont tirés de la base de données pour les
   tests de régression après avoir effectué un <command>VACUUM
   ANALYZE</command>, avec les sources de la version de développement 9.3.
   Vous devriez obtenir des résultats similaires si vous essayez les exemples
   vous-même, mais vos estimations de coût et de nombre de lignes pourraient
   légèrement varier parce que les statistiques d'<command>ANALYZE</command>
   sont basées sur des échantillons aléatoires, et parce que les coûts sont
   dépendants de la plateforme utilisée.
  </para>

  <para>
   Les exemples utilisent le format de sortie par défaut
   (<quote>text</quote>) d'<command>EXPLAIN</command>, qui est compact et
   pratique pour la lecture. Si vous voulez utiliser la sortie
   d'<command>EXPLAIN</command> avec un programme pour une analyse
   ultérieure, vous devriez utiliser un des formats de sortie au format
   machine (XML, JSON ou YAML) à la place.
  </para>

  <sect2 id="using-explain-basics">
   <title>Concepts d'<command>EXPLAIN</command></title>

   <para>
    La structure d'un plan de requête est un arbre de <firstterm>nœuds
    de plan</firstterm>. Les nœuds de bas niveau sont les nœuds
    de parcours&nbsp;: ils renvoient les lignes brutes d'une table. Il existe
    différents types de nœuds de parcours pour les différentes méthodes
    d'accès aux tables&nbsp;: parcours séquentiel, parcours d'index et
    parcours d'index bitmap. Il y a également des ensembles de lignes qui ne
    proviennent pas de tables, avec par exemple des clauses
    <literal>VALUES</literal> ainsi que des fonctions renvoyant des ensembles
    dans un <literal>FROM</literal>, qui ont leurs propres types de
    nœuds de parcours. Si la requête requiert des jointures,
    agrégations, tris ou d'autres opérations sur les lignes brutes, ce seront
    des nœuds supplémentaires au-dessus des nœuds de parcours
    pour réaliser ces opérations. Encore une fois, il existe plus d'une façon
    de réaliser ces opérations, donc différents types de nœuds peuvent
    aussi apparaître ici. La sortie d'<command>EXPLAIN</command> comprend une
    ligne pour chaque nœud dans l'arbre du plan, montrant le type de
    nœud basique avec les estimations de coût que le planificateur a
    faites pour l'exécution de ce nœud du plan. Des lignes
    supplémentaires peuvent apparaître, indentées par rapport à la ligne de
    résumé du nœud, pour montrer les propriétés supplémentaires du
    nœud. La première ligne (le nœud tout en haut) comprend le
    coût d'exécution total estimé pour le plan&nbsp;; c'est ce nombre que le
    planificateur cherche à minimiser.
   </para>

   <para>
    Voici un exemple trivial, juste pour montrer à quoi ressemble
    l'affichage.

    <screen>EXPLAIN SELECT * FROM tenk1;

                         QUERY PLAN
-------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)</screen>
   </para>

   <para>
    Puisque la requête n'a pas de clause <literal>WHERE</literal>, il faut
    parcourir toutes les lignes de la table, c'est pourquoi le planificateur
    a choisi d'utiliser un plan avec un simple parcours séquentiel. Les
    nombres affichés entre parenthèses sont (de gauche à droite)&nbsp;:

    <itemizedlist>
     <listitem>
      <para>
       Coût estimé du lancement. Cela correspond au temps passé avant que
       l'affichage de la sortie ne commence, par exemple le temps de faire un
       tri dans un nœud de tri&nbsp;;
      </para>
     </listitem>

     <listitem>
      <para>
       Coût total estimé. Cela suppose que le nœud du plan d'exécution est
       exécuté entièrement, c'est-à-dire que toutes les lignes disponibles
       sont récupérées. En pratique, un nœud parent peut arrêter la
       récupération de toutes les lignes disponibles avant la fin
       (voir l'exemple <literal>LIMIT</literal> ci-dessous)&nbsp;;
      </para>
     </listitem>

     <listitem>
      <para>
       Nombre de lignes estimé en sortie par ce nœud de plan. Encore une fois,
       on suppose que le nœud est exécuté entièrement.
      </para>
     </listitem>

     <listitem>
      <para>
       Largeur moyenne estimée (en octets) des lignes en sortie par ce nœud du
       plan.
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
    Les coûts sont mesurés en unités arbitraires déterminées par les
    paramètres de coût du planificateur (voir <xref
    linkend="runtime-config-query-constants"/>). La pratique habituelle est
    de mesurer les coûts en unité de récupération de pages disque&nbsp;;
    autrement dit, <xref linkend="guc-seq-page-cost"/> est initialisé à
    <literal>1.0</literal> par convention et les autres paramètres de coût
    sont relatifs à cette valeur. Les exemples de cette section sont exécutés
    avec les paramètres de coût par défaut.
   </para>

   <para>
    Il est important de comprendre que le coût d'un nœud de haut niveau inclut
    le coût de tous les nœuds fils. Il est aussi important de réaliser que le
    coût reflète seulement les éléments d'importance pour le planificateur.
    En particulier, le coût ne considère pas le temps dépensé dans la
    transmission des lignes de résultat au client, ce qui pourrait être un
    facteur important dans le temps réel passé&nbsp;; mais le planificateur
    l'ignore parce qu'il ne peut pas le changer en modifiant le plan
    (chaque plan correct sortira le même ensemble de lignes).
   </para>

   <para>
    La valeur <literal>rows</literal> est un peu difficile car il ne s'agit
    pas du nombre de lignes traitées ou parcourues par le plan de nœuds, mais
    plutôt le nombre émis par le nœud. C'est habituellement moins, reflétant
    la sélectivité estimée des conditions de la clause
    <literal>WHERE</literal> qui sont appliquées au nœud. Idéalement, les
    estimations des lignes de haut niveau seront une approximation des
    nombres de lignes déjà renvoyées, mises à jour, supprimées par la
    requête.
   </para>

   <para>
    Quand un <command>UPDATE</command> ou un <command>DELETE</command> affecte
    une hiérarchie d'héritage, la sortie pourrait ressembler à ceci&nbsp;:

    <screen>EXPLAIN UPDATE parent SET f2 = f2 + 1 WHERE f1 = 101;

                                              QUERY PLAN
-------------------------------------------------------------------&zwsp;-----------------------------------
 Update on parent  (cost=0.00..24.59 rows=0 width=0)
   Update on parent parent_1
   Update on child1 parent_2
   Update on child2 parent_3
   Update on child3 parent_4
   -&gt;  Result  (cost=0.00..24.59 rows=4 width=14)
         -&gt;  Append  (cost=0.00..24.54 rows=4 width=14)
               -&gt;  Seq Scan on parent parent_1  (cost=0.00..0.00 rows=1 width=14)
                     Filter: (f1 = 101)
               -&gt;  Index Scan using child1_pkey on child1 parent_2  (cost=0.15..8.17 rows=1 width=14)
                     Index Cond: (f1 = 101)
               -&gt;  Index Scan using child2_pkey on child2 parent_3  (cost=0.15..8.17 rows=1 width=14)
                     Index Cond: (f1 = 101)
               -&gt;  Index Scan using child3_pkey on child3 parent_4  (cost=0.15..8.17 rows=1 width=14)
                     Index Cond: (f1 = 101)</screen>

    Dans cet exemple, le nœud Update doit prendre en compte les trois tables
    filles ainsi que la table parente mentionnée dans la requête. Donc il y a
    quatre sous-plans de parcours en entrée, un par table. Pour plus de
    clarté, le nœud Update est annoté pour afficher les tables cibles
    spécifiques à mettre à jour, dans le même ordre que les sous-plans
    correspondants.
   </para>

   <para>
    Le <literal>Temps de planification (Planning time)</literal> affiché est
    le temps qu'il a fallu pour générer le plan d'exécution de la requête
    analysée et pour l'optimiser. Cela n'inclut ni le temps de réécriture ni
    le temps d'analyse.
   </para>

   <para>
    Pour revenir à notre exemple&nbsp;:

    <screen>EXPLAIN SELECT * FROM tenk1;

                         QUERY PLAN
-------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)</screen>
   </para>

   <para>
    Ces nombres sont directement dérivés. Si vous faites&nbsp;:

    <screen>SELECT relpages, reltuples FROM pg_class WHERE relname = 'tenk1';</screen>

    vous trouverez que <classname>tenk1</classname> a 358 blocs disque et
    10000 lignes. Le coût estimé est calculé avec (nombre de blocs lus *
    <xref linkend="guc-seq-page-cost"/>) + (lignes parcourues * <xref
    linkend="guc-cpu-tuple-cost"/>). Par défaut,
    <varname>seq_page_cost</varname> vaut 1,0 et
    <varname>cpu_tuple_cost</varname> vaut 0,01. Donc le coût estimé est de
    (358 * 1,0) + (10000 * 0,01), soit 458.
   </para>

   <para>
    Maintenant, modifions la requête originale pour ajouter une condition
    <literal>WHERE</literal>&nbsp;:

    <screen>EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 7000;

                         QUERY PLAN
------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..483.00 rows=7001 width=244)
   Filter: (unique1 &lt; 7000)</screen>

    Notez que l'affichage d'<command>EXPLAIN</command> montre la clause
    <literal>WHERE</literal> appliquée comme une condition de
    <quote>filtre</quote> rattachée au nœud de parcours séquentiel&nbsp;;
    ceci signifie que le nœud de plan vérifie la condition pour chaque ligne
    qu'il parcourt et ne conserve que celles qui satisfont la condition.
    L'estimation des lignes en sortie a baissé à cause de la clause
    <literal>WHERE</literal>. Néanmoins, le parcours devra toujours visiter
    les 10000 lignes, donc le coût n'a pas baissé&nbsp;; en fait, il a un peu
    augmenté(par 10000 * <xref linkend="guc-cpu-operator-cost"/> pour être
    exact) dans le but de refléter le temps CPU supplémentaire dépensé pour
    vérifier la condition <literal>WHERE</literal>.
   </para>

   <para>
    Le nombre réel de lignes que cette requête sélectionnera est 7000, mais
    l'estimation <literal>rows</literal> est approximative. Si vous tentez de
    dupliquer cette expérience, vous obtiendrez probablement une estimation
    légèrement différente&nbsp;; de plus, elle changera après chaque commande
    <command>ANALYZE</command> parce que les statistiques produites par
    <command>ANALYZE</command> sont prises à partir d'un extrait au hasard de
    la table.
   </para>

   <para>
    Maintenant, rendons la condition plus restrictive&nbsp;:

    <screen>EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100;

                                  QUERY PLAN
------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=5.07..229.20 rows=101 width=244)
   Recheck Cond: (unique1 &lt; 100)
   ->  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.04 rows=101 width=0)
         Index Cond: (unique1 &lt; 100)</screen>

    Ici, le planificateur a décidé d'utiliser un plan en deux étapes&nbsp;: le
    nœud en bas du plan visite un index pour trouver l'emplacement des lignes
    correspondant à la condition de l'index, puis le nœud du plan du dessus
    récupère réellement ces lignes de la table. Récupérer séparément les
    lignes est bien plus coûteux que de les lire séquentiellement, mais comme
    toutes les pages de la table n'ont pas à être visitées, cela revient
    toujours moins cher qu'un parcours séquentiel (la raison de l'utilisation
    d'un plan à deux niveaux est que le nœud du plan du dessus trie les
    emplacements des lignes identifiées par l'index dans l'ordre physique
    avant de les lire pour minimiser les coûts des récupérations séparées. Le
    <quote>bitmap</quote> mentionné dans les noms de nœuds est le mécanisme
    qui s'occupe du tri).
   </para>

   <para>
    Maintenant, ajoutons une autre condition à la clause
    <literal>WHERE</literal>&nbsp;:

    <screen>EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND stringu1 = 'xxx';

                                  QUERY PLAN
------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=5.04..229.43 rows=1 width=244)
   Recheck Cond: (unique1 &lt; 100)
   Filter: (stringu1 = 'xxx'::name)
   -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.04 rows=101 width=0)
         Index Cond: (unique1 &lt; 100)</screen>

    L'ajout de la condition <literal>stringu1 = 'xxx'</literal> réduit
    l'estimation du nombre de lignes renvoyées, mais pas son coût, car il
    faut toujours parcourir le même ensemble de lignes. Notez que la clause
    <literal>stringu1</literal> ne peut être appliquée comme une condition
    d'index car l'index ne porte que sur la colonne
    <literal>unique1</literal>. À la place, un filtre a été appliqué sur les
    lignes récupérées par l'index. C'est pourquoi le coût a légèrement
    augmenté pour refléter la vérification supplémentaire.
   </para>

   <para>

    Dans certains cas, le planificateur préfèrera un plan
    <quote>simple</quote> d'index&nbsp;:

    <screen>EXPLAIN SELECT * FROM tenk1 WHERE unique1 = 42;

                                 QUERY PLAN
-----------------------------------------------------------------------------
 Index Scan using tenk1_unique1 on tenk1  (cost=0.29..8.30 rows=1 width=244)
   Index Cond: (unique1 = 42)</screen>

    Dans ce type de plan, les lignes de la table sont récupérées dans l'ordre
    de l'index, ce qui les rend encore plus coûteuses à récupérer, mais il y
    en a tellement peu que le coût supplémentaire pour trier l'ordre des
    lignes n'est pas rentable. Vous verrez principalement ce type de plan
    pour les requêtes qui ne récupèrent qu'une seule ligne, ou pour les
    requêtes qui ont une condition <literal>ORDER BY</literal> qui correspond
    à l'ordre de l'index, car cela ne nécessite aucune étape supplémentaire
    pour satisfaire l'<literal>ORDER BY</literal>. Dans cet exemple, ajouter
    <literal>ORDER BY unique1</literal> ferait que l'optimiseur utilise le
    même plan parce que l'index fournit déjà implicitement le tri requis.
   </para>

   <para>
    L'optimiseur peut exécuter une clause <literal>ORDER BY</literal> de
    plusieurs façons. L'exemple ci-dessus montre qu'une clause de tri peut
    être effectué implicitement. L'optimiseur peut aussi ajouter une étape de
    tri (<literal>sort</literal>) explicite&nbsp;:

    <screen>EXPLAIN SELECT * FROM tenk1 ORDER BY unique1;
                            QUERY PLAN
-------------------------------------------------------------------
 Sort  (cost=1109.39..1134.39 rows=10000 width=244)
   Sort Key: unique1
   ->  Seq Scan on tenk1  (cost=0.00..445.00 rows=10000 width=244)</screen>

    Si une partie du plan garantit un ordre sur un préfixe des clés de tri
    requises, alors l'optimiseur peut décider à la place d'utiliser une étape
    de tri incrémental (<literal>incremental sort</literal>)&nbsp;:

    <screen>EXPLAIN SELECT * FROM tenk1 ORDER BY four, ten LIMIT 100;
                                              QUERY PLAN
-------------------------------------------------------------------&zwsp;-----------------------------------
 Limit  (cost=521.06..538.05 rows=100 width=244)
   ->  Incremental Sort  (cost=521.06..2220.95 rows=10000 width=244)
         Sort Key: four, ten
         Presorted Key: four
         ->  Index Scan using index_tenk1_on_four on tenk1  (cost=0.29..1510.08 rows=10000 width=244)</screen>

    Comparé aux tris habituels, le tri incrémental permet de renvoyer les
    lignes avant que l'ensemble du résultat ne soit trié, ce qui permet en
    particulier des optimisations avec les requêtes utilisant la clause
    <literal>LIMIT</literal>. Il peut aussi réduire l'utilisation de la
    mémoire et la probabilité d'envoyer des tris sur disque, mais cela a un
    coût&nbsp;: une surcharge pour répartir l'ensemble de lignes résultats
    dans plusieurs groupes de tri.
   </para>

   <para>
    S'il y a des index sur plusieurs colonnes référencées dans la clause
    <literal>WHERE</literal>, le planificateur pourrait choisir d'utiliser
    une combinaison binaire (AND et OR) des index&nbsp;:

    <screen>EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;

                                      QUERY PLAN
 -------------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=25.08..60.21 rows=10 width=244)
    Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
   -&gt;  BitmapAnd  (cost=25.08..25.08 rows=10 width=0)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.04 rows=101 width=0)
                Index Cond: (unique1 &lt; 100)
         -&gt;  Bitmap Index Scan on tenk1_unique2  (cost=0.00..19.78 rows=999 width=0)
                Index Cond: (unique2 &gt; 9000)</screen>

    Mais ceci requiert de visiter plusieurs index, donc ce n'est pas
    nécessairement un gain comparé à l'utilisation d'un seul index et au
    traitement de l'autre condition par un filtre. Si vous variez les
    échelles de valeurs impliquées, vous vous apercevrez que le plan change
    en accord.
   </para>

   <para>
    Voici un exemple montrant les effets d'un <literal>LIMIT</literal>&nbsp;:

    <screen>EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000 LIMIT 2;

                                     QUERY PLAN
-------------------------------------------------------------------------------------
 Limit  (cost=0.29..14.48 rows=2 width=244)
   -&gt;  Index Scan using tenk1_unique2 on tenk1  (cost=0.29..71.27 rows=10 width=244)
         Index Cond: (unique2 &gt; 9000)
         Filter: (unique1 &lt; 100)</screen>
   </para>

   <para>
    C'est la même requête qu'au-dessus, mais avec l'ajout de
    <literal>LIMIT</literal>, ce qui fait que toutes les lignes ne seront pas
    récupérées, et donc que le planificateur change sa façon de procéder.
    Notez que le coût total ainsi que le nombre de lignes du nœud de parcours
    d'index sont affichés comme si le nœud devait être exécuté entièrement.
    Cependant, le nœud Limit s'attend à s'arrêter après avoir récupéré
    seulement un cinquième de ces lignes, c'est pourquoi son coût total n'est
    qu'un cinquième du coût précédent, ce qui est le vrai coût estimé de la
    requête. Ce plan est préférable à l'ajout d'un nœud Limit au plan
    précédent, car le Limit ne pourrait pas empêcher le coût de départ du
    parcours d'index Bitmap, ce qui augmenterait le coût d'environ 25 unités
    avec cette approche.
   </para>

   <para>
    Maintenant, essayons de joindre deux tables, en utilisant les colonnes
    dont nous avons discuté&nbsp;:

<screen>EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2;

                                       QUERY PLAN
 --------------------------------------------------------------------------------------
 Nested Loop  (cost=4.65..118.62 rows=10 width=488)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=4.36..39.47 rows=10 width=244)
         Recheck Cond: (unique1 &lt; 10)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..4.36 rows=10 width=0)
               Index Cond: (unique1 &lt; 10)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.29..7.91 rows=1 width=244)
          Index Cond: (unique2 = t1.unique2)</screen>
   </para>

   <para>
    Dans ce plan, nous avons un nœud de jointure en boucle imbriquée sur deux
    parcours de tables en entrée. L'indentation des lignes de sommaire des
    nœuds reflète la structure en arbre du plan. Le premier nœud, ou nœud
    <quote>externe</quote>, utilise le même parcours de bitmap que celui vu
    précédemment, et donc ses coût et nombre de lignes sont les mêmes que ce
    que l'on aurait obtenu avec <literal>SELECT ... WHERE unique1 &lt;
    10</literal>, car la même clause <literal>WHERE</literal>
    <literal>unique1 &lt; 10</literal> est appliquée à ce nœud. La clause
    <literal>t1.unique2 = t2.unique2</literal> n'a pas encore d'intérêt, elle
    n'affecte donc pas le nombre de lignes du parcours externe. Le nœud de
    jointure en boucle imbriquée s'exécutera sur le deuxième nœud, ou nœud
    <quote>interne</quote>, pour chaque ligne obtenue du nœud externe. Les
    valeurs de colonne de la ligne externe courante peuvent être utilisées
    dans le parcours interne&nbsp;; ici, la valeur
    <literal>t1.unique2</literal> de la ligne externe est disponible, et on
    peut obtenir un plan et un coût similaires à ce que l'on a vu plus haut
    pour le cas simple <literal>SELECT ... WHERE t2.unique2 =
    <replaceable>constant</replaceable></literal>.(Le coût estimé est ici un
    peu plus faible que celui vu précédemment, en prévision de la mise en
    cache des données durant les parcours d'index répétés sur
    <literal>t2</literal>.) Les coûts du nœud correspondant à la boucle sont
    ensuite initialisés sur la base du coût du parcours externe, avec une
    répétition du parcours interne pour chaque ligne externe (ici 10 * 7,91),
    plus un petit temps CPU pour traiter la jointure.
   </para>

   <para>
    Dans cet exemple, le nombre de lignes en sortie de la jointure est
    identique au nombre de lignes des deux parcours, mais ce n'est pas vrai
    en règle générale car vous pouvez avoir des clauses
    <literal>WHERE</literal> mentionnant les deux tables et qui, donc,
    peuvent seulement être appliquées au point de jointure, et non pas aux
    parcours d'index. Voici un exemple&nbsp;:

    <screen>EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t2.unique2 &lt; 10 AND t1.hundred &lt; t2.hundred;

                                      QUERY PLAN
--------------------------------------------------------------------------------------
 Nested Loop  (cost=4.65..49.46 rows=33 width=488)
   Join Filter: (t1.hundred &lt; t2.hundred)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=4.36..39.47 rows=10 width=244)
         Recheck Cond: (unique1 &lt; 10)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..4.36 rows=10 width=0)
               Index Cond: (unique1 &lt; 10)
   -&gt;  Materialize  (cost=0.29..8.51 rows=10 width=244)
         -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.29..8.46 rows=10 width=244)
               Index Cond: (unique2 &lt; 10)</screen>

    La condition <literal>t1.hundred &lt; t2.hundred</literal> ne peut être
    testée dans l'index <literal>tenk2_unique2</literal>, elle est donc
    appliquée au nœud de jointure. Cela réduit l'estimation du nombre de
    lignes dans le nœud de jointure, mais ne change aucun parcours d'entrée.
   </para>

   <para>
    Notez qu'ici le planificateur a choisi de matérialiser la relation interne
    de la jointure en plaçant un nœud Materialize au-dessus. Cela signifie
    que le parcours d'index de <literal>t2</literal> ne sera réalisé qu'une
    seule fois, même si le nœud de jointure par boucle imbriquée va lire dix
    fois les données, une fois par ligne de la relation externe. Le nœud
    Materialize conserve les données en mémoire lors de leur première
    lecture, puis renvoie les données depuis la mémoire à chaque lecture
    supplémentaire.
   </para>

   <para>
    Quand vous utilisez des jointures externes, vous pouvez voir des nœuds de
    plan de jointure avec à la fois des conditions <quote>Join Filter</quote>
    et <quote>Filter</quote> simples attachées. Les conditions <quote>Join
    Filter</quote> viennent des clauses de jointures externes
    <literal>ON</literal>, pour qu'une ligne ne satisfaisant pas la condition
    <quote>Join Filter</quote> puisse toujours être récupérée comme une ligne
    NULL. Mais une condition <quote>Filter</quote> simple est appliquée après
    la règle de jointure externe et supprime donc les lignes de manière
    inconditionnelle. Dans une jointure interne, il n'y a pas de différence
    sémantique entre ces types de filtres.
   </para>

   <para>
    Si nous changeons un peu la sélectivité de la requête, on pourrait obtenir
    un plan de jointure très différent&nbsp;:

    <screen>EXPLAIN SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                        QUERY PLAN
------------------------------------------------------------------------------------------
 Hash Join  (cost=230.47..713.98 rows=101 width=488)
    Hash Cond: (t2.unique2 = t1.unique2)
    -&gt;  Seq Scan on tenk2 t2  (cost=0.00..445.00 rows=10000 width=244)
    -&gt;  Hash  (cost=229.20..229.20 rows=101 width=244)
           -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=5.07..229.20 rows=101 width=244)
                Recheck Cond: (unique1 &lt; 100)
                -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.04 rows=101 width=0)
                     Index Cond: (unique1 &lt; 100)</screen>
   </para>

   <para>
    Ici, le planificateur a choisi d'utiliser une jointure de hachage, dans
    laquelle les lignes d'une table sont entrées dans une table de hachage en
    mémoire, après quoi l'autre table est parcourue et la table de hachage
    est sondée pour faire correspondre chaque ligne. Notez encore une fois
    comment l'indentation reflète la structure du plan&nbsp;: le parcours
    d'index bitmap sur <literal>tenk1</literal> est l'entrée du nœud de
    hachage, qui construit la table de hachage. C'est alors retourné au nœud
    de jointure de hachage, qui lit les lignes depuis le plan du fils externe
    et cherche dans la table de hachage pour chaque ligne.
   </para>

   <para>
    Un autre type de jointure possible est la jointure d'assemblage, illustrée
    ici&nbsp;:

    <screen>EXPLAIN SELECT *
FROM tenk1 t1, onek t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                        QUERY PLAN
------------------------------------------------------------------------------------------
 Merge Join  (cost=198.11..268.19 rows=10 width=488)
   Merge Cond: (t1.unique2 = t2.unique2)
   -&gt;  Index Scan using tenk1_unique2 on tenk1 t1  (cost=0.29..656.28 rows=101 width=244)
         Filter: (unique1 &lt; 100)
   -&gt;  Sort  (cost=197.83..200.33 rows=1000 width=244)
         Sort Key: t2.unique2
         -&gt;  Seq Scan on onek t2  (cost=0.00..148.00 rows=1000 width=244)</screen>
   </para>

   <para>
    La jointure d'assemblage nécessite que les données en entrée soient triées
    sur la clé de jointure. Dans ce plan, les données de
    <literal>tenk1</literal> sont triées grâce à l'utilisation d'un parcours
    d'index pour visiter les lignes dans le bon ordre, mais un parcours
    séquentiel suivi d'un tri sont préférables pour <literal>onek</literal>,
    car il y a beaucoup plus de lignes à visiter dans cette table.
    (Un parcours séquentiel suivi d'un tri bat fréquemment un parcours
    d'index pour trier de nombreuses lignes, du fait des accès disques non
    séquentiels requis par le parcours d'index.)
   </para>

   <para>
    Une façon de rechercher des plans différents est de forcer le
    planificateur à oublier certaines stratégies qu'il aurait trouvées moins
    coûteuses en utilisant les options d'activation (enable)/désactivation
    (disable) décrites dans la <xref linkend="runtime-config-query-enable"/>
    (c'est un outil complexe, mais utile&nbsp;; voir aussi la <xref
    linkend="explicit-joins"/>). Par exemple, si nous n'étions pas convaincus
    qu'un parcours séquentiel suivi d'un tri soit la meilleure façon de
    parcourir la table <literal>onek</literal> dans l'exemple précédent, nous
    pourrions essayer

    <screen>SET enable_sort = off;
EXPLAIN SELECT *
FROM tenk1 t1, onek t2
 WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2;

                                         QUERY PLAN
 ------------------------------------------------------------------------------------------
 Merge Join  (cost=0.56..292.65 rows=10 width=488)
   Merge Cond: (t1.unique2 = t2.unique2)
   -&gt;  Index Scan using tenk1_unique2 on tenk1 t1  (cost=0.29..656.28 rows=101 width=244)
         Filter: (unique1 &lt; 100)
   -&gt;  Index Scan using onek_unique2 on onek t2  (cost=0.28..224.79 rows=1000 width=244)</screen>

    ce qui montre que le planificateur pense que le tri de
    <literal>onek</literal> par un parcours d'index est plus coûteux
    d'environ 12% par rapport à un parcours séquentiel suivi d'un tri. Bien
    sûr, la question suivante est de savoir s'il a raison sur ce point. Nous
    pourrions vérifier cela en utilisant <command>EXPLAIN ANALYZE</command>,
    comme expliqué ci-dessous.
   </para>
  </sect2>

  <sect2 id="using-explain-analyze">
   <title><command>EXPLAIN ANALYZE</command></title>

   <para>
    Il est possible de vérifier l'exactitude des estimations du planificateur
    en utilisant l'option <literal>ANALYZE</literal> de
    <command>EXPLAIN</command>. Avec cette option, <command>EXPLAIN</command>
    exécute vraiment la requête, puis affiche le vrai nombre de lignes et les
    vrais temps passés dans chaque nœud, avec ceux estimés par un simple
    <command>EXPLAIN</command>. Par exemple, nous pourrions avoir un résultat
    tel que&nbsp;:

    <screen>EXPLAIN ANALYZE SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 10 AND t1.unique2 = t2.unique2;

                                                           QUERY PLAN
---------------------------------------------------------------------------------------------------------------------------------
 Nested Loop  (cost=4.65..118.62 rows=10 width=488) (actual time=0.128..0.377 rows=10 loops=1)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=4.36..39.47 rows=10 width=244) (actual time=0.057..0.121 rows=10 loops=1)
          Recheck Cond: (unique1 &lt; 10)
          -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..4.36 rows=10 width=0) (actual time=0.024..0.024 rows=10 loops=1)
                Index Cond: (unique1 &lt; 10)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.29..7.91 rows=1 width=244) (actual time=0.021..0.022 rows=1 loops=10)
          Index Cond: (unique2 = t1.unique2)
 Planning time: 0.181 ms
 Execution time: 0.501 ms</screen>

    Notez que les valeurs <quote>temps réel</quote> sont en millisecondes
    alors que les estimations de <quote>coût</quote> sont exprimées dans des
    unités arbitraires&nbsp;; il y a donc peu de chances qu'elles
    correspondent. L'information qu'il faut généralement rechercher est si le
    nombre de lignes estimées est raisonnablement proche de la réalité. Dans
    cet exemple, les estimations étaient toutes rigoureusement exactes, mais
    c'est en pratique plutôt inhabituel.
   </para>

   <para>
    Dans certains plans de requête, il est possible qu'un nœud de sous-plan
    soit exécuté plus d'une fois. Par exemple, le parcours d'index interne
    est exécuté une fois par ligne externe dans le plan de boucle imbriquée
    ci-dessus. Dans de tels cas, la valeur <literal>loops</literal> renvoie
    le nombre total d'exécutions du nœud, et le temps réel et les valeurs des
    lignes affichées sont une moyenne par exécution. Ceci est fait pour que
    les nombres soient comparables avec la façon dont les estimations de
    coûts sont affichées. Multipliez par la valeur de
    <literal>loops</literal> pour obtenir le temps total réellement passé
    dans le nœud. Dans l'exemple précédent, le parcours d'index sur
    <literal>tenk2</literal> a pris un total de 0,220 milliseconde.
   </para>

   <para>
    Dans certains cas, <command>EXPLAIN ANALYZE</command> affiche des
    statistiques d'exécution supplémentaires après le temps et le nombre de
    lignes de l'exécution d'un nœud du plan. Par exemple, les nœuds de tri et
    de hachage fournissent des informations supplémentaires&nbsp;:

    <screen>EXPLAIN ANALYZE SELECT *
FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 100 AND t1.unique2 = t2.unique2 ORDER BY t1.fivethous;

                                                                 QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------------------------
 Sort  (cost=717.34..717.59 rows=101 width=488) (actual time=7.761..7.774 rows=100 loops=1)
    Sort Key: t1.fivethous
    Sort Method: quicksort  Memory: 77kB
    -&gt;  Hash Join  (cost=230.47..713.98 rows=101 width=488) (actual time=0.711..7.427 rows=100 loops=1)
          Hash Cond: (t2.unique2 = t1.unique2)
          -&gt;  Seq Scan on tenk2 t2  (cost=0.00..445.00 rows=10000 width=244) (actual time=0.007..2.583 rows=10000 loops=1)
          -&gt;  Hash  (cost=229.20..229.20 rows=101 width=244) (actual time=0.659..0.659 rows=100 loops=1)
               Buckets: 1024  Batches: 1  Memory Usage: 28kB
               -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=5.07..229.20 rows=101 width=244) (actual time=0.080..0.526 rows=100 loops=1)
                      Recheck Cond: (unique1 &lt; 100)
                      -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.04 rows=101 width=0) (actual time=0.049..0.049 rows=100 loops=1)
                            Index Cond: (unique1 &lt; 100)
 Planning time: 0.194 ms
 Execution time: 8.008 ms</screen>

    Le nœud de tri donne la méthode de tri utilisée (en particulier, si le tri
    s'est effectué en mémoire ou sur disque) ainsi que la quantité de mémoire
    ou d'espace disque requis. Le nœud de hachage montre le nombre de paquets
    de hachage, le nombre de lots ainsi la quantité maximale de mémoire
    utilisée pour la table de hachage (si le nombre de lots est supérieur à
    un, il y aura également l'utilisation de l'espace disque impliqué, mais
    cela n'est pas montré dans cet exemple).
   </para>

   <para>
    Un autre type d'information supplémentaire est le nombre de lignes
    supprimées par une condition de filtrage&nbsp;:

    <screen>EXPLAIN ANALYZE SELECT * FROM tenk1 WHERE ten &lt; 7;

                                                QUERY PLAN
----------------------------------------------------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..483.00 rows=7000 width=244) (actual time=0.016..5.107 rows=7000 loops=1)
   Filter: (ten &lt; 7)
   Rows Removed by Filter: 3000
 Planning time: 0.083 ms
 Execution time: 5.905 ms</screen>

    Ces nombres peuvent être particulièrement précieux pour les conditions de
    filtres appliquées aux nœuds de jointure. La ligne <quote>Rows
    Removed</quote> n'apparaît que si au moins une ligne parcourue, ou une
    ligne potentiellement appairée dans le cas d'un nœud de jointure, est
    rejetée par la condition de filtre.
   </para>

   <para>
    Un cas similaire aux conditions de filtre apparaît avec des parcours
    d'index <quote>avec perte</quote>. Par exemple, regardez cette recherche
    de polygone contenant un point spécifique&nbsp;:

    <screen>EXPLAIN ANALYZE SELECT * FROM polygon_tbl WHERE f1 @&gt; polygon '(0.5,2.0)';

                                              QUERY PLAN
------------------------------------------------------------------------------------------------------
 Seq Scan on polygon_tbl  (cost=0.00..1.05 rows=1 width=32) (actual time=0.044..0.044 rows=0 loops=1)
   Filter: (f1 @&gt; '((0.5,2))'::polygon)
   Rows Removed by Filter: 4
 Planning time: 0.040 ms
 Execution time: 0.083 ms</screen>

    Le planificateur pense (plutôt correctement) que cette table d'échantillon
    est trop petite pour s'embêter avec un parcours d'index, et utilise donc
    un parcours séquentiel dans lequel toutes les lignes sont rejetées par la
    condition de filtre. Mais si nous forçons l'utilisation d'un parcours
    d'index, nous voyons&nbsp;:

    <screen>SET enable_seqscan TO off;

EXPLAIN ANALYZE SELECT * FROM polygon_tbl WHERE f1 @&gt; polygon '(0.5,2.0)';

                                                        QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------
 Index Scan using gpolygonind on polygon_tbl  (cost=0.13..8.15 rows=1 width=32) (actual time=0.062..0.062 rows=0 loops=1)
   Index Cond: (f1 @&gt; '((0.5,2))'::polygon)
   Rows Removed by Index Recheck: 1
 Planning time: 0.034 ms
 Execution time: 0.144 ms</screen>

    L'index retourne une ligne candidate, qui est ensuite rejetée par une
    deuxième vérification de la condition de l'index. Cela arrive car un
    index GiST est <quote>avec perte</quote> pour les tests de contenance de
    polygone&nbsp;: il retourne en fait les lignes pour lesquelles les
    polygones chevauchent la cible, ce qui nécessite après coup un test de
    contenance exacte sur ces lignes.
   </para>

   <para>
    <command>EXPLAIN</command> a une option <literal>BUFFERS</literal> qui
    peut être utilisée avec <literal>ANALYZE</literal> pour obtenir encore
    plus de statistiques d'exécution:

    <screen>EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000;

                                                           QUERY PLAN
---------------------------------------------------------------------------------------------------------------------------------
 Bitmap Heap Scan on tenk1  (cost=25.08..60.21 rows=10 width=244) (actual time=0.323..0.342 rows=10 loops=1)
    Recheck Cond: ((unique1 &lt; 100) AND (unique2 &gt; 9000))
    Buffers: shared hit=15
   -&gt;  BitmapAnd  (cost=25.08..25.08 rows=10 width=0) (actual time=0.309..0.309 rows=0 loops=1)
          Buffers: shared hit=7
          -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.04 rows=101 width=0) (actual time=0.043..0.043 rows=100 loops=1)
                Index Cond: (unique1 &lt; 100)
                Buffers: shared hit=2
          -&gt;  Bitmap Index Scan on tenk1_unique2  (cost=0.00..19.78 rows=999 width=0) (actual time=0.227..0.227 rows=999 loops=1)
                Index Cond: (unique2 &gt; 9000)
                Buffers: shared hit=5
 Planning time: 0.088 ms
 Execution time: 0.423 ms</screen>

    Les nombres fournis par <literal>BUFFERS</literal> aident à identifier les
    parties de la requête les plus intensives en termes d'entrées sorties.
   </para>

   <para>
    Il faut garder en tête que comme <command>EXPLAIN ANALYZE</command>
    exécute vraiment la requête, tous les effets secondaires se produiront
    comme d'habitude, même si, quel que soit l'affichage de la requête, il
    est remplacé par la sortie des données d'<command>EXPLAIN</command>. Si
    vous voulez analyser une requête modifiant les données sans changer les
    données en table, vous pouvez annuler les modifications après, par
    exemple&nbsp;:

    <screen>BEGIN;
EXPLAIN ANALYZE UPDATE tenk1 SET hundred = hundred + 1 WHERE unique1 &lt; 100;

                                                           QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------------
Update on tenk1  (cost=5.08..230.08 rows=0 width=0) (actual time=3.791..3.792 rows=0 loops=1)
  -&gt;  Bitmap Heap Scan on tenk1  (cost=5.08..230.08 rows=102 width=10) (actual time=0.069..0.513 rows=100 loops=1)
        Recheck Cond: (unique1 &lt; 100)
        Heap Blocks: exact=90
        -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..5.05 rows=102 width=0) (actual time=0.036..0.037 rows=300 loops=1)
               Index Cond: (unique1 &lt; 100)
Planning Time: 0.113 ms
Execution Time: 3.850 ms

ROLLBACK;</screen>
   </para>

   <para>
    Comme vous pouvez le voir dans cet exemple, quand la requête contient une
    commande <command>INSERT</command>, <command>UPDATE</command> ou
    <command>DELETE</command> l'application des changements est faite au
    niveau du nœud principal Insert, Update ou Delete du plan. Les nœuds du
    plan sous celui-ci effectuent le travail de recherche des anciennes
    lignes et/ou le calcul des nouvelles données. Ainsi, au-dessus, on peut
    voir les mêmes tris de parcours de bitmap déjà vus précédemment, et leur
    sortie est envoyée à un nœud de mise à jour qui stocke les lignes
    modifiées. Il est intéressant de noter que bien que le nœud de
    modification de données puisse prendre une part considérable sur le temps
    d'exécution (ici, c'est la partie la plus gourmande), le planificateur
    n'ajoute rien au coût estimé pour considérer ce travail. C'est dû au fait
    que le travail à effectuer est le même pour chaque plan de requête
    correct, et n'affecte donc pas les décisions du planificateur.
   </para>

   <para>
    La phrase <literal>Planning time</literal> affichée par <command>EXPLAIN
    ANALYZE</command> correspond au temps pris pour générer et optimiser le
    plan de requêtes à partir de la requête analysée. Cela n'inclut pas
    l'analyse syntaxique et la réécriture.
   </para>

   <para>

    Le <literal>Temps total d'exécution</literal> donné par <command>EXPLAIN
    ANALYZE</command> inclut le temps de démarrage et d'arrêt de l'exécuteur,
    ainsi que le temps d'exécution de tous les triggers pouvant être
    déclenchés, mais n'inclut pas les temps d'analyse, de réécriture ou de
    planification. Le temps passé à exécuter les triggers
    <literal>BEFORE</literal>, s'il y en a, est inclus dans le temps passé à
    l'exécution des nœuds Insert, Update ou Delete associés, mais le temps
    passé à exécuter les triggers <literal>AFTER</literal> n'est pas compté,
    car les triggers <literal>AFTER</literal> sont déclenchés après
    l'achèvement du plan entier. Le temps total passé dans chaque trigger
    (que ce soit <literal>BEFORE</literal> ou <literal>AFTER</literal>) est
    affiché séparément. Notez que les triggers de contrainte ne seront pas
    exécutés avant la fin de la transaction et par conséquent ne seront pas
    affichés du tout par <command>EXPLAIN ANALYZE</command>.
   </para>
  </sect2>

  <sect2 id="using-explain-caveats">
   <title>Avertissements</title>

   <para>
    Il existe deux raisons importantes pour lesquelles les temps d'exécution
    mesurés par <command>EXPLAIN ANALYZE</command> peuvent dévier de
    l'exécution normale de la même requête. Tout d'abord, comme aucune ligne
    n'est réellement envoyée au client, les coûts de conversion réseau et les
    coûts de formatage des entrées/sorties ne sont pas inclus. Ensuite, le
    surcoût de mesure induit par <command>EXPLAIN ANALYZE</command> peut être
    significatif, plus particulièrement sur les machines avec un appel
    système <function>gettimeofday()</function> lent. Vous pouvez utiliser
    l'outil <xref linkend="pgtesttiming"/> pour mesurer le surcoût du calcul
    du temps sur votre système.
   </para>

   <para>
    Les résultats de <command>EXPLAIN</command> ne devraient pas être
    extrapolés pour des situations autres que celles de vos tests en
    cours&nbsp;; par exemple, les résultats sur une petite table ne peuvent
    être appliqués à des tables bien plus volumineuses. Les estimations de
    coût du planificateur ne sont pas linéaires et, du coup, il pourrait bien
    choisir un plan différent pour une table plus petite ou plus grande. Un
    exemple extrême est celui d'une table occupant une page disque. Vous
    obtiendrez pratiquement toujours un parcours séquentiel, que des index
    soient disponibles ou non. Le planificateur réalise que cela va
    nécessiter la lecture d'un seul bloc disque pour traiter la table dans
    ce cas, il n'y a donc pas d'intérêt à étendre des lectures de blocs
    supplémentaires pour un index. (Nous voyons cela arriver dans l'exemple
    <literal>polygon_tbl</literal> au-dessus.)
   </para>

   <para>
    Ici, ce sont des cas dans lesquels les valeurs réelles et estimées ne
    correspondent pas vraiment, mais qui ne sont pas non plus totalement
    fausses. Un tel cas peut se produire quand un nœud d'exécution d'un plan
    est arrêté par un <literal>LIMIT</literal> ou autre chose avec un effet
    similaire. Par exemple, dans la requête <literal>LIMIT</literal>
    utilisée précédemment,

    <screen>EXPLAIN ANALYZE SELECT * FROM tenk1 WHERE unique1 &lt; 100 AND unique2 &gt; 9000 LIMIT 2;

                                                          QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.29..14.71 rows=2 width=244) (actual time=0.177..0.249 rows=2 loops=1)
   -&gt;  Index Scan using tenk1_unique2 on tenk1  (cost=0.29..72.42 rows=10 width=244) (actual time=0.174..0.244 rows=2 loops=1)
         Index Cond: (unique2 &gt; 9000)
         Filter: (unique1 &lt; 100)
         Rows Removed by Filter: 287
 Planning time: 0.096 ms
 Execution time: 0.336 ms</screen>

    les estimations de coût et de nombre de lignes pour le nœud de parcours
    d'index sont affichées comme s'ils devaient s'exécuter jusqu'à la fin.
    Mais en réalité le nœud Limit arrête la récupération des lignes après la
    deuxième ligne récupérée, et donc le vrai nombre de lignes n'est que de 2
    et le temps d'exécution est moindre que ne le suggérait le coût estimé.
    Ce n'est pas une erreur d'estimation, juste une contradiction entre la
    façon dont l'estimation et les valeurs réelles sont affichées.
   </para>

   <para>
    Les jointures d'assemblage ont également leurs artefacts de mesure qui
    peuvent embrouiller une personne non avertie. Une jointure d'assemblage
    arrêtera la lecture d'une entrée si l'autre entrée est épuisée et que la
    prochaine valeur clé dans la première entrée est supérieure à la dernière
    valeur clé de l'autre entrée&nbsp;; dans un cas comme ça, il ne peut plus
    y avoir de correspondance et il est donc inutile de parcourir le reste de
    la première entrée. Cela a donc pour conséquence de ne pas lire
    entièrement un des fils, avec des résultats similaires à ceux mentionnés
    pour <literal>LIMIT</literal>. De même, si le fils externe (premier fils)
    contient des lignes avec des valeurs de clé dupliquées, le fils externe
    (second fils) est sauvegardé et les lignes correspondant à cette valeur
    clé sont parcourues de nouveau. <command>EXPLAIN ANALYZE</command> compte
    ces émissions répétées de mêmes lignes internes comme si elles étaient de
    vraies lignes supplémentaires. Quand il y a de nombreux doublons
    externes, le nombre réel de lignes affiché pour le nœud de plan du fils
    interne peut être significativement plus grand que le nombre de lignes
    qu'il y a vraiment dans la relation interne.
   </para>

   <para>
    Les nœuds BitmapAnd et BitmapOr affichent toujours un nombre de lignes
    réelles à 0, du fait des limitations d'implémentation.
   </para>

   <para>
    Habituellement, la sortie d'<command>EXPLAIN</command> affichera chaque
    nœud de plan généré par le planificateur de requêtes. Néanmoins, il
    existe des cas où l'exécuteur peut déterminer que certains nœuds n'ont
    pas besoin d'être exécutés car ils ne produisent aucune ligne.
    (Actuellement, ceci peut n'arriver qu'aux nœuds enfants du nœud
    <literal>Append</literal> qui parcourt une table partitionnée.) Quand
    cela arrive, ces nœuds sont omis de la sortie de la commande
    <command>EXPLAIN</command> et une annotation <literal>Subplans Removed:
    <replaceable>N</replaceable></literal> apparaît à la place.
   </para>
  </sect2>
 </sect1>

 <sect1 id="planner-stats">
  <title>Statistiques utilisées par le planificateur</title>

  <indexterm zone="planner-stats">
   <primary>statistiques</primary>
   <secondary>du planificateur</secondary>
  </indexterm>

  <sect2>
   <title>Statistiques mono-colonne</title>

   <para>
    Comme nous l'avons vu dans la section précédente, le planificateur de
    requêtes a besoin d'estimer le nombre de lignes récupérées par une
    requête pour faire les bons choix dans ses plans de requêtes. Cette
    section fournit un aperçu sur les statistiques que le système utilise
    pour ces estimations.
   </para>

   <para>

    Un élément des statistiques est le nombre total d'entrées dans chaque
    table et index, ainsi que le nombre de blocs disque occupés par chaque
    table et index. Cette information est conservée dans la table <link
    linkend="catalog-pg-class"><structname>pg_class</structname></link> sur
    les colonnes <structfield>reltuples</structfield> et
    <structfield>relpages</structfield>. Nous pouvons la regarder avec des
    requêtes comme celle-ci&nbsp;:

    <screen>SELECT relname, relkind, reltuples, relpages
FROM pg_class
WHERE relname LIKE 'tenk1%';

       relname        | relkind | reltuples | relpages
----------------------+---------+-----------+----------
 tenk1                | r       |     10000 |      358
 tenk1_hundred        | i       |     10000 |       30
 tenk1_thous_tenthous | i       |     10000 |       30
 tenk1_unique1        | i       |     10000 |       30
 tenk1_unique2        | i       |     10000 |       30
(5 rows)</screen>

    Ici, nous pouvons voir que <structname>tenk1</structname> contient 10000
    lignes, comme pour ses index, mais que les index sont bien plus petits
    que la table (ce qui n'est pas surprenant).
   </para>

   <para>
    Pour des raisons d'efficacité, les valeurs des colonnes
    <structfield>reltuples</structfield> et
    <structfield>relpages</structfield> ne sont pas mises à jour en temps
    réel, et contiennent alors souvent des valeurs un peu obsolètes. Elles
    sont mises à jour par les commandes <command>VACUUM</command>,
    <command>ANALYZE</command> et quelques commandes DDL comme
    <command>CREATE INDEX</command>. Une opération <command>VACUUM</command>
    ou <command>ANALYZE</command> qui ne parcourt pas la table entièrement
    (ce qui est le cas le plus fréquent) augmentera de façon incrémentale la
    valeur de <structfield>reltuples</structfield> sur la base de la partie
    de la table qu'elle a parcourue, résultant en une valeur approximative.
    Dans tous les cas, le planificateur mettra à l'échelle les valeurs qu'il
    aura trouvées dans <structname>pg_class</structname> pour correspondre à
    la taille physique de la table, obtenant ainsi une approximation plus
    proche de la réalité.
   </para>

   <indexterm>
    <primary>pg_statistic</primary>
   </indexterm>

   <para>
    La plupart des requêtes ne récupèrent qu'une fraction des lignes dans une
    table à cause de clauses <literal>WHERE</literal> qui restreignent les
    lignes à examiner. Du coup, le planificateur a besoin d'une estimation de
    la <firstterm>sélectivité</firstterm> des clauses
    <literal>WHERE</literal>, c'est-à-dire la fraction des lignes qui
    correspondent à chaque condition de la clause <literal>WHERE</literal>.
    L'information utilisée pour cette tâche est stockée dans le catalogue
    système <link
    linkend="catalog-pg-statistic"><structname>pg_statistic</structname></link>.
    Les entrées de <structname>pg_statistic</structname> sont mises à jour
    par les commandes <command>ANALYZE</command> et <command>VACUUM
    ANALYZE</command> et sont toujours approximatives même si elles ont été
    mises à jour récemment.
   </para>

   <indexterm>
    <primary>pg_stats</primary>
   </indexterm>

   <para>
    Plutôt que de regarder directement dans
    <structname>pg_statistic</structname>, il vaut mieux voir sa vue <link
    linkend="view-pg-stats"><structname>pg_stats</structname></link> lors
    d'un examen manuel des statistiques. La vue
    <structname>pg_stats</structname> est conçue pour être plus facilement
    lisible. De plus, <structname>pg_stats</structname> est lisible par tous
    alors que <structname>pg_statistic</structname> n'est lisible que par un
    super-utilisateur (ceci empêche les utilisateurs sans droits d'apprendre
    certaines choses sur le contenu des tables appartenant à d'autres
    personnes à partir des statistiques. La vue
    <structname>pg_stats</structname> est restreinte pour n'afficher que les
    lignes des tables lisibles par l'utilisateur courant). Par exemple, nous
    pourrions lancer&nbsp;:

    <screen>SELECT attname, inherited, n_distinct,
       array_to_string(most_common_vals, E'\n') as most_common_vals
FROM pg_stats
WHERE tablename = 'road';

 attname | inherited | n_distinct |          most_common_vals
---------+-----------+------------+------------------------------------
 name    | f         |  -0.363388 | I- 580                        Ramp+
         |           |            | I- 880                        Ramp+
         |           |            | Sp Railroad                       +
         |           |            | I- 580                            +
         |           |            | I- 680                        Ramp
 name    | t         |  -0.284859 | I- 880                        Ramp+
         |           |            | I- 580                        Ramp+
         |           |            | I- 680                        Ramp+
         |           |            | I- 580                            +
         |           |            | State Hwy 13                  Ramp
(2 rows)</screen>

    Notez que deux lignes sont affichées pour la même colonne, une
    correspondant à la hiérarchie d'héritage complète commençant à la table
    <literal>road</literal>
    (<literal>inherited</literal>=<literal>t</literal>), et une autre
    incluant seulement la table <literal>road</literal> elle-même
    (<literal>inherited</literal>=<literal>f</literal>).
   </para>

   <para>
    Les informations stockées dans <structname>pg_statistic</structname> par
    <command>ANALYZE</command>, en particulier le nombre maximum d'éléments
    dans les tableaux <structfield>most_common_vals</structfield> et
    <structfield>histogram_bounds</structfield> pour chaque colonne, peuvent
    être définies colonne par colonne en utilisant la commande <command>ALTER
    TABLE SET STATISTICS</command> ou globalement en initialisant la variable
    de configuration <xref linkend="guc-default-statistics-target"/>. La
    limite par défaut est actuellement de 100 entrées. Augmenter la limite
    pourrait résulter en des estimations plus précises du planificateur, en
    particulier pour les colonnes ayant des distributions de données
    irrégulières, au prix d'un plus grand espace consommé dans
    <structname>pg_statistic</structname> et d'un temps plus long pour
    calculer les estimations. En revanche, une limite plus basse pourrait
    être suffisante pour des colonnes avec des distributions de données
    simples.
   </para>

   <para>
    Le <xref linkend="planner-stats-details"/> donne plus de détails sur
    l'utilisation des statistiques par le planificateur.
   </para>
  </sect2>

  <sect2 id="planner-stats-extended">
   <title>Statistiques étendues</title>

   <indexterm zone="planner-stats-extended">
    <primary>statistiques</primary>
    <secondary>de l'optimiseur</secondary>
   </indexterm>

   <indexterm>
    <primary>corrélation</primary>
    <secondary>dans l'optimiseur de requêtes</secondary>
   </indexterm>

   <indexterm>
    <primary>pg_statistic_ext</primary>
   </indexterm>

   <indexterm>
    <primary>pg_statistic_ext_data</primary>
   </indexterm>

   <para>
    Il est habituel de voir des requêtes lentes tourner avec de mauvais plans
    d'exécution, car plusieurs colonnes utilisées dans les clauses de la
    requête sont corrélées. L'optimiseur part normalement du principe que
    toutes les conditions sont indépendantes les unes des autres, ce qui est
    faux quand les valeurs des colonnes sont corrélées. Les statistiques
    classiques, du fait qu'il s'agit par nature de statistiques sur une seule
    colonne, ne peuvent pas capturer d'information sur la corrélation entre
    colonnes. Toutefois, <productname>PostgreSQL</productname> a la
    possibilité de calculer des <firstterm>statistiques
    multivariées</firstterm>, qui peuvent capturer une telle information.
   </para>

   <para>
    Comme le nombre de combinaisons de colonnes est très important, il n'est
    pas possible de calculer les statistiques multivariées automatiquement. À
    la place, des <firstterm>objets statistiques étendus</firstterm>, plus
    souvent appelés simplement <firstterm>objets statistiques</firstterm>,
    peuvent être créés pour indiquer au serveur qu'il faut obtenir des
    statistiques sur un ensemble intéressant de colonnes.
   </para>

   <para>
    Les objets statistiques sont créés en utilisant la commande <link
    linkend="sql-createstatistics"><command>CREATE
    STATISTICS</command></link>. La création de tels objets crée seulement
    une entrée dans le catalogue pour exprimer l'intérêt dans cette
    statistique. La vraie récupération de données est effectuée par
    <command>ANALYZE</command> (soit une commande manuelle, soit une analyse
    automatique en tâche de fond). Les valeurs collectées peuvent être
    examinées dans le catalogue <link
    linkend="catalog-pg-statistic-ext-data"><structname>pg_statistic_ext_data</structname></link>.
   </para>

   <para>
    <command>ANALYZE</command> calcule des statistiques étendues basées sur le
    même ensemble de lignes de la table qu'il utilise pour calculer les
    statistiques standard sur une seule colonne. Puisque la taille
    d'échantillon peut être augmentée en augmentant la cible de statistiques
    de la table ou de n'importe laquelle de ses colonnes (comme décrit dans
    la section précédente), une plus grande cible de statistiques donnera
    normalement des statistiques étendues plus précises, mais nécessitera
    également plus de temps pour les calculer.
   </para>

   <para>
    La section suivante décrit les types de statistiques étendues qui sont
    actuellement supportées.
   </para>

   <sect3>
    <title>Dépendances fonctionnelles</title>

    <para>
     Le type le plus simple de statistiques étendues trace les
     <firstterm>dépendances fonctionnelles </firstterm>, un concept utilisé
     dans les définitions des formes normales des bases de données. On dit
     qu'une colonne <structfield>b</structfield> est fonctionnellement
     dépendante d'une colonne <structfield>a</structfield> si la connaissance
     de la valeur de <structfield>a</structfield> est suffisante pour
     déterminer la valeur de <structfield>b</structfield>, et donc qu'il
     n'existe pas deux lignes ayant la même valeur de
     <structfield>a</structfield> avec des valeurs différentes de
     <structfield>b</structfield>. Dans une base de données complètement
     normalisée, les dépendances fonctionnelles ne devraient exister que sur
     la clé primaire et les superclés. Toutefois, dans la pratique, beaucoup
     d'ensembles de données ne sont pas totalement normalisés pour de
     nombreuses raisons&nbsp;; une dénormalisation intentionnelle pour des
     raisons de performances est un exemple courant. Même dans une base de
     données totalement normalisée, il peut y avoir une corrélation partielle
     entre des colonnes, qui peuvent être exprimées comme une dépendance
     fonctionnelle partielle.
    </para>

    <para>
     L'existence de dépendances fonctionnelles a un impact direct sur la
     précision de l'estimation pour certaines requêtes. Si une requête
     contient des conditions à la fois sur des colonnes indépendantes et sur
     des colonnes dépendantes, les conditions sur les colonnes dépendantes ne
     réduisent plus la taille du résultat&nbsp;; mais sans la connaissance de
     cette dépendance fonctionnelle, l'optimiseur de requêtes supposera que
     les conditions sont indépendantes, avec pour résultat une taille de
     résultat sous-estimée.
    </para>

    <para>
     Pour informer l'optimiseur des dépendances fonctionnelles,
     <command>ANALYZE</command> peut collecter des mesures sur des
     dépendances entre colonnes. Évaluer le degré de dépendance entre tous
     les ensembles de colonnes aurait un coût prohibitif, c'est pourquoi la
     collecte de données est limitée aux groupes de colonnes apparaissant
     ensemble dans un objet statistique défini avec l'option
     <literal>dependencies</literal>. Il est conseillé de ne créer des
     <literal>dépendences</literal> statistiques que pour des groupes de
     colonnes fortement corrélées, pour éviter un surcoût à la fois dans
     <command>ANALYZE</command> et plus tard lors de la planification de
     requête.
    </para>

    <para>
     Voici un exemple de collecte de statistiques fonctionnellement
     dépendantes&nbsp;:

     <programlisting>CREATE STATISTICS stts (dependencies) ON city, zip FROM zipcodes;

ANALYZE zipcodes;

SELECT stxname, stxkeys, stxddependencies
  FROM pg_statistic_ext join pg_statistic_ext_data on (oid = stxoid)
  WHERE stxname = 'stts';
 stxname | stxkeys |             stxddependencies
---------+---------+------------------------------------------
 stts    | 1 5     | {"1 => 5": 1.000000, "5 => 1": 0.423130}
(1 row)</programlisting>

     On peut voir ici que la colonne 1 (zip code) détermine complètement la
     colonne 5 (city) et que donc le coefficient est 1.0, alors que la ville
     ne détermine le code postal qu'environ 42% du temps, ce qui veut dire
     qu'il y a beaucoup de villes (58%) qui sont représentées par plus d'un
     seul code postal.
    </para>

    <para>
     Lors du calcul de la sélectivité d'une requête impliquant des colonnes
     fonctionnellement dépendantes, le planificateur ajoute l'estimation de
     sélectivité par condition en utilisant les cœfficients de dépendance
     afin de ne pas produire de résultats sous-estimés.
    </para>

    <sect4>
     <title>Limites des dépendances fonctionnelles</title>

     <para>
      Les dépendances fonctionnelles sont pour le moment uniquement appliquées
      pour les conditions sur une simple égalité entre une colonne et une
      valeur constante et des clauses <literal>IN</literal> contenant des
      valeurs constantes. Elles ne sont pas utilisées pour améliorer
      l'estimation sur les conditions d'égalité entre deux colonnes ou la
      comparaison d'une colonne avec une expression ni pour les clauses
      d'intervalle, <literal>LIKE</literal> ou tout autre type de condition.
     </para>

     <para>
      Lors d'une estimation avec des dépendances fonctionnelles, l'optimiseur
      part du principe que les conditions sur les colonnes impliquées sont
      compatibles et donc redondantes. Si elles sont incompatibles,
      l'estimation correcte devrait être zéro ligne, mais cette possibilité
      n'est pas envisagée. Par exemple, dans une requête telle que

      <programlisting>SELECT * FROM zipcodes WHERE city = 'San Francisco' AND zip = '94105';</programlisting>

      l'optimiseur négligera la clause <structfield>city</structfield>
      puisqu'elle ne changera pas la sélectivité, ce qui est correct. Par
      contre, il fera la même supposition pour

      <programlisting>SELECT * FROM zipcodes WHERE city = 'San Francisco' AND zip = '90210';</programlisting>

      bien qu'il n'y ait en réalité aucune ligne satisfaisant cette requête.
      Toutefois, les statistiques de dépendances fonctionnelles ne
      fournissent pas suffisamment d'information pour en arriver à cette
      conclusion.
     </para>

     <para>
      Pour beaucoup de situations pratiques, cette supposition est
      généralement correcte&nbsp;; par exemple, l'application pourrait
      contenir une interface graphique qui n'autorise que la sélection de
      villes et codes postaux compatibles pour l'utilisation dans une
      requête. Mais si ce n'est pas le cas, les dépendances fonctionnelles
      pourraient ne pas être une solution viable.
     </para>
    </sect4>
   </sect3>

   <sect3>
    <title>Nombre N-Distinct multivarié</title>

    <para>
     Les statistiques sur une seule colonne stockent le nombre de valeurs
     distinctes pour chaque colonne. Les estimations du nombre de valeurs
     distinctes combinant plus d'une colonne (par exemple, pour
     <literal>GROUP BY a, b</literal>) sont souvent fausses quand
     l'optimiseur ne dispose que de données statistiques par colonne, avec
     pour conséquence le choix de mauvais plans.
    </para>

    <para>
     Afin d'améliorer de telles estimations, <command>ANALYZE</command> peut
     collecter des statistiques n-distinct pour des groupes de colonne. Comme
     précédemment, il n'est pas envisageable de le faire pour tous les
     regroupements possibles, ainsi les données ne sont collectées que pour
     ceux apparaissant ensemble dans un objet statistique défini avec
     l'option <literal>ndistinct</literal>. Des données seront collectées
     pour chaque combinaison possible de deux colonnes ou plus dans
     l'ensemble de colonnes listées.
    </para>

    <para>
     En continuant avec l'exemple précédent, le nombre n-distinct dans une
     table de code postaux pourrait ressembler à ceci&nbsp;:

     <programlisting>CREATE STATISTICS stts2 (ndistinct) ON city, state, zip FROM zipcodes;

ANALYZE zipcodes;

SELECT stxkeys AS k, stxdndistinct AS nd
  FROM pg_statistic_ext join pg_statistic_ext_data on (oid = stxoid)
  WHERE stxname = 'stts2';
-[ RECORD 1 ]--------------------------------------------------------
k  | 1 2 5
nd | {"1, 2": 33178, "1, 5": 33178, "2, 5": 27435, "1, 2, 5": 33178}
(1 row)</programlisting>

     Cela indique qu'il y a trois combinaisons de colonnes qui ont 33178
     valeurs distinctes&nbsp;: le code postal et l'état&nbsp;; le code postal
     et la ville&nbsp;; et le code postal, la ville et l'état (le fait qu'ils
     soient tous égaux est attendu puisque le code postal seul est unique
     dans cette table). D'un autre côté, la combinaison de la ville et de
     l'état n'a que 27435 valeurs distinctes.
    </para>

    <para>
     Il est conseillé de créer des objets statistiques
     <literal>ndistinct</literal> uniquement sur les combinaisons de colonnes
     réellement utilisées pour des regroupements, et pour lesquelles les
     mauvaises estimations du nombre de groupe a pour conséquence de mauvais
     plans. Sinon le temps consommé par <command>ANALYZE</command> serait
     gaspillé.
    </para>
   </sect3>

   <sect3>
    <title>Listes multivariées MCV</title>

    <para>
     Un autre type de statistiques enregistrées pour chaque colonne est les
     listes des valeurs les plus communes. Ceci permet des estimations très
     précises pour les colonnes individuelles, mais pourrait résulter en des
     estimations significativement mauvaises pour les requêtes ayant des
     filtres sur plusieurs colonnes.
    </para>

    <para>
     Pour améliorer ces estimations, <command>ANALYZE</command> peut récupérer
     des listes MCV sur des combinaisons de colonnes. De façon similaire aux
     dépendances fonctionnelles et coefficients de valeurs distinctes, il
     n'est pas possible de le faire pour chaque regroupement de colonnes.
     Ceci est encore plus vrai dans ce cas, car la liste MCV
     (contrairement aux dépendances fonctionnelles et coefficients de valeurs
     distinctes), enregistre les valeurs les plus communes. Donc les données
     ne sont récupérées que pour les groupes de colonnes apparaissant dans un
     objet statistique défini avec l'option <literal>mcv</literal>.
    </para>

    <para>
     En continuant sur l'exemple précédent, la liste MCV pour une table de
     codes ZIP pourrait ressembler à ce qui suit (contrairement aux types
     plus simples de statistiques, une fonction est requise pour inspecter le
     contenu du MCV)&nbsp;:

     <programlisting>CREATE STATISTICS stts3 (mcv) ON city, state FROM zipcodes;

ANALYZE zipcodes;

SELECT m.* FROM pg_statistic_ext join pg_statistic_ext_data on (oid = stxoid),
                pg_mcv_list_items(stxdmcv) m WHERE stxname = 'stts3';

 index |         values         | nulls | frequency | base_frequency
-------+------------------------+-------+-----------+----------------
     0 | {Washington, DC}       | {f,f} |  0.003467 |        2.7e-05
     1 | {Apo, AE}              | {f,f} |  0.003067 |        1.9e-05
     2 | {Houston, TX}          | {f,f} |  0.002167 |       0.000133
     3 | {El Paso, TX}          | {f,f} |     0.002 |       0.000113
     4 | {New York, NY}         | {f,f} |  0.001967 |       0.000114
     5 | {Atlanta, GA}          | {f,f} |  0.001633 |        3.3e-05
     6 | {Sacramento, CA}       | {f,f} |  0.001433 |        7.8e-05
     7 | {Miami, FL}            | {f,f} |    0.0014 |          6e-05
     8 | {Dallas, TX}           | {f,f} |  0.001367 |        8.8e-05
     9 | {Chicago, IL}          | {f,f} |  0.001333 |        5.1e-05
   ...
(99 rows)</programlisting>

     Ceci indique que la combinaison la plus commune des colonnes city et
     state est Washington DC, avec la fréquence réelle (dans cet exemple) de
     0,35&nbsp;%. La fréquence de base de la combinaison (telle qu'elle est
     calculée par les fréquences par mono colonne) est seulement de
     0,0027&nbsp;%, résultant en une sous-estimation très forte.
    </para>

    <para>
     Il est préférable de créer des objets statistiques <acronym>MCV</acronym>
     uniquement sur les combinaisons de colonnes réellement utilisées
     ensemble dans des filtres et pour lesquelles la mauvaise estimation du
     nombre de groupes a pour conséquence de mauvais plans. Dans le cas
     contraire, le <command>ANALYZE</command> et le temps de planification
     sont juste gâchés.
    </para>
   </sect3>
  </sect2>
 </sect1>

 <sect1 id="explicit-joins">
  <title>Contrôler le planificateur avec des clauses <literal>JOIN</literal>
   explicites</title>

  <indexterm zone="explicit-joins">
   <primary>jointure</primary>
   <secondary>contrôlant l'ordre</secondary>
  </indexterm>

  <para>
   Il est possible de contrôler le planificateur de requêtes jusqu'à un certain
   point en utilisant une syntaxe <literal>JOIN</literal> explicite. Pour
   voir en quoi ceci est important, nous avons besoin d'un peu de théorie.
  </para>

  <para>
   Dans une simple requête de jointure, telle que&nbsp;:

   <programlisting>SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;</programlisting>

   le planificateur est libre de joindre dans n'importe quel ordre les tables indiquées.
   Par exemple, il peut générer un plan de requête joignant
   A à B par la condition <literal>WHERE</literal> <literal>a.id =
   b.id</literal>, puis joignant C à cette table jointe par
   l'autre condition <literal>WHERE</literal>. Ou il peut joindre B à C,
   puis le résultat avec A. Ou il peut joindre A
   à C, puis les joindre avec B, mais cela serait inefficace, puisque
   le produit cartésien complet de A et C devra être formé alors qu'il n'y a
   pas de condition applicable dans la clause <literal>WHERE</literal> pour
   optimiser cette jointure. (Toutes les jointures dans
   l'exécuteur <productname>PostgreSQL</productname> se produisent entre deux
   tables, il est donc nécessaire de construire le résultat de
   l'une ou de l'autre de ces façons). Le point important est que ces
   différentes possibilités de jointures donnent des résultats sémantiquement
   équivalents, mais peuvent avoir des coûts d'exécution extrêmement
   différents. Le planificateur va donc toutes les explorer pour trouver
   le plan de requête le plus efficace.
  </para>

  <para>
   Quand une requête n'implique que deux ou trois tables, il y a peu
   d'ordres de jointures à considérer. Mais le nombre d'ordres de jointures
   possibles grandit de façon exponentielle quand le nombre
   de tables augmente. Au-delà d'environ dix tables en entrée, il n'est plus
   possible de faire une recherche exhaustive de toutes les possibilités, et
   même la planification de six ou sept tables peut prendre une durée gênante.
   Avec trop de tables en entrée, le planificateur
   <productname>PostgreSQL</productname> basculera d'une recherche exhaustive
   à une recherche <firstterm>génétique</firstterm> probabiliste depuis un
   nombre limité de possibilités (la limite de bascule est définie par le
   paramètre <xref linkend="guc-geqo-threshold"/>). La recherche
   génétique prend moins de temps, mais elle ne trouvera pas nécessairement
   le meilleur plan possible.
  </para>

  <para>
   Quand la requête implique des jointures externes, le planificateur est
   moins libre qu'avec des jointures internes. Par exemple,
   considérez&nbsp;:

   <programlisting>SELECT * FROM a LEFT JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);</programlisting>

   Bien qu'à première vue les conditions de cette requête semblent
   similaires à l'exemple précédent, les sémantiques sont différentes, car
   une ligne doit être émise pour chaque ligne de A qui sans ligne
   correspondante dans la jointure entre B et C. Le planificateur n'a alors
   pas le choix dans l'ordre de la jointure &nbsp;: ici, il doit joindre B
   à C, puis joindre A au résultat. En conséquence, cette requête prend moins de
   temps à planifier que la requête précédente. Dans d'autres cas, le
   planificateur peut arriver à déterminer que plus d'un ordre de
   jointure est sûr. Par exemple, étant donné&nbsp;:

   <programlisting>SELECT * FROM a LEFT JOIN b ON (a.bid = b.id) LEFT JOIN c ON (a.cid = c.id);</programlisting>

   il est valide de joindre A en premier soit à B, soit à C. Actuellement, seul
   un <literal>FULL JOIN</literal> contraint complètement l'ordre de
   jointure. En pratique, la plupart des cas impliquant un <literal>LEFT
   JOIN</literal> ou un <literal>RIGHT JOIN</literal> peuvent être réarrangés
   jusqu'à un certain degré.
  </para>

  <para>
   Sémantiquement, la syntaxe d'une jointure interne explicite (<literal>INNER JOIN</literal>,
   <literal>CROSS JOIN</literal> ou <literal>JOIN</literal>) revient
   à lister les relations en entrée du
   <literal>FROM</literal>, donc sans contraindre l'ordre de la jointure.
  </para>

  <para>
   Même si la plupart des types de <literal>JOIN</literal> ne sont pas complètement
   contraignantes pour l'ordre de jointure, il est possible de forcer le
   planificateur de requête de <productname>PostgreSQL</productname>
   de les considérer comme contraignantes.
   Par exemple, ces trois
   requêtes sont logiquement équivalentes&nbsp;:

   <programlisting>SELECT * FROM a, b, c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a CROSS JOIN b CROSS JOIN c WHERE a.id = b.id AND b.ref = c.id;
SELECT * FROM a JOIN (b JOIN c ON (b.ref = c.id)) ON (a.id = b.id);</programlisting>

   Mais si nous disons au planificateur d'honorer l'ordre des
   <literal>JOIN</literal>, la deuxième et la troisième prendront moins de
   temps à planifier que la première. Cet effet n'est pas inquiétant pour
   seulement trois tables, mais cela pourrait bien nous aider avec un nombre
   important de tables.
  </para>

  <para>
   Pour forcer le planificateur à suivre l'ordre de jointure des
   <literal>JOIN</literal> explicites, passez le paramètre
   <xref linkend="guc-join-collapse-limit"/> à 1 (d'autres valeurs possibles
   sont discutées plus bas).
  </para>

  <para>
   Vous n'avez pas besoin de restreindre l'ordre de jointure pour diminuer le
   temps de recherche car il est correct d'utiliser des opérateurs
   <literal>JOIN</literal> parmi les éléments d'une liste
   <literal>FROM</literal>. Par exemple, considérez&nbsp;:

<programlisting>SELECT * FROM a CROSS JOIN b, c, d, e WHERE ...;</programlisting>

   Avec <varname>join_collapse_limit</varname> = 1, le planificateur est
   forcé de joindre A à B avant la jointure aux autres tables, mais
   sans restreindre ses choix par ailleurs. Dans cet exemple, le nombre d'ordres de
   jointures possibles est réduit par un facteur de cinq.
  </para>

  <para>
   Cette technique pour restreindre la recherche du planificateur peut servir à
   réduire les temps de planification et aiguiller le
   planificateur vers un bon plan de requête. Si le planificateur choisit spontanément un
   mauvais ordre de jointure, vous pouvez le forcer à choisir un
   meilleur via la syntaxe <literal>JOIN</literal> &mdash; à supposer
   que vous connaissiez un meilleur ordre. Il faut tester.
  </para>

  <para>
   Un problème très proche et affectant le temps de planification est le
   regroupement de sous-requêtes dans leurs requêtes parentes. Par exemple,
   considérez&nbsp;:

   <programlisting>SELECT *
FROM x, y,
    (SELECT * FROM a, b, c WHERE quelquechose) AS ss
WHERE quelquechosedautre;</programlisting>

   Cette situation peut apparaître lors de l'utilisation d'une vue contenant
   une jointure&nbsp;; la règle <literal>SELECT</literal> de la vue sera
   insérée à la place de la référence de la vue, produisant une requête
   comme celle ci-dessus. Normalement, le planificateur essaiera
   de regrouper la sous-requête avec son parent, donnant&nbsp;:

   <programlisting>SELECT * FROM x, y, a, b, c WHERE quelquechose AND quelquechosedautre;</programlisting>

   Ceci donne généralement un meilleur plan que planifier séparément
   la sous-requête. (Par exemple, grâce aux clauses <literal>WHERE</literal>
   externes, joindre X à A peut éliminer d'entrée
   un bon nombre de lignes de A, évitant ainsi le besoin de générer la
   totalité de la sous-requête). Mais en même temps, nous avons accru le
   temps de planification&nbsp;; ici, nous avons un problème de jointure à
   cinq tables remplaçant un problème de deux jointures séparées à trois
   tables. À cause de l'augmentation exponentielle du nombre de possibilités,
   ceci fait une grande différence. Le planificateur essaie d'éviter de se
   retrouver coincé dans des problèmes de recherche de grosses jointures en
   ne regroupant pas une sous-requête si plus de
   <varname>from_collapse_limit</varname> éléments sont la résultante de la
   requête parent. Vous pouvez arbitrer entre le temps de planification et la
   qualité du plan en ajustant ce paramètre à la hausse ou à la baisse.
  </para>

  <para>
   <xref linkend="guc-from-collapse-limit"/> et <xref
   linkend="guc-join-collapse-limit"/> sont nommés de façon similaire car
   ils font pratiquement la même chose&nbsp;: le premier contrôle le
   moment où le planificateur <quote>aplatira</quote> les sous-requêtes, et
   le second contrôle quand aplatir les jointures explicites.
   Typiquement, vous définirez <varname>join_collapse_limit</varname>
   à la même valeur que <varname>from_collapse_limit</varname> (de façon à ce que les
   jointures explicites et les sous-requêtes agissent de la même façon) ou
   vous affecterez <varname>join_collapse_limit</varname> à 1 (si vous
   voulez contrôler l'ordre de jointure par des jointures explicites). Mais vous
   pouvez les définir différemment en essayant de configurer
   finement la relation entre le temps de planification et le temps
   d'exécution.
  </para>
 </sect1>

 <sect1 id="populate">
  <title>Remplir une base de données</title>

  <para>
   Vous pourriez avoir besoin d'insérer un grand nombre de données pour
   remplir une base de données tout au début. Cette section contient quelques
   suggestions pour réaliser cela de la façon la plus efficace.
  </para>

  <sect2 id="disable-autocommit">
   <title>Désactivez la validation automatique (autocommit)</title>

   <indexterm>
    <primary>autocommit</primary>
    <secondary>gros chargement de données</secondary>
   </indexterm>

   <para>
    Lors d'<command>INSERT</command> multiples, désactivez la validation
    automatique et faites une seule validation à la fin (en SQL, ceci
    signifie de lancer <command>BEGIN</command> au début et
    <command>COMMIT</command> à la fin. Quelques bibliothèques client
    pourraient le faire derrière votre dos, auquel cas vous devez vous
    assurer que la bibliothèque le fait quand vous le voulez). Si vous
    permettez à chaque insertion d'être validée séparément,
    <productname>PostgreSQL</productname> fait un gros travail pour chaque
    ligne ajoutée. Un bénéfice supplémentaire de réaliser toutes les
    insertions dans une seule transaction est que si l'insertion d'une ligne
    échoue alors les lignes insérées jusqu'à maintenant seront annulées. Vous
    ne serez donc pas bloqué avec des données partiellement chargées.
   </para>
  </sect2>

  <sect2 id="populate-copy-from">
   <title>Utilisez <command>COPY</command></title>

   <para>
    Utilisez l'instruction <link
    linkend="sql-copy"><command>COPY</command></link> pour charger toutes les
    lignes en une seule commande, plutôt que d'utiliser une série de
    commandes <command>INSERT</command>. La commande <command>COPY</command>
    est optimisée pour charger un grand nombre de lignes&nbsp;; elle est
    moins flexible que <command>INSERT</command>, mais introduit
    significativement moins de surcharge lors du chargement de grosses
    quantités de données. Comme <command>COPY</command> est une seule
    commande, il n'y a pas besoin de désactiver la validation automatique
    (autocommit) si vous utilisez cette méthode pour remplir une table.
   </para>

   <para>
    Si vous ne pouvez pas utiliser <command>COPY</command>, utilisez <link
    linkend="sql-prepare"><command>PREPARE</command></link> pour créer une
    instruction préparée <command>INSERT</command>, puis utilisez
    <command>EXECUTE</command> autant de fois que nécessaire. Ceci évite
    certaines surcharges lors d'une analyse et d'une planification répétées
    de commandes <command>INSERT</command>. Différentes interfaces
    fournissent cette fonctionnalité de plusieurs façons&nbsp;; recherchez
    <quote>instructions préparées</quote> dans la documentation de
    l'interface.
   </para>

   <para>
    Notez que charger un grand nombre de lignes en utilisant
    <command>COPY</command> est pratiquement toujours plus rapide que
    d'utiliser <command>INSERT</command>, même si <command>PREPARE ...
    INSERT</command> est utilisé lorsque de nombreuses insertions sont
    groupées en une seule transaction.
   </para>

   <para>
    <command>COPY</command> est plus rapide quand il est utilisé dans la même
    transaction que la commande <command>CREATE TABLE</command> ou
    <command>TRUNCATE</command> précédente. Dans ce cas, les journaux de
    transactions ne sont pas impactés, car, en cas d'erreur, les fichiers
    contenant les données nouvellement chargées seront supprimés de toute
    façon. Néanmoins, cette considération ne s'applique que quand <xref
    linkend="guc-wal-level"/> vaut <literal>minimal</literal> car toutes les
    commandes doivent écrire dans les journaux de transaction dans les autres
    cas.
   </para>
  </sect2>

  <sect2 id="populate-rm-indexes">
   <title>Supprimez les index</title>

   <para>
    Si vous chargez une table tout juste créée, la méthode la plus rapide est
    de créer la table, de charger en lot les données de cette table en
    utilisant <command>COPY</command>, puis de créer tous les index
    nécessaires pour la table. Créer un index sur des données déjà existantes
    est plus rapide que de mettre à jour de façon incrémentale à chaque ligne
    ajoutée.
   </para>

   <para>
    Si vous ajoutez beaucoup de données à une table existante, il pourrait
    être avantageux de supprimer les index, de charger la table, puis de
    recréer les index. Bien sûr, les performances de la base de données pour
    les autres utilisateurs pourraient souffrir tout le temps où les index
    seront manquants. Vous devez aussi y penser à deux fois avant de
    supprimer des index uniques, car la vérification d'erreur apportée par la
    contrainte unique sera perdue tout le temps où l'index est manquant.
   </para>
  </sect2>

  <sect2 id="populate-rm-fkeys">
   <title>Suppression des contraintes de clés étrangères</title>

   <para>
    Comme avec les index, une contrainte de clé étrangère peut être vérifiée
    <quote>en gros volume</quote> plus efficacement que ligne par ligne.
    Donc, il pourrait être utile de supprimer les contraintes de clés
    étrangères, de charger les données et de créer de nouveau les
    contraintes. De nouveau, il y a un compromis à faire entre la vitesse de
    chargement des données et la perte de la vérification des erreurs lorsque
    la contrainte manque.
   </para>

   <para>
    De plus, quand vous chargez des données dans une table contenant des
    contraintes de clés étrangères, chaque nouvelle ligne requiert une entrée
    dans la liste des événements de déclencheur en attente(puisque c'est le
    lancement d'un déclencheur qui vérifie la contrainte de clé étrangère de
    la ligne). Le chargement de plusieurs millions de lignes peut amener la
    taille de la file d'attente des déclencheurs à dépasser la mémoire
    disponible, causant ainsi une mise en mémoire swap intolérable, voire
    l'échec de la commande. Dans ce cas, il peut être
    <emphasis>nécessaire</emphasis>, pas seulement souhaitable, de supprimer
    et recréer la clé étrangère lors de chargements de grandes quantités de
    données. Si la suppression temporaire de la contrainte n'est pas
    acceptable, le seul recours possible est de découper les opérations de
    chargement en de plus petites transactions.
   </para>
  </sect2>

  <sect2 id="populate-work-mem">
   <title>Augmentez <varname>maintenance_work_mem</varname></title>

   <para>
    Augmenter temporairement la variable <xref
    linkend="guc-maintenance-work-mem"/> lors du chargement de grosses
    quantités de données peut amener une amélioration des performances. Ceci
    aidera à l'accélération des commandes <command>CREATE INDEX</command> et
    <command>ALTER TABLE ADD FOREIGN KEY</command>. Cela ne changera pas
    grand-chose pour la commande <command>COPY</command>. Donc, ce conseil
    est seulement utile quand vous utilisez une des deux ou les deux
    techniques ci-dessus.
   </para>
  </sect2>

  <sect2 id="populate-max-wal-size">
   <title>Augmenter <varname>max_wal_size</varname></title>

   <para>
    Augmenter temporairement la variable de configuration <xref
    linkend="guc-max-wal-size"/> peut aussi aider à un chargement rapide de
    grosses quantités de données. Ceci est dû au fait que charger une grosse
    quantité de données dans <productname>PostgreSQL</productname> causera la
    venue très fréquente de checkpoints (la fréquence de ces checkpoints est
    spécifiée par la variable de configuration
    <varname>checkpoint_timeout</varname>). Quand survient un checkpoint,
    toutes les pages modifiées sont écrites sur disque. En augmentant
    <varname>max_wal_size</varname> temporairement lors du chargement des
    données, le nombre de checkpoints requis peut être significativement
    diminué.
   </para>
  </sect2>

  <sect2 id="populate-pitr">
   <title>Désactiver l'archivage des journaux de transactions et la
     réplication en flux</title>

   <para>
    Lors du chargement de grosse quantité de données dans une instance qui
    utilise l'archivage des journaux de transactions ou la réplication en
    flux, il pourrait être plus rapide de prendre une nouvelle sauvegarde de
    base après que le chargement ait terminé, plutôt que de traiter une
    grosse quantité de données incrémentales dans les journaux de
    transactions. Pour empêcher un accroissement de la journalisation des
    transactions lors du chargement, vous pouvez désactiver l'archivage et la
    réplication en flux lors du chargement en configurant <xref
    linkend="guc-wal-level"/> à <literal>minimal</literal>, <xref
    linkend="guc-archive-mode"/> à <literal>off</literal> et <xref
    linkend="guc-max-wal-senders"/> à zéro). Mais notez que le changement de
    ces paramètres requiert un redémarrage du serveur, et rends toute
    sauvegarde de base réalisée auparavant inutilisable pour la restauration
    par archives et pour créer un serveur secondaire, ce qui pourrait amener
    à des pertes de données.
   </para>

   <para>
    En dehors d'éviter le temps de traitement des données des journaux de
    transactions par l'archiveur ou l'émetteur des journaux de transactions,
    ce paramétrage accélérera certaines commandes où la sous-transaction
    (ou transaction de plus haut niveau) courante crée ou tronque une table
    ou un index&nbsp;: elles n'écriront pas du tout dans les journaux de
    transactions si <varname>wal_level</varname> vaut
    <literal>minimal</literal>. (Elles peuvent garantir la sûreté des données
    de façon moins coûteuse en exécutant un <function>fsync</function> à la
    fin plutôt qu'en écrivant les journaux de transactions.)
   </para>
  </sect2>

  <sect2 id="populate-analyze">
   <title>Lancez <command>ANALYZE</command> après</title>

   <para>
    Quand vous avez changé significativement la distribution des données à
    l'intérieur d'une table, exécuter <link
    linkend="sql-analyze"><command>ANALYZE</command></link> est fortement
    recommandé. Ceci inclut le chargement de grosses quantités de données
    dans la table.
    Exécuter <command>ANALYZE</command> (ou <command>VACUUM
    ANALYZE</command>) vous assure que le planificateur dispose de
    statistiques à jour sur la table. Sans statistiques ou avec des
    statistiques obsolètes, le planificateur pourrait prendre de mauvaises
    décisions lors de la planification de la requête, amenant des
    performances pauvres sur toutes les tables sans statistiques ou avec des
    statistiques inexactes. Notez que si le démon autovacuum est activé, il
    pourrait exécuter <command>ANALYZE</command> automatiquement&nbsp;; voir
    <xref linkend="vacuum-for-statistics"/> et <xref linkend="autovacuum"/>
    pour plus d'informations.
   </para>
  </sect2>

  <sect2 id="populate-pg-dump">
   <title>Quelques notes sur <application>pg_dump</application></title>

   <para>
    Les scripts de sauvegarde générés par <application>pg_dump</application>
    appliquent automatiquement plusieurs des indications ci-dessus, mais pas
    toutes. Pour recharger une sauvegarde <application>pg_dump</application>
    aussi rapidement que possible, vous avez besoin de faire quelques étapes
    supplémentaires manuellement (notez que ces points s'appliquent lors de
    la <emphasis>restauration</emphasis> d'une sauvegarde, et non pas lors de
    sa <emphasis>création</emphasis>. Les mêmes points s'appliquent soit lors
    de la restauration d'une sauvegarde texte avec
    <application>psql</application> soit lors de l'utilisation de
    <application>pg_restore</application> pour charger un fichier de
    sauvegarde <application>pg_dump</application>).
   </para>

   <para>
    Par défaut, <application>pg_dump</application> utilise
    <command>COPY</command> et, lorsqu'il génère une sauvegarde complexe,
    schéma et données, il est préférable de charger les données avant de
    créer les index et les clés étrangères. Donc, dans ce cas, plusieurs
    lignes de conduite sont gérées automatiquement. Ce qui vous reste à faire
    est de&nbsp;:

    <itemizedlist>
     <listitem>
      <para>
       Configurer des valeurs appropriées (c'est-à-dire plus importantes que
       la normale) pour <varname>maintenance_work_mem</varname> et
       <varname>max_wal_size</varname>.
      </para>
     </listitem>

     <listitem>
      <para>
       Si vous utilisez l'archivage des journaux de transactions ou la
       réplication en flux, considérez leur désactivation lors de la
       restauration. Pour faire cela, configurez
       <varname>archive_mode</varname> à <literal>off</literal>,
       <varname>wal_level</varname> à <literal>minimal</literal> et
       <varname>max_wal_senders</varname> à zéro avant de charger le script
       de sauvegarde. Après coup, remettez les anciennes valeurs et effectuez
       une nouvelle sauvegarde de base.
      </para>
     </listitem>

     <listitem>
      <para>
       Tester le mode parallélisé de la sauvegarde et de la restauration des
       outils <application>pg_dump</application> et
       <application>pg_restore</application>, et trouver le nombre optimal de
       tâches parallélisées à utiliser. La sauvegarde et la restauration en
       parallèle avec l'option <option>-j</option> devraient vous donner de
       meilleures performances.
      </para>
     </listitem>

     <listitem>
      <para>
       Se demander si la sauvegarde complète doit être restaurée dans une
       seule transaction. Pour cela, passez l'option <option>-1</option> ou
       <option>--single-transaction</option> à
       <application>psql</application> ou
       <application>pg_restore</application>. Lors de l'utilisation de ce
       mode, même les erreurs les plus petites annuleront la restauration
       complète, peut-être en annulant des heures de traitements. Suivant à
       quel point les données sont en relation, il peut être préférable de
       faire un nettoyage manuel. Les commandes <command>COPY</command>
       s'exécuteront plus rapidement si vous utilisez une transaction simple
       et que vous avez désactivé l'archivage des journaux de transaction.
      </para>
     </listitem>

     <listitem>
      <para>
       Si plusieurs processeurs sont disponibles sur le serveur, penser à
       utiliser l'option <option>--jobs</option> de
       <application>pg_restore</application>. Cela permet la parallélisation
       du chargement des données et de la création des index.
      </para>
     </listitem>

     <listitem>
      <para>
       Exécuter <command>ANALYZE</command> après coup.
      </para>
     </listitem>
    </itemizedlist>
   </para>

   <para>
    Une sauvegarde des données seules utilise toujours
    <command>COPY</command>, mais elle ne supprime ni ne recrée les index et
    elle ne touche généralement pas les clés étrangères.

     <footnote>
      <para>
       Vous pouvez obtenir l'effet de désactivation des clés étrangères en
       utilisant l'option <option>--disable-triggers</option> &mdash; mais
       réalisez que cela élimine, plutôt que repousse, la validation des clés
       étrangères et qu'il est du coup possible d'insérer des données
       mauvaises si vous l'utilisez.
      </para>
     </footnote>
    Donc, lorsque vous chargez une sauvegarde ne contenant que les données,
    c'est à vous de supprimer et recréer les index et clés étrangères si vous
    souhaitez utiliser ces techniques. Il est toujours utile d'augmenter
    <varname>max_wal_size</varname> lors du chargement des données, mais ne
    vous embêtez pas à augmenter
    <varname>maintenance_work_mem</varname>&nbsp;; en fait, vous le ferez
    lors d'une nouvelle création manuelle des index et des clés étrangères.
    Et n'oubliez pas <command>ANALYZE</command> une fois que vous avez
    terminé&nbsp;; voir <xref linkend="vacuum-for-statistics"/> et <xref
    linkend="autovacuum"/> pour plus d'informations.
   </para>
  </sect2>
 </sect1>

 <sect1 id="non-durability">
  <title>Configuration avec une perte acceptée</title>

  <indexterm zone="non-durability">
   <primary>perte acceptée</primary>
  </indexterm>

  <para>
   La durabilité est une fonctionnalité des serveurs de bases de données
   permettant de garantir l'enregistrement des transactions validées même si
   le serveur s'arrête brutalement, par exemple en cas de coupure électrique.
   Néanmoins, la durabilité ajoute une surcharge significative. Si votre base
   de données n'a pas besoin de cette garantie,
   <productname>PostgreSQL</productname> peut être configuré pour fonctionner
   bien plus rapidement. Voici des modifications de configuration que vous
   pouvez faire pour améliorer les performances dans ce cas. Sauf indication
   contraire, la durabilité des transactions est garantie dans le cas d'un
   crash du serveur de bases de données&nbsp;; seul un arrêt brutal du
   système d'exploitation crée un risque de perte de données ou de corruption
   quand ces paramètres sont utilisés.

   <itemizedlist>
    <listitem>
     <para>
      Placer le répertoire des données dans un système de fichiers en mémoire
      (par exemple un disque <acronym>RAM</acronym>). Ceci élimine toutes les
      entrées/sorties disque de la base de données. Cela limite aussi la
      quantité de mémoire disponible (et peut-être aussi du swap).
     </para>
    </listitem>

    <listitem>
     <para>
      Désactiver <xref linkend="guc-fsync"/>&nbsp;; il n'est pas nécessaire
      d'écrire les données sur disque.
     </para>
    </listitem>

     <listitem>
      <para>
       Désactiver <xref linkend="guc-synchronous-commit"/>&nbsp;; il n'est pas
       forcément nécessaire d'écrire les journaux de transactions
       <acronym>WAL</acronym> à chaque validation de transaction. Ce
       paramètre engendre un risque de perte de transactions (mais pas de
       corruption de données) dans le cas d'un arrêt brutal de la
       <emphasis>base de données</emphasis>.
      </para>
     </listitem>

     <listitem>
      <para>
       Désactiver <xref linkend="guc-full-page-writes"/>&nbsp;; il n'est pas
       nécessaire de se prémunir contre les écritures de pages partielles.
      </para>
     </listitem>

     <listitem>
      <para>
       Augmenter <xref linkend="guc-max-wal-size"/> et <xref
       linkend="guc-checkpoint-timeout"/>&nbsp;; cela réduit les fréquences
       des checkpoints, mais augmente l'espace disque nécessaire dans
       <filename>pg_wal</filename>.
      </para>
     </listitem>

     <listitem>
      <para>
       Créer des <link linkend="sql-createtable-unlogged">tables non
       journalisées</link> pour éviter des écritures dans les journaux de
       transactions (<acronym>WAL</acronym>), bien que cela rende les tables
       non résistantes à un arrêt brutal.
      </para>
     </listitem>
    </itemizedlist>
   </para>
  </sect1>
</chapter>
