<?xml version="1.0" encoding="UTF-8"?>
<!-- Dernière modification
     le       $Date$
     par      $Author$
     révision $Revision$ -->

<sect1 id="monitoring">
<title>Surveillance</title>
<indexterm><primary>Surveiller &slony1;</primary></indexterm>

<para> As a prelude to the discussion, it is worth pointing out that
since the bulk of &slony1; functionality is implemented via running
database functions and SQL queries against tables within a &slony1;
schema, most of the things that one might want to monitor about
replication may be found by querying tables in the schema created for
the cluster in each database in the cluster. </para>

<para> Here are some of the tables that contain information likely to
be particularly interesting from a monitoring and diagnostic
perspective.</para>

<glosslist>
<glossentry><glossterm><envar>sl_status</envar></glossterm>

<glossdef><para>This view is the first, most obviously useful thing to
look at from a monitoring perspective.  It looks at the local node's
events, and checks to see how quickly they are being confirmed on
other nodes.</para>

<para> The view is primarily useful to run against an origin
(<quote>master</quote>) node, as it is only there where the events
generated are generally expected to require interesting work to be
done.  The events generated on non-origin nodes tend to
be <command>SYNC</command> events that require no replication work be
done, and that are nearly no-ops, as a
result. </para></glossdef></glossentry>

<glossentry><glossterm>&slconfirm;</glossterm>

<glossdef><para>Contains confirmations of replication events; this may be used to infer which events have, and <emphasis>have not</emphasis> been processed.</para></glossdef></glossentry>

<glossentry><glossterm>&slevent;</glossterm>
<glossdef><para>Contains information about the replication events processed on the local node.  </para></glossdef></glossentry>

<glossentry><glossterm>
&sllog1;
and
&sllog2;
</glossterm>

<glossdef><para>These tables contain replicable data.  On an origin node, this is the <quote>queue</quote> of data that has not necessarily been replicated everywhere.  By examining the table, you may examine the details of what data is replicable. </para></glossdef></glossentry>

<glossentry><glossterm>&slnode;</glossterm>
<glossdef><para>The list of nodes in the cluster.</para></glossdef></glossentry>

<glossentry><glossterm>&slpath;</glossterm>
<glossdef><para>This table holds connection information indicating how &lslon; processes are to connect to remote nodes, whether to access events, or to request replication data. </para></glossdef></glossentry>

<glossentry><glossterm>&sllisten;</glossterm>

<glossdef><para>This configuration table indicates how nodes listen
for events coming from other nodes.  Usually this is automatically
populated; generally you can detect configuration problems by this
table being <quote>underpopulated.</quote> </para></glossdef></glossentry>

<glossentry><glossterm>&slregistry;</glossterm>

<glossdef><para>A configuration table that may be used to store
miscellaneous runtime data.  Presently used only to manage switching
between the two log tables.  </para></glossdef></glossentry>

<glossentry><glossterm>&slseqlog;</glossterm>

<glossdef><para>Contains the <quote>last value</quote> of replicated
sequences.</para></glossdef></glossentry>

<glossentry><glossterm>&slset;</glossterm>

<glossdef><para>Contains definition information for replication sets,
which is the mechanism used to group together related replicable
tables and sequences.</para></glossdef></glossentry>

<glossentry><glossterm>&slsetsync;</glossterm>
<glossdef><para>Contains information about the state of synchronization of each replication set, including transaction snapshot data.</para></glossdef></glossentry>

<glossentry><glossterm>&slsubscribe;</glossterm>
<glossdef><para>Indicates what subscriptions are in effect for each replication set.</para></glossdef></glossentry>

<glossentry><glossterm>&sltable;</glossterm>
<glossdef><para>Contains the list of tables being replicated.</para></glossdef></glossentry>

</glosslist>

<sect2 id="testslonystate"> <title> test_slony_state</title>

<indexterm><primary>script test_slony_state to test replication state</primary></indexterm>

<para> This invaluable script does various sorts of analysis of the
state of a &slony1; cluster.  &slony1; <xref linkend="bestpractices"/>
recommend running these scripts frequently (hourly seems suitable) to
find problems as early as possible.  </para>

<para> You specify arguments including <option>database</option>,
<option>host</option>, <option>user</option>,
<option>cluster</option>, <option>password</option>, and
<option>port</option> to connect to any of the nodes on a cluster.
You also specify a <option>mailprog</option> command (which should be
a program equivalent to <productname>Unix</productname>
<application>mailx</application>) and a recipient of email. </para>

<para> You may alternatively specify database connection parameters
via the environment variables used by
<application>libpq</application>, <emphasis>e.g.</emphasis> - using
<envar>PGPORT</envar>, <envar>PGDATABASE</envar>,
<envar>PGUSER</envar>, <envar>PGSERVICE</envar>, and such.</para>

<para> The script then rummages through <xref linkend="table.sl-path"/>
to find all of the nodes in the cluster, and the DSNs to allow it to,
in turn, connect to each of them.</para>

<para> For each node, the script examines the state of things,
including such things as:

<itemizedlist>
<listitem><para> Checking <xref linkend="table.sl-listen"/> for some
<quote>analytically determinable</quote> problems.  It lists paths
that are not covered.</para></listitem>

<listitem><para> Providing a summary of events by origin node</para>

<para> If a node hasn't submitted any events in a while, that likely
suggests a problem.</para></listitem>

<listitem><para> Summarizes the <quote>aging</quote> of table <xref
linkend="table.sl-confirm"/> </para>

<para> If one or another of the nodes in the cluster hasn't reported
back recently, that tends to lead to cleanups of tables like &sllog1;,
&sllog2; and &slseqlog; not taking place.</para></listitem>

<listitem><para> Summarizes what transactions have been running for a
long time</para>

<para> This only works properly if the statistics collector is
configured to collect command strings, as controlled by the option
<option> stats_command_string = true </option> in <filename>
postgresql.conf </filename>.</para>

<para> If you have broken applications that hold connections open,
this will find them.</para>

<para> If you have broken applications that hold connections open,
that has several unsalutory effects as <link
linkend="longtxnsareevil"> described in the
FAQ</link>.</para></listitem>

</itemizedlist></para>

<para> The script does some diagnosis work based on parameters in the
script; if you don't like the values, pick your favorites!</para>

<note><para> Note that there are two versions, one using the
<quote>classic</quote> <filename>Pg.pm</filename> Perl module for
accessing &postgres; databases, and one, with <filename>dbi</filename>
in its name, that uses the newer Perl <function> DBI</function>
interface.  It is likely going to be easier to find packaging for
<function>DBI</function>. </para> </note>

</sect2>

<sect2>
<title>Tester la replication avec &nagios;</title>
<indexterm><primary>&nagios; pour surveiller la réplication</primary></indexterm>

<para>
  Le script <command>psql_replication_check.pl</command>, qui se trouve dans le
  répertoire <filename>tools</filename>, regroupe les meilleures tentatives de
  de tests utilisables par le système de surveillance <ulink
  url="http://www.nagios.org/">&nagios;</ulink>.
</para>

<para>
  Un script antérieur, nommé <filename>test_slony_replication.pl</filename>,
  utilisait une approche <quote>intelligente</quote>&nbsp;: un <quote>script de
  test</quote> est exécuté périodiquement et se déploie à travers les
  configurations &slony1; pour trouver l'origine et les abonnés, injecte un
  changement et observe sa propagation à travers le système. Il présentait deux
  problèmes&nbsp;:
</para>

<itemizedlist>
  <listitem>
    <para>
      En cas de problème de connectique impactant le n&oelig;ud qui jouait ce
      test, c'est l'ensemble de réplication qui semblait détruite. De plus,
      cette stratégie de surveillance est très fragile et dépend de nombreuses
      conditions d'erreurs.
    </para>
  </listitem>

  <listitem>
    <para>
      &nagios; n'a pas la possibilité de profiter de l'
      <quote>intelligence</quote> d'une exploration automatique d'un ensemble
      de n&oelig;uds. Vous devez mettre en place des règles de surveillance
      &nagios; pour chaque n&oelig;ud.
    </para>
  </listitem>
</itemizedlist>

<para>
  Le nouveau script, <command>psql_replication_check.pl</command>, utilise une
  approche minimaliste qui suppose que le système est un système en ligne
  recevant un <quote>trafic</quote> régulier, et vous permet de définir une vue
  spécifique pour le test de réplication appelée
  <envar>replication_status</envar> qui doit contenir des mises à jour
  régulières. Cette vue regarde simplement la dernière
  <quote>transaction</quote> sur le n&oelig;ud, et liste son horodatage, son
  âge ainsi que quelques informations sur l'application qui peuvent être
  utiles.
</para>

<itemizedlist>
  <listitem>
    <para>
      Pour un système d'inventaire, cela pourrait être le numéro de l'ordre
      effectué le plus récemment.
    </para>
  </listitem>

  <listitem>
    <para>
      Pour un serveur de nom de domaines, cela peut être le nom du dernier
      domaine créé.
    </para>
  </listitem>
</itemizedlist>

<para>
  Une instance du script doit être exécutée sur chaque n&oelig;ud
  surveillé&nbsp;; c'est ainsi que &nagios; fonctionne.
</para>

</sect2>

<sect2 id="slonymrtg">
<title>Surveiller &slony1; avec MRTG</title>
<indexterm><primary>Utiliser MRTG pour surveiller la réplication</primary></indexterm>

<para>
  Un utilisateur a expliqué sur la liste de discussion de &slony1; comment
  configurer <ulink url="http://people.ee.ethz.ch/~oetiker/webtools/mrtg/">
  <application>MRTG</application></ulink> (acronyme de «&nbsp;Multi Router
  Traffic Grapher&nbsp;») pour surveiller une réplication &slony1;.
</para>

<para>
  [...] puisque j'utilise <application>MRTG</application> pour visualiser les
  données depuis plusieurs serveurs, j'utilise SNMP
  (<application>net-snmp</application> pour être exact). Pour un serveur de
  bases de données, j'ai ajouté la ligne suivante à la configuration de
  <application>snmpd</application>&nbsp;:
</para>

<programlisting>
exec replicationLagTime  /cvs/scripts/snmpReplicationLagTime.sh 2
</programlisting>

<para>
  avec <filename>/cvs/scripts/snmpReplicationLagTime.sh</filename> contenant
  ceci&nbsp;:
</para>

<programlisting>
#!/bin/bash
/home/pgdba/work/bin/psql -U pgdba -h 127.0.0.1 -p 5800 -d _DBNAME_ -qAt -c
"select cast(extract(epoch from st_lag_time) as int8) FROM _irr.sl_status
WHERE st_received = $1"
</programlisting>

<para>
  Ensuite, dans la configuration de mrtg, j'ai ajouté la cible suivante&nbsp;:
</para>

<programlisting>
Target[db_replication_lagtime]:extOutput.3&amp;extOutput.3:public at db::30:::
MaxBytes[db_replication_lagtime]: 400000000
Title[db_replication_lagtime]: db: replication lag time
PageTop[db_replication_lagtime]: &lt;H1&gt;db: replication lag time&lt;/H1&gt;
Options[db_replication_lagtime]: gauge,nopercent,growright
</programlisting>

<para>
  De son coté, Ismail Yenigul propose une méthode pour surveiller
  &slony1; en utilisant <application>MRTG</application> sans installer
  <application>SNMPD</application>.
</para>

<para>
  Voici sa configuration MRTG&nbsp;:
</para>

<programlisting>
Target[db_replication_lagtime]:`/bin/snmpReplicationLagTime.sh 2`
MaxBytes[db_replication_lagtime]: 400000000
Title[db_replication_lagtime]: db: replication lag time
PageTop[db_replication_lagtime]: &lt;H1&gt;db: replication lag time&lt;/H1&gt;
Options[db_replication_lagtime]: gauge,nopercent,growright
</programlisting>

<para>
  Et voici sa version modifiée du script&nbsp;:
</para>

<programlisting>
# cat /bin/snmpReplicationLagTime.sh
#!/bin/bash

output=`/usr/bin/psql -U slony -h 192.168.1.1 -d endersysecm -qAt -c
"select cast(extract(epoch from st_lag_time) as int8) FROM _mycluster.sl_status WHERE st_received = $1"`
echo $output
echo $output
echo 
echo
# end of script#
</programlisting>

<note>
  <para>
    MRTG attend quatre lignes en provenance du script. Puisque le script n'en
    fournit que deux, la sortie doit être prolongée de deux lignes.
  </para>
</note>

</sect2>

<sect2 id="testslonystate">
<title>test_slony_state</title>
<indexterm><primary>script test_slony_state pour tester l'état de la réplication</primary></indexterm>

<para>
  Ce script effectue différents analyses sur l'état d'un cluster &slony1;.
</para>

<para>
  Vous devez spécifier les arguments tels que la <option>base de
  données</option>, l'<option>hôte</option>, l'<option>utilisateur</option>,
  le <option>cluster</option>, le <option>mot de passe</option> et le
  <option>port</option> afin de se connecter à n'importe quel n&oelig;ud du
  cluster. Vous devez également préciser une commande <option>mailprog</option>
  (qui doit être une commande équivalente à la commande
  <productname>Unix</productname> <application>mailx</application>) et une
  destination pour le courrier.
</para>

<para>
  Par ailleurs, vous spécifiez les paramètres de connexion aux bases de données
  via les variables d'environnement utilisées par
  <application>libpq</application>, <emphasis>par exemple</emphasis>&nbsp;:
  <envar>PGPORT</envar>, <envar>PGDATABASE</envar>, <envar>PGUSER</envar>,
  <envar>PGSERVICE</envar> et ainsi de suite.
</para>

<para>
  Le script se promène à travers <xref linkend="table.sl-path"/> pour trouver
  tous les n&oelig;uds du cluster et dans les DSNs qui lui permettront de se
  connecter à chaque n&oelig;ud.
</para>

<para>
  Pour chaque n&oelig;ud, le script examine l'état des données suivantes&nbsp;:
</para>

<itemizedlist>
  <listitem>
    <para>
      Vérification de <xref linkend="table.sl-listen"/> à la recherche de
      problèmes <quote>déterminés analytiquement</quote>. Cela liste les voies
      de communication qui ne sont pas couvertes.
    </para>
  </listitem>

  <listitem>
    <para>
      Effectuer un résumé des événements sur le n&oelig;ud d'origine.
    </para>

    <para>
      Si un n&oelig;ud n'a pas soumis un événement depuis longtemps, il y a
      certainement un problème.
    </para>
  </listitem>

  <listitem>
    <para>
      Vérification de <quote>l'âge</quote> de la table <xref
      linkend="table.sl-confirm"/>.
    </para>

    <para>
      Si un ou plusieurs n&oelig;uds du cluster n'ont pas envoyé de rapport
      récemment, alors cela peut conduire à l'absence de nettoyage dans
      certaines tables comme <xref linkend="table.sl-log-1"/> et <xref
      linkend="table.sl-seqlog"/>.
    </para>
  </listitem>

  <listitem>
    <para>
      Vérifications des transactions longues.
    </para>

    <para>
      Ceci ne fonctionne correctement que si le collecteur de statistique est
      configuré pour collecter les requêtes, c'est-à-dire l'option
      <option>stats_command_string = true</option> est présente dans
      <filename>postgresql.conf</filename>.
    </para>

    <para>
      Si des applications buggées conservent des connexions ouvertes, ce script
      devrait les trouver.
    </para>

    <para>
      Si des applications buggées conservent des connexions ouvertes, plusieurs
      effets négatifs sont à prévoir tels que <link
      linkend="longtxnsareevil">ceux décrits dans la FAQ</link>.
    </para>
  </listitem>
</itemizedlist>

<para>
  Ce script fait des diagnostiques basés sur des paramètres définis dans le
  script&nbsp;; si vous n'aimez pas les valeurs par défaut, modifiez-les&nbsp;!
</para>

</sect2>

<sect2 id="search-logs">
<title><command>search-logs.sh</command></title>
<indexterm><primary>chercher dans les journaux applicatifs &slony1; avec search-logs.sh</primary></indexterm>

<para>
  Ce script est construit pour chercher dans les journaux applicatifs &slony1;,
  à un emplacement donné (<envar>LOGHOME</envar>), en se basant à la fois
  sur les conventions de nommage utilisées par les systèmes <xref
  linkend="launchclusters"/> et <xref linkend="slonwatchdog"/> lors du
  démarrage des processus &lslon;.
</para>

<para>
  Si des erreurs sont trouvées, elles sont listées pour chaque fichier et
  transmises par courriel à un utilisateur spécifié
  (<envar>LOGRECIPIENT</envar>)&nbsp;; si aucun courriel n'est spécifié, le
  résultat est affiché sur la sortie standard.
</para>

<para>
  <envar>LOGTIMESTAMP</envar> permet de rechercher à partir de cette (plutôt
  sur la dernière heure).
</para>

<para>
  Un administrateur peut exécuter ce script une fois par heure pour surveiller
  les problèmes de réplication.
</para>

</sect2>

<sect2 id="wikigen">
<title>Produire un rapport de surveillance au format MediaWiki</title>
<indexterm><primary>générer la documentation Wiki d'un cluster</primary></indexterm>

<para>
  Le script <filename>mkmediawiki.pl </filename>, situé dans
  <filename>tools</filename>, peut être utilisé pour générer un rapport de
  surveillance du cluster compatible avec le populaire logiciel <ulink
  url="http://www.mediawiki.org/">MediaWiki</ulink>. Note that the
  <option>--categories</option> permits the user to specify a set of
  (comma-delimited) categories with which to associate the output.  If
  you have a series of &slony1; clusters, passing in the option
  <option>--categories=slony1</option> leads to the MediaWiki instance
  generating a category page listing all &slony1; clusters so
  categorized on the wiki.
</para>

<para>
  On pourra utiliser le commande ainsi&nbsp;:
</para>

<screen>
~/logtail.en>         mvs login -d mywiki.example.info -u "Chris Browne" -p `cat ~/.wikipass` -w wiki/index.php                     
Doing login with host: logtail and lang: en
~/logtail.en> perl $SLONYHOME/tools/mkmediawiki.pl --host localhost --database slonyregress1 --cluster slony_regress1 --categories=Slony-I > Slony_replication.wiki
~/logtail.en> mvs commit -m "More sophisticated generated Slony-I cluster docs" Slony_replication.wiki
Doing commit Slony_replication.wiki with host: logtail and lang: en
</screen>

<para>
  Notons que <command>mvs</command> est un client Mediawiki écrit en Perl&nbsp;;
  sur <ulink url="http://www.debian.org/">Debian GNU/Linux</ulink>, le paquet
  associé est nommé <application>libwww-mediawiki-client-perl</application>&nbsp;;
  d'autres systèmes disposent probablement d'une version packagée sous un nom
  similaire.
</para>

</sect2>

<sect2>
<title> Analysis of a SYNC </title>

<para> The following is (as of 2.0) an extract from the &lslon; log for node
#2 in a run of <quote>test1</quote> from the <xref linkend="testbed"/>. </para>

<screen>
DEBUG2 remoteWorkerThread_1: SYNC 19 processing
INFO   about to monitor_subscriber_query - pulling big actionid list 134885072
INFO   remoteWorkerThread_1: syncing set 1 with 4 table(s) from provider 1
DEBUG2  ssy_action_list length: 0
DEBUG2 remoteWorkerThread_1: current local log_status is 0
DEBUG2 remoteWorkerThread_1_1: current remote log_status = 0
DEBUG1 remoteHelperThread_1_1: 0.028 seconds delay for first row
DEBUG1 remoteHelperThread_1_1: 0.978 seconds until close cursor
INFO   remoteHelperThread_1_1: inserts=144 updates=1084 deletes=0
INFO   remoteWorkerThread_1: sync_helper timing:  pqexec (s/count)- provider 0.063/6 - subscriber 0.000/6
INFO   remoteWorkerThread_1: sync_helper timing:  large tuples 0.315/288
DEBUG2 remoteWorkerThread_1: cleanup
INFO   remoteWorkerThread_1: SYNC 19 done in 1.272 seconds
INFO   remoteWorkerThread_1: SYNC 19 sync_event timing:  pqexec (s/count)- provider 0.001/1 - subscriber 0.004/1 - IUD 0.972/248
</screen>

<para> Here are some notes to interpret this output: </para>

<itemizedlist>
<listitem><para> Note the line that indicates <screen>inserts=144 updates=1084 deletes=0</screen> </para> 
<para> This indicates how many tuples were affected by this particular SYNC. </para></listitem>
<listitem><para> Note the line indicating <screen>0.028 seconds delay for first row</screen></para> 

<para> This indicates the time it took for the <screen>LOG
cursor</screen> to get to the point of processing the first row of
data.  Normally, this takes a long time if the SYNC is a large one,
and one requiring sorting of a sizable result set.</para></listitem>

<listitem><para> Note the line indicating <screen>0.978 seconds until
close cursor</screen></para> 

<para> This indicates how long processing took against the
provider.</para></listitem>

<listitem><para> sync_helper timing:  large tuples 0.315/288 </para> 

<para> This breaks off, as a separate item, the number of large tuples
(<emphasis>e.g.</emphasis> - where size exceeded the configuration
parameter <xref linkend="slon-config-max-rowsize"/>) and where the
tuples had to be processed individually. </para></listitem>

<listitem><para> <screen>SYNC 19 done in 1.272 seconds</screen></para> 

<para> This indicates that it took 1.272 seconds, in total, to process
this set of SYNCs. </para>
</listitem>

<listitem><para> <screen>SYNC 19 sync_event timing:  pqexec (s/count)- provider 0.001/1 - subscriber 0.004/0 - IUD 0.972/248</screen></para> 

<para> This records information about how many queries were issued
against providers and subscribers in function
<function>sync_event()</function>, and how long they took. </para>

<para> Note that 248 does not match against the numbers of inserts,
updates, and deletes, described earlier, as I/U/D requests are
clustered into groups of queries that are submitted via a single
<function>pqexec()</function> call on the
subscriber. </para></listitem>

<listitem><para> <screen>sync_helper timing:  pqexec (s/count)- provider 0.063/6 - subscriber 0.000/6</screen></para>

<para> This records information about how many queries were issued
against providers and subscribers in function
<function>sync_helper()</function>, and how long they took.
</para></listitem>

</itemizedlist>

</sect2>

</sect1>
